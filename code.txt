======= Directory: app =======

----- app/models.py -----
# app/models.py

from datetime import datetime, timezone
from enum import Enum as PyEnum
import uuid

from sqlalchemy import (
    Column,
    Integer,
    String,
    Float,
    DateTime,
    Boolean,
    ForeignKey,
    JSON,
    func
)
from sqlalchemy.orm import relationship
from sqlalchemy import Enum as Enum 
from app.core.database import Base
from app.schemas import DeviceType


# -------------------------------------------------------------------
# USERS & PROFILES
# -------------------------------------------------------------------

def _uuid() -> str:
    return uuid.uuid4().hex 

class User(Base):
    __tablename__ = "users"

    id              = Column(Integer, primary_key=True, index=True)
    email           = Column(String(128), unique=True, nullable=False, index=True)
    hashed_password = Column(String(256), nullable=False)
    role            = Column(String(50), nullable=False, default="user")
    created_at      = Column(DateTime(timezone=True), server_default=func.now(), nullable=False)
    updated_at      = Column(
                         DateTime(timezone=True),
                         server_default=func.now(),
                         onupdate=func.now(),
                         nullable=False,
                     )

    # oneâ€toâ€one
    profile      = relationship(
                       "UserProfile",
                       back_populates="user",
                       uselist=False,
                       cascade="all, delete-orphan",
                       lazy="joined",
                   )
    # oneâ€toâ€many
    farms        = relationship(
                       "Farm",
                       back_populates="user",
                       cascade="all, delete-orphan",
                       lazy="joined",
                   )
    devices      = relationship("Device", back_populates="user", cascade="all, delete-orphan")
    subscriptions = relationship("Subscription", back_populates="user", cascade="all, delete-orphan")
    payment_orders = relationship("PaymentOrder", back_populates="user", cascade="all, delete-orphan")
    cameras      = relationship("UserCamera", back_populates="user", cascade="all, delete-orphan")

class UserProfile(Base):
    __tablename__ = "user_profiles"

    id          = Column(Integer, primary_key=True, index=True)
    user_id     = Column(Integer, ForeignKey("users.id", ondelete="CASCADE"), nullable=False, unique=True)
    first_name  = Column(String(50))
    last_name   = Column(String(50))
    phone       = Column(String(20))
    address     = Column(String(256))
    city        = Column(String(100))
    state       = Column(String(100))
    country     = Column(String(100))
    postal_code = Column(String(20))
    created_at  = Column(DateTime(timezone=True), server_default=func.now(), nullable=False)
    updated_at  = Column(DateTime(timezone=True), server_default=func.now(), onupdate=func.now(), nullable=False)

    user = relationship("User", back_populates="profile")


# -------------------------------------------------------------------
# FARMS
# -------------------------------------------------------------------

class Farm(Base):
    __tablename__ = "farms"

    id          = Column(Integer, primary_key=True, index=True)
    user_id     = Column(Integer, ForeignKey("users.id", ondelete="CASCADE"), nullable=False)
    name        = Column(String(128), nullable=False)
    location    = Column(String(256))
    created_at  = Column(DateTime(timezone=True), server_default=func.now(), nullable=False)
    updated_at  = Column(DateTime(timezone=True), server_default=func.now(), onupdate=func.now(), nullable=False)

    user    = relationship("User", back_populates="farms")
    devices = relationship("Device", back_populates="farm", cascade="all, delete-orphan")


# -------------------------------------------------------------------
# DEVICES & PROFILES
# -------------------------------------------------------------------

class Device(Base):
    __tablename__ = "devices"
    id = Column(String(64), primary_key=True, index=True) 
    user_id             = Column(Integer, ForeignKey("users.id", ondelete="SET NULL"), nullable=True)
    farm_id             = Column(Integer, ForeignKey("farms.id", ondelete="SET NULL"), nullable=True)
    mac_id              = Column(String(64), unique=True, nullable=False, index=True)
    name                = Column(String(128), nullable=False)
    type                = Column(Enum(DeviceType, name="device_type"), nullable=False)
    http_endpoint       = Column(String(256), nullable=False)
    location_description= Column(String(256))
    is_active           = Column(Boolean, nullable=False, default=True)
    last_seen           = Column(DateTime(timezone=True))
    firmware_version    = Column(String(32), nullable=False, server_default="0.0.0")
    created_at          = Column(DateTime(timezone=True), server_default=func.now(), nullable=False)
    updated_at          = Column(DateTime(timezone=True), server_default=func.now(), onupdate=func.now(), nullable=False)

    # JSON blobs
    pump_configurations = Column(JSON)
    sensor_parameters   = Column(JSON)
    valve_configurations= Column(JSON)

    # relationships
    user               = relationship("User", back_populates="devices")
    farm               = relationship("Farm", back_populates="devices")
    dosing_profiles    = relationship("DosingProfile", back_populates="device", cascade="all, delete-orphan")
    sensor_readings    = relationship("SensorReading", back_populates="device", cascade="all, delete-orphan")
    dosing_operations  = relationship("DosingOperation", back_populates="device", cascade="all, delete-orphan")
    subscriptions      = relationship("Subscription", back_populates="device", cascade="all, delete-orphan")
    payment_orders     = relationship("PaymentOrder", back_populates="device", cascade="all, delete-orphan")
    tasks              = relationship("Task", back_populates="device", cascade="all, delete-orphan")


class DosingProfile(Base):
    __tablename__ = "dosing_profiles"

    id             = Column(Integer, primary_key=True, index=True)
    device_id      = Column(String(32), ForeignKey("devices.id", ondelete="CASCADE"), nullable=False)
    plant_name     = Column(String(100), nullable=False)
    plant_type     = Column(String(100), nullable=False)
    growth_stage   = Column(String(50), nullable=False)
    seeding_date   = Column(DateTime(timezone=True), nullable=False)
    target_ph_min  = Column(Float, nullable=False)
    target_ph_max  = Column(Float, nullable=False)
    target_tds_min = Column(Float, nullable=False)
    target_tds_max = Column(Float, nullable=False)
    dosing_schedule= Column(JSON, nullable=False)
    created_at     = Column(DateTime(timezone=True), server_default=func.now(), nullable=False)
    updated_at     = Column(DateTime(timezone=True), server_default=func.now(), onupdate=func.now(), nullable=False)

    device = relationship("Device", back_populates="dosing_profiles")

# app/models.py

class DeviceCommand(Base):
    __tablename__ = "device_commands"
    id            = Column(Integer, primary_key=True)
    device_id     = Column(String, index=True)
    action = Column(
        Enum("restart", "update", name="cmd_action", native_enum=False),
        nullable=False,
    )
    parameters    = Column(JSON, nullable=True)     # e.g. {"url": "..."}
    issued_at     = Column(DateTime, default=datetime.utcnow)
    dispatched    = Column(Boolean, default=False)

class Task(Base):
    __tablename__ = "tasks"

    id           = Column(Integer, primary_key=True, index=True)
    device_mac_id= Column(String(64), ForeignKey("devices.mac_id", ondelete="CASCADE"), nullable=False, index=True)
    type         = Column(String(50), nullable=False)
    parameters   = Column(JSON)
    status       = Column(String(50), nullable=False, default="pending")
    created_at   = Column(DateTime(timezone=True), server_default=func.now(), nullable=False)

    device = relationship("Device", back_populates="tasks")


class SensorReading(Base):
    __tablename__ = "sensor_readings"

    id          = Column(Integer, primary_key=True, index=True)
    device_id = Column(String(64), ForeignKey("devices.id", ondelete="CASCADE"))
    reading_type= Column(String(50), nullable=False)
    value       = Column(Float, nullable=False)
    timestamp   = Column(DateTime(timezone=True), server_default=func.now(), nullable=False)
    location    = Column(String(100))

    device = relationship("Device", back_populates="sensor_readings")


class DosingOperation(Base):
    __tablename__ = "dosing_operations"

    id          = Column(Integer, primary_key=True, index=True)
    device_id = Column(String(64), ForeignKey("devices.id", ondelete="CASCADE"))
    operation_id= Column(String(100), unique=True, nullable=False)
    actions     = Column(JSON, nullable=False)
    status      = Column(String(50), nullable=False)
    timestamp   = Column(DateTime(timezone=True), server_default=func.now(), nullable=False)

    device = relationship("Device", back_populates="dosing_operations")


# -------------------------------------------------------------------
# PLANTS & ANALYSIS
# -------------------------------------------------------------------

class Plant(Base):
    __tablename__ = "plants"

    id           = Column(Integer, primary_key=True, index=True)
    name         = Column(String(100), nullable=False)
    type         = Column(String(100), nullable=False)
    growth_stage = Column(String(50),  nullable=False)
    seeding_date = Column(DateTime(timezone=True), nullable=False)
    region       = Column(String(100), nullable=False)
    location     = Column(String(100), nullable=False)
    created_at   = Column(DateTime(timezone=True), server_default=func.now(), nullable=False)
    updated_at   = Column(DateTime(timezone=True), server_default=func.now(), onupdate=func.now(), nullable=False)


class SupplyChainAnalysis(Base):
    __tablename__ = "supply_chain_analysis"

    id                   = Column(Integer, primary_key=True, index=True)
    origin               = Column(String(100), nullable=False)
    destination          = Column(String(100), nullable=False)
    produce_type         = Column(String(50),  nullable=False)
    weight_kg            = Column(Float, nullable=False)
    transport_mode       = Column(String(50), server_default="railway", nullable=False)
    distance_km          = Column(Float, nullable=False)
    cost_per_kg          = Column(Float, nullable=False)
    total_cost           = Column(Float, nullable=False)
    estimated_time_hours = Column(Float, nullable=False)
    market_price_per_kg  = Column(Float, nullable=False)
    net_profit_per_kg    = Column(Float, nullable=False)
    final_recommendation = Column(String(200), nullable=False)
    created_at           = Column(DateTime(timezone=True), server_default=func.now(), nullable=False)
    updated_at           = Column(DateTime(timezone=True), server_default=func.now(), onupdate=func.now(), nullable=False)

    conversation_logs = relationship(
        "ConversationLog", back_populates="analysis", cascade="all, delete-orphan"
    )


class ConversationLog(Base):
    __tablename__ = "conversation_logs"

    id           = Column(Integer, primary_key=True, index=True)
    analysis_id  = Column(Integer, ForeignKey("supply_chain_analysis.id", ondelete="SET NULL"))
    conversation = Column(JSON, nullable=False)
    created_at   = Column(DateTime(timezone=True), server_default=func.now(), nullable=False)

    analysis = relationship("SupplyChainAnalysis", back_populates="conversation_logs")


# -------------------------------------------------------------------
# SUBSCRIPTIONS & BILLING
# -------------------------------------------------------------------

class SubscriptionPlan(Base):
    __tablename__ = "subscription_plans"

    id            = Column(Integer, primary_key=True, index=True)
    name          = Column(String(128), nullable=False)
    device_types  = Column(JSON, nullable=False)    # e.g. ["dosing_unit"]
    duration_days = Column(Integer, nullable=False)  # 28 to 730
    price_cents   = Column(Integer, nullable=False)
    created_by    = Column(Integer, ForeignKey("users.id", ondelete="SET NULL"), nullable=False)
    created_at    = Column(DateTime(timezone=True), server_default=func.now(), nullable=False)

    activation_keys = relationship("ActivationKey", back_populates="plan", cascade="all, delete-orphan")
    subscriptions   = relationship("Subscription", back_populates="plan", cascade="all, delete-orphan")
    payment_orders  = relationship("PaymentOrder", back_populates="plan", cascade="all, delete-orphan")


class ActivationKey(Base):
    __tablename__ = "activation_keys"

    id                  = Column(Integer, primary_key=True, index=True)
    key                 = Column(String(64), unique=True, nullable=False, index=True)
    device_type         = Column(Enum(DeviceType, name="activation_device_type"), nullable=False)
    plan_id             = Column(Integer, ForeignKey("subscription_plans.id", ondelete="CASCADE"), nullable=False)
    created_by          = Column(Integer, ForeignKey("users.id", ondelete="SET NULL"), nullable=False)
    created_at          = Column(DateTime(timezone=True), server_default=func.now(), nullable=False)
    redeemed            = Column(Boolean, default=False, nullable=False)
    redeemed_at         = Column(DateTime(timezone=True), nullable=True)
    redeemed_device_id  = Column(String(64), ForeignKey("devices.id", ondelete="SET NULL"))
    redeemed_user_id    = Column(Integer, ForeignKey("users.id", ondelete="SET NULL"))
    allowed_device_id   = Column(String(64), ForeignKey("devices.id", ondelete="SET NULL"))

    plan             = relationship("SubscriptionPlan", back_populates="activation_keys")
    creator          = relationship("User", foreign_keys=[created_by])
    redeemed_device  = relationship("Device", foreign_keys=[redeemed_device_id])
    redeemed_user    = relationship("User", foreign_keys=[redeemed_user_id])
    allowed_device   = relationship("Device", foreign_keys=[allowed_device_id], backref="allowed_activation_keys")


class Subscription(Base):
    __tablename__ = "subscriptions"

    id         = Column(Integer, primary_key=True, index=True)
    user_id    = Column(Integer, ForeignKey("users.id", ondelete="CASCADE"), nullable=False)
    device_id = Column(String(64), ForeignKey("devices.id", ondelete="CASCADE"))
    plan_id    = Column(Integer, ForeignKey("subscription_plans.id", ondelete="SET NULL"), nullable=False)
    start_date = Column(DateTime(timezone=True), server_default=func.now(), nullable=False)
    end_date   = Column(DateTime(timezone=True), nullable=False)
    active     = Column(Boolean, default=True, nullable=False)
    created_at = Column(DateTime(timezone=True), server_default=func.now(), nullable=False)

    user   = relationship("User", back_populates="subscriptions")
    device = relationship("Device", back_populates="subscriptions")
    plan   = relationship("SubscriptionPlan", back_populates="subscriptions")


class PaymentStatus(PyEnum):
    PENDING    = "pending"
    PROCESSING = "processing"
    COMPLETED  = "completed"
    FAILED     = "failed"


class PaymentOrder(Base):
    __tablename__ = "payment_orders"

    id                 = Column(Integer, primary_key=True, index=True)
    user_id            = Column(Integer, ForeignKey("users.id", ondelete="CASCADE"), nullable=False)
    device_id          = Column(String(64), ForeignKey("devices.id", ondelete="CASCADE"))
    plan_id            = Column(Integer, ForeignKey("subscription_plans.id", ondelete="SET NULL"), nullable=False)
    amount_cents       = Column(Integer, nullable=False)
    status             = Column(
                             Enum(PaymentStatus, name="payment_status"),
                             default=PaymentStatus.PENDING,
                             nullable=False,
                         )
    upi_transaction_id = Column(String(64))
    created_at         = Column(DateTime(timezone=True), server_default=func.now(), nullable=False)
    updated_at         = Column(DateTime(timezone=True), server_default=func.now(), onupdate=func.now(), nullable=False)

    user   = relationship("User", back_populates="payment_orders")
    device = relationship("Device", back_populates="payment_orders")
    plan   = relationship("SubscriptionPlan", back_populates="payment_orders")


# -------------------------------------------------------------------
# CAMERAS & DETECTIONS
# -------------------------------------------------------------------

class Camera(Base):
    __tablename__ = "cameras"

    id              = Column(String(64), primary_key=True, index=True)
    name            = Column(String(120), nullable=False)
    is_online       = Column(Boolean, default=False, nullable=False)
    last_seen       = Column(DateTime(timezone=True))
    frames_received = Column(Integer, default=0, nullable=False)
    clips_count     = Column(Integer, default=0, nullable=False)
    last_clip_time  = Column(DateTime(timezone=True))
    storage_used    = Column(Float, default=0.0, nullable=False)  # MB
    settings        = Column(JSON)

    user_cameras     = relationship("UserCamera", back_populates="camera", cascade="all, delete-orphan")
    detection_records= relationship("DetectionRecord", back_populates="camera", cascade="all, delete-orphan")


class UserCamera(Base):
    __tablename__ = "user_cameras"

    id        = Column(Integer, primary_key=True, index=True)
    user_id   = Column(Integer, ForeignKey("users.id", ondelete="CASCADE"), nullable=False)
    camera_id = Column(String(64), ForeignKey("cameras.id", ondelete="CASCADE"), nullable=False)
    nickname  = Column(String(120))

    user   = relationship("User", back_populates="cameras")
    camera = relationship("Camera", back_populates="user_cameras")


class DetectionRecord(Base):
    __tablename__ = "detection_records"

    id          = Column(Integer, primary_key=True, index=True)
    camera_id   = Column(String(64), ForeignKey("cameras.id", ondelete="CASCADE"), nullable=False)
    object_name = Column(String(100), nullable=False)
    timestamp   = Column(DateTime(timezone=True), server_default=func.now(), nullable=False)

    camera = relationship("Camera", back_populates="detection_records")


class CloudKey(Base):
    __tablename__ = "cloud_keys"

    id         = Column(Integer, primary_key=True, index=True)
    key        = Column(String(64), unique=True, nullable=False, index=True)
    created_by = Column(Integer, ForeignKey("admins.id", ondelete="CASCADE"), nullable=False)
    created_at = Column(DateTime(timezone=True), server_default=func.now())

    creator = relationship("Admin", back_populates="cloud_keys")


class CameraToken(Base):
    __tablename__ = "camera_tokens"
    camera_id = Column(String(64), primary_key=True)
    token     = Column(String(64), nullable=False)
    issued_at = Column(DateTime(timezone=True), server_default=func.now())


class Admin(Base):
    __tablename__ = "admins"

    id           = Column(Integer, primary_key=True, index=True)
    email        = Column(String(128), unique=True, nullable=False, index=True)
    hashed_password = Column(String(256), nullable=False)
    role         = Column(String(50), nullable=False, default="superadmin")
    created_at   = Column(DateTime(timezone=True), server_default=func.now())

    # ğŸ‘‡ **add this single line**
    cloud_keys = relationship(
        "CloudKey",
        back_populates="creator",
        cascade="all, delete-orphan",
        lazy="selectin",          # optional â€“ gives efficient eager loading
    )

----- app/__init__.py -----
# app/__init__.py
"""
Hydroleaf Application Package Initialization.
This file marks the directory as a Python package.
"""


----- app/simulated_esp.py -----
# simulated_esp_all.py
"""
Hydroleaf Simulated Device Server
Simulates an ESP32-CAM, Dosing Unit, and Valve Controller on a single HTTP endpoint for testing.
Listens on port 8080 and provides all device-specific API routes.
"""
import logging
from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from datetime import datetime

# Configure logging
tlogging = logging.getLogger("simulator")
logging.basicConfig(level=logging.INFO)

# Instantiate FastAPI app
app = FastAPI(
    title="Hydroleaf Simulated ESP32 Devices",
    version="1.0.0",
    docs_url="/docs",
    redoc_url=None,
)

# Allow all CORS (for testing)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

## Discovery Endpoint
@app.get("/discovery", summary="Simulated device discovery")
async def discovery():
    """
    Simulates the /discovery endpoint for all devices.
    Returns device metadata for registration/discovery.
    """
    logging.info("/discovery called")
    return {
        "device_id": "dummy_device",
        "name": "Simulated ESP Device",
        # For dosing registrations, tests expect "dosing_unit"
        "type": "dosing_unit",
        "version": "3.0.0",
        "status": "online",
        "ip": "127.0.0.1"
    }

## Pump Endpoint (Dosing Unit)
@app.post("/pump", summary="Activate a pump")
async def pump(request: Request):
    data = await request.json()
    pump = data.get("pump")
    amount = data.get("amount")
    if pump is None or amount is None:
        logging.warning("/pump missing pump or amount")
        raise HTTPException(status_code=400, detail="Missing pump or amount")
    logging.info(f"/pump called: pump={pump}, amount={amount}")
    return {
        "message": "Pump started",
        "pump": pump,
        "dose_ml": amount,
        "timestamp": datetime.utcnow().isoformat()
    }

## Combined Dose + Monitor Endpoint
@app.post("/dose_monitor", summary="Activate pump and monitor")
async def dose_monitor(request: Request):
    data = await request.json()
    pump = data.get("pump")
    amount = data.get("amount")
    if pump is None or amount is None:
        logging.warning("/dose_monitor missing pump or amount")
        raise HTTPException(status_code=400, detail="Missing pump or amount")
    logging.info(f"/dose_monitor called: pump={pump}, amount={amount}")
    return {
        "message": "Combined started",
        "pump": pump,
        "dose_ml": amount,
        "timestamp": datetime.utcnow().isoformat()
    }

## Pump Calibration Endpoint
@app.post("/pump_calibration", summary="Pump calibration command")
async def pump_calibration(request: Request):
    data = await request.json()
    command = data.get("command")
    logging.info(f"/pump_calibration called: command={command}")
    if command == "start":
        return {"message": "All pumps on"}
    elif command == "stop":
        return {"message": "All pumps off"}
    else:
        raise HTTPException(status_code=400, detail="Invalid command")

## Sensor Monitor Endpoint
@app.get("/monitor", summary="Return sensor readings")
async def monitor():
    logging.info("/monitor called")
    return {
        "device_id": "dummy_device",
        "type": "dosing_unit",
        "version": "3.0.0",
        "wifi_connected": True,
        # Provide fixed pH and TDS
        "ph": 6.8,
        "tds": 750
    }

## Valve State Endpoint (Valve Controller)
@app.get("/state", summary="Return valve states")
async def state():
    logging.info("/state called")
    return {
        "device_id": "dummy_valve",
        "valves": [
            {"id": i, "state": "off"} for i in range(1, 5)
        ]
    }

## Toggle Valve Endpoint
@app.post("/toggle", summary="Toggle a valve")
async def toggle(request: Request):
    data = await request.json()
    valve = data.get("valve_id")
    logging.info(f"/toggle called: valve_id={valve}")
    if valve not in [1, 2, 3, 4]:
        raise HTTPException(status_code=400, detail="Invalid valve_id")
    # Echo back toggled state
    return {
        "device_id": "dummy_valve",
        "valve_id": valve,
        "new_state": "toggled"
    }

## Main Entrypoint
def main():
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8080)

if __name__ == "__main__":
    main()


----- app/schemas.py -----
from enum import Enum
from typing import Optional, List, Dict
from datetime import datetime

from pydantic import BaseModel, Field, ConfigDict, field_validator, EmailStr

# -------------------- Device Related Schemas -------------------- #

class DeviceType(str, Enum):
    DOSING_UNIT = "dosing_unit"
    PH_TDS_SENSOR = "ph_tds_sensor"
    ENVIRONMENT_SENSOR = "environment_sensor"
    VALVE_CONTROLLER = "valve_controller"
   
class PumpConfig(BaseModel):
    pump_number: int = Field(..., ge=1, le=4)
    chemical_name: str = Field(..., max_length=50)
    chemical_description: Optional[str] = Field(None, max_length=200)

    model_config = ConfigDict(from_attributes=True)

class ValveConfig(BaseModel):
    valve_id: int = Field(..., ge=1, le=4)
    name: Optional[str] = Field(None, max_length=50)

    model_config = ConfigDict(from_attributes=True)

class DeviceBase(BaseModel):
    mac_id: str = Field(..., max_length=64)
    name: str = Field(..., max_length=128)
    type: DeviceType
    http_endpoint: str = Field(..., max_length=256)
    location_description: Optional[str] = Field(None, max_length=256)
    farm_id: Optional[int] = None

    model_config = ConfigDict(from_attributes=True)
    valve_configurations: Optional[List[ValveConfig]] = None

class DosingDeviceCreate(DeviceBase):
    pump_configurations: List[PumpConfig] = Field(..., min_length=1, max_length=4)
    
    @field_validator('type')
    @classmethod
    def validate_device_type(cls, v):
        if v != DeviceType.DOSING_UNIT:
            raise ValueError("Device type must be dosing_unit for DosingDeviceCreate")
        return v

class SensorDeviceCreate(DeviceBase):
    sensor_parameters: Dict[str, str] = Field(...)
    
    @field_validator('type')
    @classmethod
    def validate_device_type(cls, v):
        if v not in [DeviceType.PH_TDS_SENSOR, DeviceType.ENVIRONMENT_SENSOR]:
            raise ValueError("Device type must be a sensor type")
        return v

class DeviceResponse(DeviceBase):
    id: int
    created_at: datetime
    updated_at: datetime
    is_active: bool
    last_seen: Optional[datetime] = None
    pump_configurations: Optional[List[PumpConfig]] = None
    sensor_parameters: Optional[Dict[str, str]] = None

    model_config = ConfigDict(from_attributes=True)

# -------------------- Dosing Related Schemas -------------------- #

class DosingAction(BaseModel):
    pump_number: int
    chemical_name: str
    dose_ml: float
    reasoning: str

class DosingProfileBase(BaseModel):
    device_id: str  
    plant_name: str = Field(..., max_length=100)
    plant_type: str = Field(..., max_length=100)
    growth_stage: str = Field(..., max_length=50)
    seeding_date: datetime
    target_ph_min: float = Field(..., ge=0, le=14)
    target_ph_max: float = Field(..., ge=0, le=14)
    target_tds_min: float = Field(..., ge=0)
    target_tds_max: float = Field(..., ge=0)
    dosing_schedule: Dict[str, float] = Field(...)

    model_config = ConfigDict(from_attributes=True)

class DosingProfileCreate(DosingProfileBase):
    pass

class DosingProfileResponse(DosingProfileBase):
    id: int
    created_at: datetime
    updated_at: datetime

class DosingOperation(BaseModel):
    device_id: str  
    operation_id: str
    actions: List[DosingAction]
    status: str
    timestamp: datetime

    model_config = ConfigDict(from_attributes=True)

class SensorReading(BaseModel):
    device_id: str
    reading_type: str
    value: float
    timestamp: datetime

    model_config = ConfigDict(from_attributes=True)

# -------------------- Health Related Schemas -------------------- #

class HealthCheck(BaseModel):
    status: str
    version: str
    timestamp: datetime
    environment: str

class DatabaseHealthCheck(BaseModel):
    status: str
    type: str
    timestamp: datetime
    last_test: Optional[str]

class FullHealthCheck(BaseModel):
    system: HealthCheck
    database: DatabaseHealthCheck
    timestamp: datetime

class SimpleDosingCommand(BaseModel):
    pump: int = Field(..., ge=1, le=4, description="Pump number (1-4)")
    amount: float = Field(..., gt=0, description="Dose in milliliters")

# -------------------- Plant Related Schemas -------------------- #

class PlantBase(BaseModel):
    name: str = Field(..., max_length=100)
    type: str = Field(..., max_length=100)
    growth_stage: str = Field(..., max_length=50)
    seeding_date: datetime
    region: str = Field(..., max_length=100)
    location: str = Field(..., max_length=100)

class PlantCreate(PlantBase):
    """Schema for creating a new plant profile."""

class PlantResponse(PlantBase):
    """Schema for returning plant details."""
    id: int
    created_at: datetime
    updated_at: datetime

    model_config = ConfigDict(from_attributes=True)

# -------------------- Supply Chain Related Schemas -------------------- #

class TransportRequest(BaseModel):
    origin: str
    destination: str
    produce_type: str
    weight_kg: float
    transport_mode: str = "railway"

class TransportCost(BaseModel):
    distance_km: float
    cost_per_kg: float
    total_cost: float
    estimated_time_hours: float

class SupplyChainAnalysisResponse(BaseModel):
    origin: str
    destination: str
    produce_type: str
    weight_kg: float
    transport_mode: str
    distance_km: float
    cost_per_kg: float
    total_cost: float
    estimated_time_hours: float
    market_price_per_kg: float
    net_profit_per_kg: float
    final_recommendation: str
    created_at: Optional[datetime] = None

    model_config = ConfigDict(from_attributes=True)

class CloudAuthenticationRequest(BaseModel):
    device_id: str
    cloud_key: str

class CloudAuthenticationResponse(BaseModel):
    token: str
    message: str

class DosingCancellationRequest(BaseModel):
    device_id: str
    event: str

# -------------------- User Related Schemas -------------------- #

class UserUpdate(BaseModel):
    email: Optional[EmailStr] = None
    first_name: Optional[str] = Field(None, max_length=50)
    last_name: Optional[str] = Field(None, max_length=50)
    phone: Optional[str] = Field(None, max_length=20)
    role: Optional[str] = None
    address: Optional[str] = Field(None, max_length=256)
    city: Optional[str] = Field(None, max_length=100)
    state: Optional[str] = Field(None, max_length=100)
    country: Optional[str] = Field(None, max_length=100)
    postal_code: Optional[str] = Field(None, max_length=20)

class UserProfile(BaseModel):
    id: int
    email: EmailStr
    role: str
    first_name: str = Field(..., max_length=50)
    last_name: str = Field(..., max_length=50)
    phone: Optional[str] = Field(None, max_length=20)
    address: Optional[str] = Field(None, max_length=256)
    city: Optional[str] = Field(None, max_length=100)
    state: Optional[str] = Field(None, max_length=100)
    country: Optional[str] = Field(None, max_length=100)
    postal_code: Optional[str] = Field(None, max_length=20)
    created_at: datetime
    updated_at: datetime

    model_config = ConfigDict(from_attributes=True)

class UserCreate(BaseModel):
    email: EmailStr
    password: str
    first_name: Optional[str] = Field(None, max_length=50)
    last_name: Optional[str] = Field(None, max_length=50)
    phone: Optional[str] = Field(None, max_length=20)
    address: Optional[str] = Field(None, max_length=256)
    city: Optional[str] = Field(None, max_length=100)
    state: Optional[str] = Field(None, max_length=100)
    country: Optional[str] = Field(None, max_length=100)
    postal_code: Optional[str] = Field(None, max_length=20)
    name: str = Field(..., max_length=128)
    location: Optional[str] = Field(None, max_length=256)

class FarmBase(BaseModel):
    name: str = Field(..., max_length=128)
    location: Optional[str] = Field(None, max_length=256)

class FarmCreate(FarmBase):
    pass

class FarmResponse(FarmBase):
    id: int
    created_at: datetime
    updated_at: datetime

    model_config = ConfigDict(from_attributes=True)

class ValveDeviceCreate(DeviceBase):
    valve_configurations: List[ValveConfig] = Field(..., min_length=1, max_length=4)

    @field_validator('type')
    @classmethod
    def validate_device_type(cls, v):
        if v != DeviceType.VALVE_CONTROLLER:
            raise ValueError("Device type must be valve_controller for ValveDeviceCreate")
        return v
    
class UserProfileBase(BaseModel):
    first_name: Optional[str] = None
    last_name: Optional[str] = None
    phone: Optional[str] = None
    address: Optional[str] = None
    city: Optional[str] = None
    state: Optional[str] = None
    country: Optional[str] = None
    postal_code: Optional[str] = None

class UserProfileCreate(UserProfileBase):
    pass

class UserProfileResponse(UserProfileBase):
    id: int
    user_id: int
    created_at: datetime
    updated_at: datetime

    model_config = ConfigDict(from_attributes=True)

class UserResponse(BaseModel):
    id: int
    email: EmailStr
    role: str
    created_at: datetime
    profile: Optional[UserProfileResponse] = None

    model_config = ConfigDict(from_attributes=True)

class SubscriptionPlanCreate(BaseModel):
    name: str
    device_types: List[str]
    duration_days: int
    price_cents: int

class SubscriptionResponse(BaseModel):
    id: int
    user_id: int
    device_id: str
    plan_id: int
    start_date: datetime
    end_date: datetime
    active: bool

    model_config = ConfigDict(from_attributes=True)

class ActivationKeyResponse(BaseModel):
    activation_key: str

class SubscriptionPlanResponse(BaseModel):
    id: int
    name: str
    device_types: List[str]
    duration_days: int
    price_cents: int
    created_by: int
    created_at: datetime

    model_config = ConfigDict(from_attributes=True)

class CreatePaymentRequest(BaseModel):
    device_id: str
    plan_id: int

class ConfirmPaymentRequest(BaseModel):
    upi_transaction_id: str = Field(..., max_length=64)

class PaymentStatus(str, Enum):
    PENDING = "pending"
    PROCESSING = "processing"
    COMPLETED = "completed"
    FAILED = "failed"

class PaymentOrderResponse(BaseModel):
    id: int
    user_id: int
    device_id: str
    plan_id: int
    amount_cents: int
    status: PaymentStatus
    upi_transaction_id: Optional[str]
    qr_code_url: Optional[str]
    created_at: datetime
    updated_at: datetime

    model_config = ConfigDict(from_attributes=True)

class DetectionRange(BaseModel):
    object_name: str
    start_time: datetime
    end_time: datetime

class CameraReportResponse(BaseModel):
    camera_id: str
    detections: List[DetectionRange]


----- app/main.py -----
# app/main.py

import os
import time
import logging
import asyncio
from datetime import datetime, timezone
from contextlib import asynccontextmanager

from fastapi import FastAPI, HTTPException, Request, status
from fastapi.middleware.cors import CORSMiddleware
from starlette.middleware.sessions import SessionMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import JSONResponse
from fastapi.templating import Jinja2Templates
import uvicorn

from app.core.config import ENVIRONMENT, ALLOWED_ORIGINS, SESSION_KEY, API_V1_STR, RESET_DB
from app.core.database import engine, Base, get_db, check_db_connection

from app.routers import (
    auth_router,
    users_router,
    admin_users_router,
    subscriptions_router,
    admin_subscriptions_router,
    devices_router,
    dosing_router,
    config_router,
    farms_router,
    plants_router,
    supply_chain_router,
    cloud_router,
    admin_router,
    device_comm_router,
    cameras_router,
)

from app.routers.cameras import upload_day_frame, upload_night_frame
from app.utils.camera_tasks import offline_watcher
from app.utils.camera_queue import camera_queue

# â”€â”€â”€ Logging Setup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

# â”€â”€â”€ Application Lifespan â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@asynccontextmanager
async def lifespan(app):
    # record startup time for /health
    app.state.start_time = time.time()

    async with engine.begin() as conn:
        if RESET_DB:
            await conn.run_sync(Base.metadata.drop_all)
        await conn.run_sync(Base.metadata.create_all)

    yield
# â”€â”€â”€ Instantiate FastAPI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
app = FastAPI(
    title="Hydroleaf API",
    version=os.getenv("API_VERSION", "1.0.0"),
    docs_url=f"{API_V1_STR}/docs",
    redoc_url=None,
    openapi_url=f"{API_V1_STR}/openapi.json",
    lifespan=lifespan,
)

# â”€â”€â”€ Middleware â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
app.add_middleware(SessionMiddleware, secret_key=SESSION_KEY)
app.add_middleware(
    CORSMiddleware,
    allow_origins=ALLOWED_ORIGINS,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
app.mount("/static", StaticFiles(directory="app/static"), name="static")
templates = Jinja2Templates(directory="app/templates")
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost",
        "http://localhost:3000",
        "http://127.0.0.1:3000",
        "http://localhost:5173",
        "http://127.0.0.1:5173",
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
# â”€â”€â”€ Request Logging Middleware â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.middleware("http")
async def log_requests(request: Request, call_next):
    start = time.time()
    try:
        # â”€â”€ NEW: who is calling? â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        client_ip = request.headers.get("x-forwarded-for", request.client.host)
        device_id = request.query_params.get("device_id")  # may be None

        response = await call_next(request)
        latency = time.time() - start

        # neat oneâ€‘liner: METHOD PATH â€¢ ip=â€¦ â€¢ device_id=â€¦ â€¢ code â€¢  ms
        logger.info(
            "%s %s â€¢ ip=%s â€¢ device_id=%s â€¢ %d â€¢ %.1fâ€¯ms",
            request.method,
            request.url.path,
            client_ip,
            device_id or "-",
            response.status_code,
            latency * 1000,
        )

        response.headers.update({
             "X-Process-Time": f"{latency:.3f}",
             "X-API-Version": app.version,
         })
        return response
    except Exception as exc:
        logger.error(f"Unhandled error during request: {exc}", exc_info=True)
        raise

# â”€â”€â”€ Health Endpoints â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.get(f"{API_V1_STR}/health")
async def health_check():
    uptime = time.time() - app.state.start_time
    return {
        "status": "healthy",
        "version": app.version,
        "timestamp": datetime.now(timezone.utc),
        "environment": ENVIRONMENT,
        "uptime": uptime,
    }

@app.get(f"{API_V1_STR}/health/database")
async def database_health():
    return await check_db_connection()

@app.get(f"{API_V1_STR}/health/system")
async def system_health():
    sys = await health_check()
    db = await database_health()
    return {
        "system": sys,
        "database": db,
        "timestamp": datetime.now(timezone.utc),
    }

# â”€â”€â”€ Override Camera Upload Endpoints â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
app.add_api_route("/upload/{camera_id}/day", upload_day_frame, methods=["POST"])
app.add_api_route("/upload/{camera_id}/night", upload_night_frame, methods=["POST"])

# â”€â”€â”€ Exception Handlers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.exception_handler(HTTPException)
async def http_exc_handler(request: Request, exc: HTTPException):
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "detail": exc.detail,
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "path": request.url.path,
        },
    )

@app.exception_handler(Exception)
async def exc_handler(request: Request, exc: Exception):
    logger.error(f"Unhandled exception: {exc}", exc_info=True)
    return JSONResponse(
        status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
        content={
            "detail": "Internal server error",
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "path": request.url.path,
        },
    )

# â”€â”€â”€ Include Routers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# routers that declare their own prefixes internally:
app.include_router(auth_router,            prefix=f"{API_V1_STR}/auth")
app.include_router(users_router)                                  # already @router(prefix="/api/v1/users")
app.include_router(admin_users_router)                            # already @router(prefix="/admin/users")
app.include_router(subscriptions_router)                          # already @router(prefix="/api/v1/subscriptions")
app.include_router(admin_subscriptions_router)                    # already @router(prefix="/admin")

# the rest use main.py prefixes:
app.include_router(devices_router,       prefix=f"{API_V1_STR}/devices",       tags=["devices"])
app.include_router(dosing_router,        prefix=f"{API_V1_STR}/dosing",        tags=["dosing"])
app.include_router(config_router,        prefix=f"{API_V1_STR}/config",        tags=["config"])
app.include_router(plants_router,        prefix=f"{API_V1_STR}/plants",        tags=["plants"])
app.include_router(farms_router,         prefix=f"{API_V1_STR}/farms",         tags=["farms"])
app.include_router(supply_chain_router,  prefix=f"{API_V1_STR}/supply_chain",  tags=["supply_chain"])
app.include_router(cloud_router,         prefix=f"{API_V1_STR}/cloud",         tags=["cloud"])
app.include_router(admin_router,         prefix="/admin",                      tags=["admin"])
app.include_router(device_comm_router,   prefix=f"{API_V1_STR}/device_comm",   tags=["device_comm"])
app.include_router(cameras_router,       prefix=f"{API_V1_STR}/cameras",       tags=["cameras"])

# â”€â”€â”€ Startup Tasks â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.on_event("startup")
async def startup_tasks():
    asyncio.create_task(
        offline_watcher(
            db_factory=get_db,
            interval_seconds=30,
        )
    )
    camera_queue.start_workers()

# â”€â”€â”€ Main Entrypoint â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    uvicorn.run(
        "app.main:app",
        host="0.0.0.0",
        port=int(os.getenv("PORT", 3000)),
        log_level=os.getenv("LOG_LEVEL", "info"),
        reload=os.getenv("DEBUG", "false").lower() == "true",
    )


----- app/dependencies.py -----
# app/dependencies.py
from datetime import datetime, timezone
import os
import jwt
from fastapi import Depends, HTTPException, status
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from fastapi.security import OAuth2PasswordBearer
from sqlalchemy.future import select
from app.models import ActivationKey, CameraToken, Device, Subscription, SubscriptionPlan, User, Admin
from app.core.database import get_db
bearer_scheme = HTTPBearer() 
oauth2_scheme = OAuth2PasswordBearer(tokenUrl="/api/v1/auth/login")
ALGORITHM = "HS256"
async def get_current_user(token: str = Depends(oauth2_scheme), db=Depends(get_db)):
    SECRET_KEY = os.getenv("SECRET_KEY", "your-default-secret")
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=["HS256"])
        user_id = payload.get("user_id")
        if user_id is None:
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail="Invalid authentication credentials"
            )
        result = await db.execute(select(User).where(User.id == user_id))
        user = result.unique().scalar_one_or_none()
        if user is None:
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail="User not found"
            )
        return user
    except jwt.PyJWTError:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Could not validate credentials"
        )

async def get_current_admin(
    token: str = Depends(oauth2_scheme),
    db=Depends(get_db),
):
    """
    Dependency that verifies the bearer token belongs to an Admin.
    """
    SECRET_KEY = os.getenv("SECRET_KEY", "your-default-secret")
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
        admin_id = payload.get("user_id")
        if admin_id is None:
            raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail="Invalid authentication credentials")

        result = await db.execute(select(Admin).where(Admin.id == admin_id))
        admin = result.unique().scalar_one_or_none()
        if not admin or admin.role != "superadmin":
            raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail="Admin privileges required")

        return admin
    except jwt.PyJWTError:
        raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail="Could not validate credentials")


async def get_current_device(
    creds: HTTPAuthorizationCredentials = Depends(bearer_scheme),
    db=Depends(get_db),
):
    key = creds.credentials
    ak = await db.scalar(select(ActivationKey).where(ActivationKey.key == key))
    if not ak or not ak.redeemed:
        raise HTTPException(status_code=401, detail="Invalid or unâ€‘redeemed device key")
    device = await db.get(Device, ak.redeemed_device_id)
    if not device:
        raise HTTPException(status_code=404, detail="Device not found")
    # check subscription
    now = datetime.now(timezone.utc)
    sub = await db.scalar(
      select(Subscription)
      .where(
        Subscription.device_id == device.id,
        Subscription.active == True,
        Subscription.start_date <= now,
        Subscription.end_date >= now
      )
    )
    if not sub:
        raise HTTPException(status_code=403, detail="No active subscription")
    plan = await db.get(SubscriptionPlan, sub.plan_id)
    if device.type.value not in plan.device_types:
        raise HTTPException(status_code=403, detail="Plan does not cover this device type")
    return device

async def verify_camera_token(
        
    creds: HTTPAuthorizationCredentials = Depends(HTTPBearer()),
    db = Depends(get_db),
):
    result = await db.execute(select(CameraToken)
        .where(CameraToken.token == creds.credentials))
    row = result.scalar_one_or_none()
    if not row:
        raise HTTPException(401, "Invalid camera token")
    return row.camera_id

----- app/routers/auth.py -----
# app/routers/auth.py
from fastapi import APIRouter, HTTPException, Depends
from fastapi.security import OAuth2PasswordRequestForm
from app.models import User
from app.core.database import get_db
from sqlalchemy.future import select
import jwt  # This is from PyJWT
import os
import datetime
from passlib.context import CryptContext
from app.schemas import UserCreate, UserResponse 

router = APIRouter()
pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")
SECRET_KEY = os.getenv("SECRET_KEY", "your-default-secret")
ALGORITHM = "HS256"

def verify_password(plain_password, hashed_password):
    return pwd_context.verify(plain_password, hashed_password)

def get_password_hash(password):
    return pwd_context.hash(password)

@router.post("/login")
async def login(form_data: OAuth2PasswordRequestForm = Depends(), db=Depends(get_db)):
    # Retrieve user by email
    result = await db.execute(select(User).where(User.email == form_data.username))
    user = result.unique().scalar_one_or_none()
    if not user or not verify_password(form_data.password, user.hashed_password):
        raise HTTPException(status_code=400, detail="Invalid credentials")
    
    token_data = {
        "user_id": user.id,
        "role": user.role,
        "exp": datetime.datetime.utcnow() + datetime.timedelta(hours=1)
    }
    token = jwt.encode(token_data, SECRET_KEY, algorithm=ALGORITHM)
    return {"access_token": token, "token_type": "bearer"}

@router.post("/signup", response_model=UserResponse)
async def signup(user_create: UserCreate, db=Depends(get_db)):
    # Check if email exists
    result = await db.execute(select(User).where(User.email == user_create.email))
    if result.unique().scalar_one_or_none():
        raise HTTPException(status_code=400, detail="Email already registered")
    
    hashed_pw = get_password_hash(user_create.password)
    user = User(email=user_create.email, hashed_password=hashed_pw, role="user")
    db.add(user)
    await db.commit()
    await db.refresh(user)
    from app.models import UserProfile
    profile = UserProfile(
        user_id    = user.id,
        first_name = user_create.first_name,
        last_name  = user_create.last_name,
        phone      = user_create.phone,
        address    = user_create.address,
        city       = user_create.city,
        state      = user_create.state,
        country    = user_create.country,
        postal_code= user_create.postal_code
    )
    db.add(profile)
    await db.commit()
    await db.refresh(profile)
    await db.refresh(user)
    return user


----- app/routers/payments.py -----
# app/routers/payments.py

from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.future import select
from app.core.database import get_db
from app.dependencies import get_current_user, get_current_admin
from app.models import PaymentOrder, SubscriptionPlan, Subscription, PaymentStatus
from app.schemas import (
    CreatePaymentRequest,
    ConfirmPaymentRequest,
    PaymentOrderResponse
)
import segno
from pathlib import Path
from datetime import datetime, timedelta

router = APIRouter(prefix="/api/v1/payments", tags=["payments"])
admin_router = APIRouter(
    prefix="/admin/payments",
    tags=["admin-payments"],
    dependencies=[Depends(get_current_admin)]
)

# Where to save QR images
QR_DIR = Path("app/static/qr_codes")
QR_DIR.mkdir(parents=True, exist_ok=True)

@router.post("/create", response_model=PaymentOrderResponse, status_code=status.HTTP_201_CREATED)
async def create_payment(
    req: CreatePaymentRequest,
    db: AsyncSession = Depends(get_db),
    user = Depends(get_current_user),
):
    # 1) Validate plan & device
    plan = await db.get(SubscriptionPlan, req.plan_id)
    if not plan:
        raise HTTPException(404, "Plan not found")
    # you could also verify device belongs to user if needed

    # 2) Create the order
    order = PaymentOrder(
        user_id      = user.id,
        device_id    = req.device_id,
        plan_id      = plan.id,
        amount_cents = plan.price_cents,
    )
    db.add(order)
    await db.commit()
    await db.refresh(order)

    # 3) Generate UPI URL & QR
    upi_url = (
        f"upi://pay?"
        f"pa=your-upi-id@bank&"
        f"pn=Hydroleaf&"
        f"am={order.amount_cents/100:.2f}&"
        f"cu=INR&"
        f"tn={order.id}"
    )
    qr = segno.make(upi_url)
    qr_file = QR_DIR / f"order_{order.id}.png"
    qr.save(str(qr_file), scale=5, border=1)

    # 4) Respond with the QR code URL
    resp = PaymentOrderResponse.from_orm(order)
    resp.qr_code_url = f"/static/qr_codes/order_{order.id}.png"
    return resp

@router.post("/confirm/{order_id}", response_model=PaymentOrderResponse)
async def confirm_payment(
    order_id: int,
    req: ConfirmPaymentRequest,
    db: AsyncSession = Depends(get_db),
    user = Depends(get_current_user),
):
    order = await db.get(PaymentOrder, order_id)
    if not order or order.user_id != user.id:
        raise HTTPException(404, "Order not found")
    if order.status != PaymentStatus.PENDING:
        raise HTTPException(400, "Cannot confirm order in its current status")

    order.upi_transaction_id = req.upi_transaction_id
    order.status             = PaymentStatus.PROCESSING
    await db.commit()
    await db.refresh(order)
    resp = PaymentOrderResponse.from_orm(order)
    resp.qr_code_url = f"/static/qr_codes/order_{order.id}.png"
    return resp

@admin_router.get("/", response_model=list[PaymentOrderResponse])
async def list_orders(db: AsyncSession = Depends(get_db)):
    result = await db.execute(select(PaymentOrder))
    orders = result.scalars().all()
    return [PaymentOrderResponse.from_orm(o) for o in orders]

@admin_router.post("/approve/{order_id}", response_model=PaymentOrderResponse)
async def approve_payment(
    order_id: int,
    db: AsyncSession = Depends(get_db),
):
    order = await db.get(PaymentOrder, order_id)
    if not order:
        raise HTTPException(404, "Order not found")
    if order.status != PaymentStatus.PROCESSING:
        raise HTTPException(400, "Order not ready for approval")

    # 1) Mark completed
    order.status = PaymentStatus.COMPLETED

    # 2) Create the subscription
    now = datetime.utcnow()
    plan = await db.get(SubscriptionPlan, order.plan_id)
    sub = Subscription(
        user_id    = order.user_id,
        device_id  = order.device_id,
        plan_id    = plan.id,
        start_date = now,
        end_date   = now + timedelta(days=plan.duration_days),
        active     = True
    )
    db.add(sub)

    await db.commit()
    await db.refresh(order)

    resp = PaymentOrderResponse.from_orm(order)
    resp.qr_code_url = f"/static/qr_codes/order_{order.id}.png"
    return resp


----- app/routers/config.py -----
# app/routers/config.py

from fastapi import APIRouter, HTTPException, Depends
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.future import select
from typing import List
from sqlalchemy import select, func
from app.core.database import get_db
from app.schemas import (
    DosingProfileCreate,
    DosingProfileResponse,
    DeviceType,
    PlantCreate,
    PlantResponse
)
from app.models import Device, DosingOperation, DosingProfile, Plant, SensorReading

router = APIRouter()

@router.get("/system-info", summary="Get system information")
async def get_system_info(db: AsyncSession = Depends(get_db)):
    """Get system configuration and status using unified device counts"""
    dosing_count = await db.scalar(
        select(func.count()).select_from(Device).where(Device.type == DeviceType.DOSING_UNIT)
    )
    sensor_count = await db.scalar(
        select(func.count()).select_from(Device).where(
            Device.type.in_([DeviceType.PH_TDS_SENSOR, DeviceType.ENVIRONMENT_SENSOR])
        )
    )
    
    return {
        "version": "1.0.0",
        "device_count": {
            "dosing": dosing_count or 0,
            "sensors": sensor_count or 0
        }
    }

@router.post("/dosing-profile", response_model=DosingProfileResponse)
async def create_dosing_profile(
    profile: DosingProfileCreate,
    db: AsyncSession = Depends(get_db)
):
    """Create a new dosing profile for a device"""
    result = await db.execute(
        select(Device).where(Device.id == profile.device_id)
    )
    device = result.scalar_one_or_none()
    if not device:
        raise HTTPException(status_code=404, detail="Device not found")
    
    # Ensure the device is a dosing unit (unified device)
    if device.type != DeviceType.DOSING_UNIT:
        raise HTTPException(
            status_code=400,
            detail="Dosing profiles can only be created for dosing units"
        )

    new_profile = DosingProfile(**profile.model_dump())
    db.add(new_profile)
    try:
        await db.commit()
        await db.refresh(new_profile)
        if new_profile.updated_at is None:
            new_profile.updated_at = new_profile.created_at
        return new_profile
    except Exception as exc:
        await db.rollback()
        raise HTTPException(
            status_code=500,
            detail=f"Error creating dosing profile: {exc}"
        )

@router.get("/dosing-profiles/{device_id}", response_model=List[DosingProfileResponse])
async def get_device_profiles(
    device_id: str,
    db: AsyncSession = Depends(get_db)
):
    """Get all dosing profiles for a device"""
    device = await db.scalar(
        select(Device).where(Device.id == device_id)
    )
    if not device:
        raise HTTPException(status_code=404, detail="Device not found")

    result = await db.execute(
        select(DosingProfile)
        .where(DosingProfile.device_id == device_id)
        .order_by(DosingProfile.created_at.desc())
    )
    profiles = result.scalars().all()
    return profiles

@router.delete("/dosing-profiles/{profile_id}")
async def delete_dosing_profile(
    profile_id: int,
    db: AsyncSession = Depends(get_db)
):
    """Delete a dosing profile"""
    profile = await db.get(DosingProfile, profile_id)
    if not profile:
        raise HTTPException(status_code=404, detail="Profile not found")
    
    try:
        await db.delete(profile)
        await db.commit()
        return {"message": "Profile deleted successfully"}
    except Exception as exc:
        await db.rollback()
        raise HTTPException(
            status_code=500,
            detail=f"Error deleting profile: {exc}"
        )


----- app/routers/users.py -----
    # app/routers/users.py
from fastapi import APIRouter, HTTPException, Depends
from app.dependencies import get_current_user
from app.models import User
from app.core.database import get_db
from app.schemas import UserResponse, UserUpdate  # reuse the already defined UserUpdate from schemas.py
from sqlalchemy.future import select

router = APIRouter(prefix="/api/v1/users", tags=["users"])

@router.get("/me", response_model=UserResponse)
async def get_my_profile(current_user: User = Depends(get_current_user)):
    return current_user

@router.put("/me", response_model=UserResponse)
async def update_my_profile(update: UserUpdate, db=Depends(get_db), current_user: User = Depends(get_current_user)):
    # Allow updating only permitted fields (e.g. email).
    if update.email:
        current_user.email = update.email
    profile = current_user.profile
    for field, value in update.dict(exclude_unset=True, exclude={"email","role"}).items():
        setattr(profile, field, value)
    # Do NOT allow role change by the user.
    db.add(current_user)
    await db.commit()
    await db.refresh(current_user)
    return current_user


----- app/routers/cloud.py -----
# app/routers/cloud.py
"""
Cloud-key management & device authentication.

â€¢ Every generated key is stored in the `cloud_keys` table (latest row is current).
â€¢ Keys survive process restarts and are shared across all workers.
â€¢ `/authenticate` simply checks the supplied key and returns a random token.
"""

from __future__ import annotations

import logging
import secrets
from datetime import timezone, datetime

from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy import select, func
from sqlalchemy.ext.asyncio import AsyncSession

from app.schemas import (
    CloudAuthenticationRequest,
    CloudAuthenticationResponse,
    DosingCancellationRequest,
)
from app.dependencies import get_current_admin
from app.core.database import get_db
from app.models import Base, CameraToken, User
from sqlalchemy import Column, Integer, String, DateTime
from app.models import CloudKey
logger = logging.getLogger(__name__)
router = APIRouter()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2.  Helper â€“ fetch the newest key
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def _get_current_key(db: AsyncSession) -> str | None:
    row = await db.scalar(
        select(CloudKey).order_by(CloudKey.id.desc()).limit(1)
    )
    return row.key if row else None


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3.  Public endpoints
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@router.post("/authenticate", response_model=CloudAuthenticationResponse)
async def authenticate_cloud(
    payload: CloudAuthenticationRequest,
    db: AsyncSession = Depends(get_db),
):
    """
    Device â†’ cloud authentication.

    A device posts `{device_id, cloud_key}`.
    If the key matches the latest one generated by an admin, return a token.
    """
    current_key = await _get_current_key(db)
    if payload.cloud_key != current_key:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Invalid cloud key",
        )

    token = secrets.token_hex(16)  # (replace with JWT if needed)
    db.add(CameraToken(camera_id=payload.device_id, token=token))
    logger.info(
        "Device %s authenticated OK â€“ issued token %s", payload.device_id, token
    )
    return CloudAuthenticationResponse(
        token=token,
        message="Authentication successful",
    )


@router.post("/verify_key")
async def verify_cloud_key(
    payload: CloudAuthenticationRequest,
    db: AsyncSession = Depends(get_db),
):
    """
    Quick check used by devices/portal: â€œis this key still valid?â€.
    """
    if payload.cloud_key == await _get_current_key(db):
        return {"status": "valid", "message": "Cloud key is valid"}
    raise HTTPException(status_code=401, detail="Invalid cloud key")


@router.post("/dosing_cancel")
async def dosing_cancel(request: DosingCancellationRequest):
    """
    Webhook target for a device reporting a cancelled dosing event.
    """
    if request.event != "dosing_cancelled":
        raise HTTPException(400, "Invalid event type")
    logger.info("Dosing cancelled â€“ device=%s", request.device_id)
    return {"message": "Dosing cancellation received", "device_id": request.device_id}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4.  Admin endpoints
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@router.post(
    "/admin/generate_cloud_key",
    dependencies=[Depends(get_current_admin)],
)
@router.post("/admin/generate_cloud_key", dependencies=[Depends(get_current_admin)])
async def generate_cloud_key(
    db: AsyncSession = Depends(get_db),
    admin: User = Depends(get_current_admin),   # â† get the actual admin user
    ):
    new_key = secrets.token_hex(16)
    cloud_key = CloudKey(key=new_key, created_by=admin.id)
    db.add(cloud_key)
    await db.commit()
    logger.info("New cloud key generated: %s", new_key)
    return {"cloud_key": new_key}


----- app/routers/admin_users.py -----
# app/routers/admin_users.py
from fastapi import APIRouter, HTTPException, Depends, status
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.future import select
from typing import List
import datetime
import os
import jwt
from sqlalchemy.orm import joinedload
from app.models import User
from app.core.database import get_db
from app.dependencies import get_current_admin
from app.schemas import UserResponse, UserUpdate

router = APIRouter(prefix="/admin/users", tags=["admin", "users"])

@router.get("/", response_model=List[UserResponse])
async def list_users(
    db: AsyncSession = Depends(get_db),
    admin: User = Depends(get_current_admin),
):
    """
    Admin-only endpoint to list all users (including their devices).
    """
    # 1) construct the query
    stmt = select(User).options(joinedload(User.devices))

    # 2) execute it
    result = await db.execute(stmt)

    # 3) collapse duplicate User rows (one per device)
    result = result.unique()

    # 4) extract the User objects
    users = result.scalars().all()

    return users

    

@router.get("/{user_id}", response_model=UserResponse)
async def get_user(
    user_id: int,
    db: AsyncSession = Depends(get_db),
    admin: User = Depends(get_current_admin)
):
    """
    Admin-only endpoint to get details of a specific user.
    """
    user = await db.get(User, user_id)
    if not user:
        raise HTTPException(status_code=404, detail="User not found")
    return user

@router.put("/{user_id}", response_model=UserResponse)
async def update_user(
    user_id: int,
    user_update: UserUpdate,
    db: AsyncSession = Depends(get_db),
    admin: User = Depends(get_current_admin)
):
    """
    Admin-only endpoint to update a user's email or role.
    """
    user = await db.get(User, user_id)
    if not user:
        raise HTTPException(status_code=404, detail="User not found")
    
    if user_update.email is not None:
        user.email = user_update.email
    if user_update.role is not None:
        user.role = user_update.role

    db.add(user)
    await db.commit()
    await db.refresh(user)
    return user

@router.delete("/{user_id}")
async def delete_user(
    user_id: int,
    db: AsyncSession = Depends(get_db),
    admin: User = Depends(get_current_admin)
):
    """
    Admin-only endpoint to delete a user.
    """
    user = await db.get(User, user_id)
    if not user:
        raise HTTPException(status_code=404, detail="User not found")
    
    await db.delete(user)
    await db.commit()
    return {"detail": "User deleted successfully"}

@router.post("/impersonate/{user_id}")
async def impersonate_user(
    user_id: int,
    db: AsyncSession = Depends(get_db),
    admin: User = Depends(get_current_admin)
):
    """
    Admin-only endpoint to switch context and impersonate another user.
    Returns a new JWT token for the target user.
    """
    user = await db.get(User, user_id)
    if not user:
        raise HTTPException(status_code=404, detail="User not found")
    
    SECRET_KEY = os.getenv("SECRET_KEY", "your-default-secret")
    ALGORITHM = "HS256"
    token_data = {
        "user_id": user.id,
        "role": user.role,
        "impersonated_by": admin.id,  # For audit purposes
        "exp": datetime.datetime.utcnow() + datetime.timedelta(hours=1)
    }
    token = jwt.encode(token_data, SECRET_KEY, algorithm=ALGORITHM)
    return {
        "access_token": token,
        "token_type": "bearer",
        "impersonated_user": user.email
    }


----- app/routers/admin_subscriptions.py -----
from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.future import select
import secrets

from app.models import ActivationKey, SubscriptionPlan, Device, User
from app.schemas import DeviceType, ActivationKeyResponse
from app.dependencies import get_current_admin
from app.core.database import get_db

router = APIRouter(prefix="/admin", tags=["admin"])

@router.post(
    "/generate_device_activation_key",
    response_model=ActivationKeyResponse,
    status_code=status.HTTP_201_CREATED,
    dependencies=[Depends(get_current_admin)]
)
async def generate_device_activation_key(
    device_id: str,
    plan_id: int,
    db: AsyncSession = Depends(get_db),
    admin: User = Depends(get_current_admin),
):

    # 1) Validate device exists
    device = await db.get(Device, device_id)
    if not device:
        raise HTTPException(status_code=404, detail="Device not found")
    # 2) Validate plan exists & covers this type
    plan = await db.get(SubscriptionPlan, plan_id)
    if not plan:
        raise HTTPException(status_code=404, detail="Plan not found")
    if device.type.value not in plan.device_types:
        raise HTTPException(
            status_code=400,
            detail=f"Plan does not support device type {device.type.value}"
        )
    # 3) Mint & store key
    key = secrets.token_urlsafe(32)
    ak = ActivationKey(
        key=key,
        device_type=device.type,
        plan_id=plan.id,
        created_by=admin.id,
        allowed_device_id=device.id,
    )
    db.add(ak)
    await db.commit()
    return {"activation_key": key}


----- app/routers/plants.py -----
from fastapi import APIRouter, Depends, HTTPException
from fastapi.logger import logger
from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession
from typing import List
from app.schemas import DosingOperation, PlantCreate, PlantResponse, SensorReading
from app.core.database import get_db
from app.services.plant_service import (
    get_all_plants,
    get_plant_by_id,
    create_plant,
    delete_plant
)
from app.models import Plant

router = APIRouter()

@router.get("/plants", response_model=List[PlantResponse])
async def fetch_all_plants(db: AsyncSession = Depends(get_db)):
    """Retrieve all plant profiles"""
    plants = await get_all_plants(db)
    return plants 

@router.get("/plants/{plant_id}", response_model=PlantResponse)
async def fetch_plant(plant_id: int, db: AsyncSession = Depends(get_db)):
    """Retrieve a plant by ID."""
    return await get_plant_by_id(plant_id, db)

@router.post("/", response_model=PlantResponse)
async def add_plant(plant: PlantCreate, db: AsyncSession = Depends(get_db)):
    """Create a new plant."""
    return await create_plant(plant, db)

@router.delete("/plants/{plant_id}")
async def remove_plant(plant_id: int, db: AsyncSession = Depends(get_db)):
    """Delete a plant by ID."""
    return await delete_plant(plant_id, db)

@router.post("/execute-dosing/{plant_id}", response_model=DosingOperation)
async def execute_dosing(plant_id: int, db: AsyncSession = Depends(get_db)):
    """
    Execute a dosing operation by checking the latest sensor readings and applying the correct amount of nutrients.
    
    **Note:** This endpoint expects the Plant object to have dosing parameters
    (`target_ph_min`, `target_ph_max`, `target_tds_min`, and `target_tds_max`). 
    If these are not configured, the endpoint returns a 400 error.
    """
    plant = await db.get(Plant, plant_id)
    if not plant:
        raise HTTPException(status_code=404, detail="Plant Profile not found")
    
    # Ensure the plant has dosing parameters.
    for attr in ("target_ph_min", "target_ph_max", "target_tds_min", "target_tds_max"):
        if not hasattr(plant, attr):
            raise HTTPException(status_code=400, detail="Plant dosing parameters not configured")
    
    target_ph_min = getattr(plant, "target_ph_min")
    target_ph_max = getattr(plant, "target_ph_max")
    target_tds_min = getattr(plant, "target_tds_min")
    target_tds_max = getattr(plant, "target_tds_max")
    
    # Get latest sensor readings for the plant's location.
    readings_result = await db.execute(
        select(SensorReading)
        .where(SensorReading.location == plant.location)
        .order_by(SensorReading.timestamp.desc())
    )
    latest_readings = readings_result.scalars().all()
    if not latest_readings:
        raise HTTPException(status_code=400, detail="No sensor readings available")
    
    # Extract pH and TDS values.
    ph = next((r.value for r in latest_readings if r.reading_type == "ph"), None)
    tds = next((r.value for r in latest_readings if r.reading_type == "tds"), None)
    if ph is None or tds is None:
        raise HTTPException(status_code=400, detail="Missing pH or TDS readings")
    
    # Determine dosing actions based on the plantâ€™s dosing parameters.
    actions = []
    if ph < target_ph_min:
        actions.append({"pump": 1, "dose_ml": 10, "reasoning": "Increase pH"})
    elif ph > target_ph_max:
        actions.append({"pump": 2, "dose_ml": 10, "reasoning": "Decrease pH"})
    
    if tds < target_tds_min:
        actions.append({"pump": 3, "dose_ml": 5, "reasoning": "Increase nutrients"})
    elif tds > target_tds_max:
        actions.append({"pump": 4, "dose_ml": 5, "reasoning": "Decrease nutrients"})
    
    return {"plant_id": plant_id, "actions": actions}


----- app/routers/subscriptions.py -----
# app/routers/subscriptions.py
from typing import List
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.future import select
from sqlalchemy.ext.asyncio import AsyncSession
from datetime import datetime, timedelta

from app.models import ActivationKey, Subscription, SubscriptionPlan, Device
from app.schemas import SubscriptionPlanResponse, SubscriptionResponse  # youâ€™ll need to define this
from app.dependencies import get_current_user
from app.core.database import get_db

router = APIRouter(prefix="/api/v1/subscriptions", tags=["subscriptions"])

@router.post("/redeem", response_model=SubscriptionResponse)
async def redeem_key(
    activation_key: str,
    device_id: str,
    db: AsyncSession = Depends(get_db),
    current_user=Depends(get_current_user),
):
    # 1) fetch & validate key
    ak = await db.scalar(
        select(ActivationKey).where(
            ActivationKey.key == activation_key,
            ActivationKey.redeemed == False
        )
    )
    if not ak:
        raise HTTPException(400, "Invalid or alreadyâ€used activation key")

    # 2) fetch & validate device
    device = await db.get(Device, device_id)
    if ak.allowed_device_id and ak.allowed_device_id != device_id:
        raise HTTPException(400, "This key is not valid for that device")
    device = await db.get(Device, device_id)

    if not device or device.type != ak.device_type:
        raise HTTPException(400, "Key does not match this device type")

    # 3) mark the key redeemed
    ak.redeemed       = True
    ak.redeemed_at    = datetime.utcnow()  # â† now we record when
    ak.redeemed_user_id   = current_user.id
    ak.redeemed_device_id = device_id

    # 4) create a Subscription
    plan = await db.get(SubscriptionPlan, ak.plan_id)
    start = datetime.utcnow()
    end = start + timedelta(days=plan.duration_days)
    device.user_id = current_user.id
    device.is_active = True
    sub = Subscription(
        user_id=current_user.id,
        device_id=device_id,
        plan_id=plan.id,
        start_date=start,
        end_date=end,
        active=True
    )
    db.add_all([ak, sub, device])
    await db.commit()
    await db.refresh(sub)
    return sub

@router.get("/plans", response_model=List[SubscriptionPlanResponse])
async def list_plans(
    db: AsyncSession = Depends(get_db),
    _ = Depends(get_current_user)   # any logged-in user may browse plans
):
    result = await db.execute(select(SubscriptionPlan))
    return result.scalars().all()

@router.get("/", response_model=List[SubscriptionResponse])
async def list_my_subscriptions(
    db: AsyncSession = Depends(get_db),
    current_user=Depends(get_current_user),
):
    result = await db.execute(
        select(Subscription).where(Subscription.user_id == current_user.id)
    )
    return result.scalars().all()

----- app/routers/dosing.py -----
from fastapi import APIRouter, HTTPException, Depends
from fastapi.logger import logger
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.future import select
from typing import List
from datetime import datetime, UTC
from pydantic import BaseModel
from app.schemas import DeviceType 
from app.core.database import get_db
from app.schemas import (
    DosingOperation,
    DosingProfileResponse,
    DosingProfileCreate
)
from app.models import Device, DosingProfile
from app.services.dose_manager import execute_dosing_operation, cancel_dosing_operation
from app.services.dosing_profile_service import set_dosing_profile_service

router = APIRouter()

@router.post("/execute/{device_id}", response_model=DosingOperation)
async def execute_dosing(
    device_id: str,
    db: AsyncSession = Depends(get_db)
):
    """
    Execute a dosing operation for a device using its HTTP endpoint.
    """
    device = await db.get(Device, device_id)
    if not device:
        raise HTTPException(status_code=404, detail="Device not found")
    if device.type != DeviceType.DOSING_UNIT:
        raise HTTPException(status_code=400, detail="Device is not a dosing unit")
    
    try:
        # Use the device's HTTP endpoint and pump configurations to execute the dosing operation
        result = await execute_dosing_operation(device_id, device.http_endpoint, device.pump_configurations)
        return result
    except Exception as exc:
        raise HTTPException(
            status_code=500,
            detail=f"Error executing dosing operation: {exc}"
        )

@router.post("/cancel/{device_id}")
async def cancel_dosing(
    device_id: str,
    db: AsyncSession = Depends(get_db)
):
    """
    Cancel an active dosing operation for a device.
    """
    device = await db.get(Device, device_id)
    if not device:
        raise HTTPException(status_code=404, detail="Device not found")
    
    try:
        result = await cancel_dosing_operation(device_id, device.http_endpoint)
        return result
    except Exception as exc:
        raise HTTPException(status_code=500, detail=f"Error cancelling dosing operation: {exc}")


@router.get("/history/{device_id}", response_model=List[DosingOperation])
async def get_dosing_history(
    device_id: str,
    session: AsyncSession = Depends(get_db)
):
    """
    Retrieve the dosing history for a device.
    """
    try:
        result = await session.execute(
            select(Device).where(Device.id == device_id)
        )
        device = result.scalar_one_or_none()
        if not device:
            raise HTTPException(status_code=404, detail="Device not found")

        # Import the DosingOperation model from app.models to query the history
        from app.models import DosingOperation as ModelDosingOperation
        result = await session.execute(
            select(ModelDosingOperation)
            .where(ModelDosingOperation.device_id == device_id)
            .order_by(ModelDosingOperation.timestamp.desc())
        )
        operations = result.scalars().all()
        return operations
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Error fetching dosing history: {str(e)}"
        )

@router.post("/profile", response_model=DosingProfileResponse)
async def create_dosing_profile(
    profile: DosingProfileCreate,
    db: AsyncSession = Depends(get_db)
):
    """
    Create a new dosing profile for a dosing device.
    """
    result = await db.execute(
        select(Device).where(Device.id == profile.device_id)
    )
    device = result.scalar_one_or_none()
    if not device:
        raise HTTPException(status_code=404, detail="Device not found")
    if device.type != DeviceType.DOSING_UNIT:
        raise HTTPException(
            status_code=400,
            detail="Dosing profiles can only be created for dosing units"
        )

    now = datetime.now(UTC)
    new_profile = DosingProfile(
        **profile.model_dump(),
        created_at=now,
        updated_at=now
    )
    
    db.add(new_profile)
    await db.commit()
    await db.refresh(new_profile)
    return new_profile

# New endpoint to handle the LLM dosing flow
class LlmDosingRequest(BaseModel):
    sensor_data: dict
    plant_profile: dict

@router.post("/llm-request")
async def llm_dosing_request(
    device_id: str,
    request: LlmDosingRequest,
    db: AsyncSession = Depends(get_db)
):
    """
    Process a dosing request using sensor data and plant profile to generate a dosing plan via LLM.
    """
    try:
        # Verify device exists
        device = await db.get(Device, device_id)
        if not device:
            raise HTTPException(status_code=404, detail="Device not found")

        # Process the dosing request
        from app.services.llm import process_dosing_request
        result,raw = await process_dosing_request(device_id, request.sensor_data, request.plant_profile, db)

        return result,raw

    except HTTPException as he:
        raise he  # Allow already handled errors to propagate correctly

    except Exception as exc:
        logger.exception(f"Unexpected error in /llm-request: {exc}")
        raise HTTPException(status_code=500, detail="Internal Server Error")

class llmPlaningRequest(BaseModel):
    sensor_data: dict
    plant_profile: dict
    query: str

@router.post("/llm-plan")
async def llm_plan(
    device_id: str,
    request: llmPlaningRequest,
    db: AsyncSession= Depends(get_db)
): 
    """
    PROCESS A DOSING PLAN ACCORDING TO GIVEN REGION CLIMATE
    """

    try:
        # Verify device exists
        device = await db.get(Device, device_id)
        if not device:
            raise HTTPException(status_code=404, detail="Device not found")

        # Process the dosing request
        from app.services.llm import process_sensor_plan
        result= await process_sensor_plan(device_id, request.sensor_data, request.plant_profile, request.query, db)

        return result

    except HTTPException as he:
        raise he  # Allow already handled errors to propagate correctly

    except Exception as exc:
        logger.exception(f"Unexpected error in /llm-request: {exc}")
        raise HTTPException(status_code=500, detail="Internal Server Error")


class DosingProfileServiceRequest(BaseModel):
    device_id: str
    device_ip: str | None = None
    plant_name: str
    plant_type: str
    growth_stage: str
    seeding_date: datetime
    target_ph_min: float
    target_ph_max: float
    target_tds_min: float
    target_tds_max: float
    dosing_schedule: dict


@router.post("/unified-dosing", summary="Create profile with unified sensor + LLM")
async def unified_dosing_profile(
    request: DosingProfileServiceRequest,
    db: AsyncSession = Depends(get_db)
):
    """
    Unified sensor + LLM dosing profile creation.
    Uses sensor data from device and generates profile + dose via LLM.
    """
    try:
        profile_data = request.model_dump()
        result = await set_dosing_profile_service(profile_data, db)
        return result
    except HTTPException as he:
        raise he
    except Exception as e:
        logger.exception(f"Unexpected error in /unified-dosing: {e}")
        raise HTTPException(status_code=500, detail="Internal Server Error")


----- app/routers/__init__.py -----
# app/routers/__init__.py

from .devices       import router as devices_router
from .dosing        import router as dosing_router
from .config        import router as config_router
from .plants        import router as plants_router
from .supply_chain  import router as supply_chain_router
from .farms         import router as farms_router
from .cloud         import router as cloud_router
from .auth          import router as auth_router
from .users         import router as users_router
from .admin_users   import router as admin_users_router
from .device_comm   import router as device_comm_router
from .admin         import router as admin_router
from .cameras       import router as cameras_router
# in routers/__init__.py
from .subscriptions import router as subscriptions_router
from .admin_subscriptions import router as admin_subscriptions_router

__all__ = [
    "devices_router", "dosing_router", "config_router", "plants_router",
    "supply_chain_router", "farms_router", "cloud_router", "auth_router",
    "users_router", "admin_users_router", "device_comm_router",
    "heartbeat_router", "admin_router", "cameras_router","subscriptions_router","admin_subscriptions_router"
]


----- app/routers/farms.py -----
# app/routers/farms.py
from fastapi import APIRouter, HTTPException, Depends
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.future import select
from typing import List
from app.core.database import get_db
from app.models import Farm, User
from app.schemas import FarmCreate, FarmResponse
from app.dependencies import get_current_user

router = APIRouter(tags=["farms"])

@router.post("/", response_model=FarmResponse)
async def create_farm(farm: FarmCreate, db: AsyncSession = Depends(get_db), current_user: User = Depends(get_current_user)):
    new_farm = Farm(user_id=current_user.id, name=farm.name, location=farm.location)
    db.add(new_farm)
    await db.commit()
    await db.refresh(new_farm)
    return new_farm

@router.get("/", response_model=List[FarmResponse])
async def list_farms(db: AsyncSession = Depends(get_db), current_user: User = Depends(get_current_user)):
    result = await db.execute(select(Farm).where(Farm.user_id == current_user.id))
    return result.scalars().all()

@router.get("/{farm_id}", response_model=FarmResponse)
async def get_farm(farm_id: int, db: AsyncSession = Depends(get_db), current_user: User = Depends(get_current_user)):
    farm = await db.get(Farm, farm_id)
    if not farm or farm.user_id != current_user.id:
        raise HTTPException(status_code=404, detail="Farm not found")
    return farm

@router.delete("/{farm_id}")
async def delete_farm(farm_id: int, db: AsyncSession = Depends(get_db), current_user: User = Depends(get_current_user)):
    farm = await db.get(Farm, farm_id)
    if not farm or farm.user_id != current_user.id:
        raise HTTPException(status_code=404, detail="Farm not found")
    await db.delete(farm)
    await db.commit()
    return {"detail": "Farm deleted successfully"}


----- app/routers/supply_chain.py -----
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.ext.asyncio import AsyncSession
from app.schemas import TransportRequest, SupplyChainAnalysisResponse
from app.core.database import get_db
from app.services.supply_chain_service import trigger_transport_analysis

router = APIRouter()

@router.post("/", response_model=SupplyChainAnalysisResponse)
async def analyze_supply_chain(request: TransportRequest, db: AsyncSession = Depends(get_db)):
    """
    Trigger the transport optimization analysis and return the results.
    """
    try:
        result = await trigger_transport_analysis(request.dict(), db)
        # result["analysis"] is the analysis record dictionary returned from our service
        return result["analysis"]
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


----- app/routers/admin.py -----
from fastapi import APIRouter
import asyncio
from app.services.device_discovery import get_connected_devices
from app.services.ping import ping_host

router = APIRouter(prefix="/admin", tags=["admin"])

@router.get("/devices")
async def list_connected_devices():
    devices = get_connected_devices()
    results = {}
    # For each registered device, ping its IP and return status along with last seen time.
    for device_id, info in devices.items():
        ip = info["ip"]
        reachable = await ping_host(ip)
        results[device_id] = {
            "ip": ip,
            "reachable": reachable,
            "last_seen": info["last_seen"]
        }
    return results


----- app/routers/cameras.py -----
from datetime import datetime, timedelta, timezone
import mimetypes
import asyncio
import time
from pathlib import Path

import numpy as np
import cv2
from fastapi import APIRouter, Depends, Request, BackgroundTasks, HTTPException
from fastapi.responses import FileResponse, StreamingResponse, JSONResponse
from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession

from app.core.config import CAM_EVENT_GAP_SECONDS, DATA_ROOT, RAW_DIR, CLIPS_DIR, BOUNDARY
from app.core.database import get_db
from app.dependencies import get_current_user, verify_camera_token
from app.models import Camera, DetectionRecord, DeviceCommand, User
from app.schemas import CameraReportResponse, DetectionRange
from app.utils.camera_tasks import encode_and_cleanup
from app.utils.camera_queue import camera_queue
router = APIRouter()

def current_user(request: Request, db=Depends(get_db)) -> User | None:
    uid = request.session.get("uid")
    if not uid:
        return None
    return db.query(User).get(uid)

async def _process_upload(
    camera_id: str,
    request: Request,
    background_tasks: BackgroundTasks,
    db: AsyncSession,
    day_flag: bool
) -> dict:
    # 1) Validate content-type
    content_type = request.headers.get("content-type", "")
    if not content_type.startswith("image/"):
        raise HTTPException(415, "Unsupported Media Type; expected image/jpeg")

    # 2) Read & decode
    raw_bytes = await request.body()
    arr = np.frombuffer(raw_bytes, dtype=np.uint8)
    frame = cv2.imdecode(arr, cv2.IMREAD_COLOR)
    if frame is None:
        raise HTTPException(400, "Invalid JPEG data")

    # 3) Day/night enhancement
    try:
        if day_flag:
            processed = _enhance_day(frame)
        else:
            processed = enhance_night(frame)
        ok, buf = cv2.imencode(".jpg", processed)
        image_bytes = buf.tobytes() if ok else raw_bytes
    except Exception:
        image_bytes = raw_bytes

    # 4) Save files
    base_dir = Path(DATA_ROOT) / camera_id
    raw_dir = base_dir / RAW_DIR
    raw_dir.mkdir(parents=True, exist_ok=True)
    latest_file = base_dir / "latest.jpg"

    ts = int(time.time() * 1000)
    (raw_dir / f"{ts}.jpg").write_bytes(image_bytes)
    latest_file.write_bytes(image_bytes)

    # 5) Update DB
    camera = await db.get(Camera, camera_id)
    if not camera:
        camera = Camera(id=camera_id, name=camera_id)
        db.add(camera)
    camera.is_online = True
    camera.last_seen = datetime.utcnow()
    await db.commit()

    # 6) Schedule encoding
    def _encode(cam: str):
        asyncio.run(encode_and_cleanup(cam))
    background_tasks.add_task(_encode, camera_id)

    # 7) Schedule YOLO detection
    # we pass the saved `latest.jpg` for detection
    latest_file = base_dir / "latest.jpg"
    # enqueue for async processing
    background_tasks.add_task(
        lambda cid, fp: asyncio.run(camera_queue.enqueue(cid, Path(fp))),
        camera_id, str(latest_file)
    )
    return {"ok": True, "ts": ts, "mode": "day" if day_flag else "night"}

@router.post("/upload/{camera_id}/day", dependencies=[Depends(verify_camera_token)])
async def upload_day_frame(
    camera_id: str, request: Request,
    background_tasks: BackgroundTasks,
    db: AsyncSession = Depends(get_db)
) -> dict:
    return await _process_upload(camera_id, request, background_tasks, db, day_flag=True)

@router.post("/upload/{camera_id}/night")
async def upload_night_frame(
    camera_id: str, request: Request,
    background_tasks: BackgroundTasks,
    db: AsyncSession = Depends(get_db)
) -> dict:
    return await _process_upload(camera_id, request, background_tasks, db, day_flag=False)

@router.get("/stream/{camera_id}", dependencies=[Depends(get_current_user)])
def mjpeg_stream(camera_id: str):
    cam_dir = Path(DATA_ROOT) / camera_id
    if not cam_dir.exists():
        raise HTTPException(404, "Camera not found")

    async def gen():
        last_mtime = 0
        while True:
            img_path = cam_dir / "latest.jpg"
            if img_path.exists():
                m = img_path.stat().st_mtime_ns
                if m != last_mtime:
                    last_mtime = m
                    data = img_path.read_bytes()
                    yield (
                        f"--{BOUNDARY}\r\n"
                        f"Content-Type: image/jpeg\r\n"
                        f"Content-Length: {len(data)}\r\n\r\n"
                    ).encode() + data + b"\r\n"
            await asyncio.sleep(0.05)

    return StreamingResponse(gen(),
        media_type=f"multipart/x-mixed-replace; boundary={BOUNDARY}")

@router.get("/still/{camera_id}")
def still(camera_id: str):
    p = Path(DATA_ROOT) / camera_id / "latest.jpg"
    if not p.exists():
        raise HTTPException(404, "Image not found")
    return FileResponse(p, media_type="image/jpeg")

@router.get("/api/clips/{camera_id}")
def list_clips(camera_id: str):
    clip_dir = Path(DATA_ROOT) / camera_id / CLIPS_DIR
    clips = sorted(clip_dir.glob("*.mp4"),
                   key=lambda p: p.stat().st_mtime, reverse=True)
    out = []
    for c in clips:
        ts = int(c.stem)
        out.append({
            "filename": c.name,
            "datetime": datetime.fromtimestamp(ts/1000, timezone.utc).isoformat(),
            "size_mb": round(c.stat().st_size / 1024**2, 2)
        })
    return JSONResponse(out)

@router.get("/clips/{camera_id}/{clip_name}")
def serve_clip(camera_id: str, clip_name: str):
    clip = Path(DATA_ROOT) / camera_id / CLIPS_DIR / clip_name
    if not clip.exists():
        raise HTTPException(404, "Clip not found")
    mime = mimetypes.guess_type(clip_name)[0] or "video/mp4"
    return FileResponse(clip, media_type=mime)

@router.get("/api/status/{camera_id}")
def cam_status(camera_id: str, db=Depends(get_db)):
    cam = db.query(Camera).get(camera_id)
    if not cam:
        raise HTTPException(404, "Camera not registered")
    return {"is_online": cam.is_online, "last_seen": cam.last_seen}

@router.get("/commands/{camera_id}", dependencies=[Depends(verify_camera_token)])
async def next_command(camera_id: str, db: AsyncSession = Depends(get_db)):
    cmd = await db.scalar(
        select(DeviceCommand)
        .where(DeviceCommand.device_id == camera_id, DeviceCommand.dispatched == False)
        .order_by(DeviceCommand.issued_at)
        .limit(1)
    )
    if not cmd:
        return {"command": None}
    cmd.dispatched = True
    await db.commit()
    return {"command": cmd.action, "parameters": cmd.parameters or {}}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Below: internal helpers for day & night enhancement
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _enhance_day(frame: np.ndarray) -> np.ndarray:
    """Apply mild color & contrast boost plus denoise for daytime."""
    # Convert to Lab color space
    lab = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    # CLAHE for contrast
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    cl = clahe.apply(l)
    lab = cv2.merge((cl, a, b))
    enhanced = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
    # Fast denoise
    return cv2.fastNlMeansDenoisingColored(enhanced, None, 4, 4, 7, 21)

def enhance_night(frame: np.ndarray) -> np.ndarray:
    """Enhance low-light frame (grayscale focus, noise reduction)."""
    # 1. Gamma Correction (brighten midtones)
    # Using a lower gamma to intensify brightness in dark areas.
    gamma = 0.5  # more aggressive brightening than 0.6
    inv_gamma = 1.0 / gamma
    # Create a lookup table for gamma correction
    table = np.array([( (i/255.0) ** inv_gamma ) * 255 for i in range(256)]).astype("uint8")
    bright = cv2.LUT(frame, table)  # apply gamma curve
    
    # 2. Convert to grayscale for contrast enhancement
    gray = cv2.cvtColor(bright, cv2.COLOR_BGR2GRAY)
    # Apply CLAHE (Adaptive histogram equalization) on the grayscale image
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    equalized = clahe.apply(gray)
    
    # 3. Merge enhanced grayscale back to color (to retain some color info, if needed)
    # We duplicate the equalized grayscale into 3 channels
    eq_bgr = cv2.cvtColor(equalized, cv2.COLOR_GRAY2BGR)
    # Blend the color image with the equalized grayscale image.
    # This keeps some original color (70%) while imbuing luminance contrast from equalized image (30%).
    merged = cv2.addWeighted(bright, 0.7, eq_bgr, 0.3, 0)
    
    # 4. Denoise â€“ strong noise reduction on the merged image.
    # Using Non-Local Means Denoising. Parameters can be tuned (h=luminance strength, hColor=color strength).
    denoised = cv2.fastNlMeansDenoisingColored(merged, None, h=10, hColor=10, templateWindowSize=7, searchWindowSize=21)
    
    # 5. (Optional) Sharpening to enhance edges (unsharp mask technique)
    # We apply a Gaussian blur and then subtract a portion of it from the denoised image.
    blur = cv2.GaussianBlur(denoised, (0,0), sigmaX=3, sigmaY=3)
    sharpened = cv2.addWeighted(denoised, 1.5, blur, -0.5, 0)
    
    # Return the final processed frame.
    return sharpened

@router.get("/api/report/{camera_id}", response_model=CameraReportResponse)
async def get_camera_report(camera_id: str, db: AsyncSession = Depends(get_db)):
    """
    Return for each object detected on this camera a list of { start_time, end_time }
    where consecutive detections within CAM_EVENT_GAP_SECONDS are merged.
    """
    q      = await db.execute(
        select(DetectionRecord)
        .where(DetectionRecord.camera_id == camera_id)
        .order_by(DetectionRecord.timestamp)
    )
    records = q.scalars().all()
    grouped = {}  # object_name â†’ list of ranges

    gap = timedelta(seconds=CAM_EVENT_GAP_SECONDS)

    for rec in records:
        lst = grouped.setdefault(rec.object_name, [])
        if not lst:
            lst.append({"start": rec.timestamp, "end": rec.timestamp})
        else:
            last = lst[-1]
            if rec.timestamp - last["end"] <= gap:
                last["end"] = rec.timestamp
            else:
                lst.append({"start": rec.timestamp, "end": rec.timestamp})

    # Flatten into Pydantic list
    detections = []
    for obj, ranges in grouped.items():
        for r in ranges:
            detections.append(
                DetectionRange(
                    object_name=obj,
                    start_time=r["start"],
                    end_time=r["end"]
                )
            )

    return CameraReportResponse(camera_id=camera_id, detections=detections)

----- app/routers/devices.py -----
from datetime import timezone
import datetime
import json
import os
import ipaddress
import asyncio
from pathlib import Path as FsPath 
import socket
from typing import List
import httpx
import logging
from fastapi import APIRouter, HTTPException, Depends, Query, Request,  WebSocket, Path as PathParam
from fastapi.responses import JSONResponse, StreamingResponse
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.future import select
import re
from app.core.config import DEPLOYMENT_MODE  # e.g. "LAN" or "CLOUD"
from app.models import Device, Subscription, User
from app.dependencies import get_current_user
from app.core.database import get_db
from app.services.device_controller import DeviceController
from app.services.llm import getSensorData
from app.schemas import (
    DosingDeviceCreate,
    SensorDeviceCreate,
    DeviceResponse,
    DeviceType,
    ValveDeviceCreate,
)

logger = logging.getLogger(__name__)
router = APIRouter()

cam_registry: dict[str, str] = {}
latest_frames = {}
ws_connections = {}

JPEG_SOI = b'\xff\xd8'
JPEG_EOI = b'\xff\xd9'
jpeg_regex = re.compile(rb'\xff\xd8.*?\xff\xd9', re.DOTALL)

def get_local_ip() -> str:
    s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    try:
        s.connect(("8.8.8.8", 80))
        ip = s.getsockname()[0]
    except Exception:
        ip = "127.0.0.1"
    finally:
        s.close()
    return ip

def default_subnet_from_ip(local_ip: str) -> str:
    parts = local_ip.split(".")
    if len(parts) == 4:
        return f"{parts[0]}.{parts[1]}.{parts[2]}.0/24"
    return "192.168.1.0/24"

async def discover_cloud_device(device: Device, client: httpx.AsyncClient) -> dict:
    url = device.http_endpoint.rstrip("/") + "/discovery"
    try:
        response = await asyncio.wait_for(client.get(url), timeout=2.0)
        if response.status_code == 200:
            data = response.json()
            data["ip"] = device.http_endpoint
            return data
    except Exception as e:
        logger.error(f"Cloud discovery error for device {device.id} at {device.http_endpoint}: {e}")
    return None

async def discover_lan_device(ip: str, port: str, client: httpx.AsyncClient) -> dict:
    url = f"http://{ip}:{port}/discovery"
    try:
        response = await asyncio.wait_for(client.get(url), timeout=2.0)
        if response.status_code == 200:
            data = response.json()
            data["ip"] = ip
            return data
    except Exception as e:
        logger.debug(f"No response from {ip}:{port} - {e}")
    return None

@router.get("/discover-all", summary="Discover devices with progress updates")
async def discover_all_devices(db: AsyncSession = Depends(get_db)):
    async def event_generator():
        discovered_devices = []
        eventCount = 0  # Count every SSE event sent
        async with httpx.AsyncClient(timeout=httpx.Timeout(2.0)) as client:
            if DEPLOYMENT_MODE.upper() == "LAN":
                local_ip = get_local_ip()
                subnet = os.getenv("LAN_SUBNET", default_subnet_from_ip(local_ip))
                port = os.getenv("LAN_PORT", "80")
                network = ipaddress.ip_network(subnet, strict=False)
                ips = [str(ip) for ip in network.hosts()]
                # If you want a fixed target for LAN mode, force total_ips to 256:
                total_ips = len(ips)  # Or: total_ips = len(ips) if you prefer the real count
                logger.info(f"LAN mode: scanning {total_ips} IPs in subnet {subnet} on port {port}")

                sem = asyncio.Semaphore(20)
                async def sem_discover(ip: str):
                    async with sem:
                        return await discover_lan_device(ip, port, client)
                tasks = [asyncio.create_task(sem_discover(ip)) for ip in ips]
                for task in asyncio.as_completed(tasks):
                    eventCount += 1  # Increment for every event (each IP tested)
                    try:
                        result = await task
                    except Exception as exc:
                        logger.error(f"Error in LAN discovery task: {exc}")
                        result = None
                    if result:
                        discovered_devices.append(result)
                    yield f"data: {json.dumps({'eventCount': eventCount, 'total': total_ips})}\n\n"
            else:
                result = await db.execute(select(Device))
                devices = result.scalars().all()
                total_devices = len(devices)
                logger.info(f"CLOUD mode: found {total_devices} registered devices")
                sem = asyncio.Semaphore(20)
                async def sem_discover_cloud(device: Device):
                    async with sem:
                        return await discover_cloud_device(device, client)
                tasks = [asyncio.create_task(sem_discover_cloud(device)) for device in devices]
                for task in asyncio.as_completed(tasks):
                    eventCount += 1
                    try:
                        result = await task
                    except Exception as exc:
                        logger.error(f"Error in CLOUD discovery task: {exc}")
                        result = None
                    if result:
                        discovered_devices.append(result)
                    yield f"data: {json.dumps({'eventCount': eventCount, 'total': total_devices})}\n\n"
        # Final event: send the full discovered devices list.
        yield f"data: {json.dumps({'discovered_devices': discovered_devices})}\n\n"
    return StreamingResponse(event_generator(), media_type="text/event-stream")


# ---------- Additional Endpoints ----------
@router.get("/discover", summary="Check if a device is connected")
async def check_device_connection(
    ip: str = Query(..., description="IP address of the device to validate")
):
    controller = DeviceController(device_ip=ip)
    device_info = await controller.discover()
    logger.info(f"Discovery response for {ip}: {device_info}")
    if not device_info or not isinstance(device_info, dict) or "device_id" not in device_info:
        raise HTTPException(status_code=404, detail="No device found at the provided IP")
    formatted_device = {
        "id": device_info.get("device_id"),
        "name": device_info.get("name", device_info.get("device_id")),
        "type": device_info.get("type"),
        "status": device_info.get("status"),
        "version": device_info.get("version"),
        "ip": device_info.get("ip")
    }
    return formatted_device

@router.post("/dosing", response_model=DeviceResponse)
async def create_dosing_device(
    device: DosingDeviceCreate,
    session: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    try:
        endpoint = device.http_endpoint
        if not endpoint.startswith("http"):
            endpoint = f"http://localhost/{endpoint}"
        controller = DeviceController(device_ip=endpoint)
        discovered_device = await controller.discover()
        if not discovered_device:
            raise HTTPException(status_code=500, detail="Device discovery failed at the given endpoint")
        existing = await session.execute(select(Device).where(Device.mac_id == device.mac_id))
        if existing.scalar_one_or_none():
            raise HTTPException(status_code=400, detail="Device already registered")
        new_device = Device(
            name=discovered_device.get("name", device.name),
            user_id=current_user.id,
            mac_id=device.mac_id,
            type=DeviceType.DOSING_UNIT,
            http_endpoint=endpoint,
            location_description=device.location_description or "",
            pump_configurations=[p.model_dump() for p in device.pump_configurations],
            is_active=True,
            farm_id=device.farm_id
        )
        session.add(new_device)
        await session.commit()
        await session.refresh(new_device)
        return new_device
    except Exception as e:
        await session.rollback()
        raise HTTPException(status_code=500, detail=f"Error creating dosing device: {e}")

@router.post("/sensor", response_model=DeviceResponse)
async def create_sensor_device(
    device: SensorDeviceCreate,
    session: AsyncSession = Depends(get_db)
):
    try:
        new_device = Device(
            mac_id=device.mac_id,
            name=device.name,
            type=device.type,
            http_endpoint=device.http_endpoint,
            location_description=device.location_description,
            sensor_parameters=device.sensor_parameters,
            is_active=True,
            farm_id=device.farm_id
        )
        session.add(new_device)
        await session.commit()
        await session.refresh(new_device)
        return new_device
    except Exception as e:
        await session.rollback()
        raise HTTPException(status_code=500, detail=f"Error creating sensor device: {e}")

@router.get("", response_model=list[DeviceResponse], summary="List all devices")
async def list_devices(db: AsyncSession = Depends(get_db)):
    result = await db.execute(select(Device))
    return result.scalars().all()

@router.get("/{device_id}", response_model=DeviceResponse, summary="Get device details")
async def get_device(device_id: str = PathParam(..., description="MAC ID of the valve controller"), db: AsyncSession = Depends(get_db)):
    result = await db.execute(select(Device).where(Device.id == device_id))
    device = result.scalar_one_or_none()
    if not device:
        raise HTTPException(status_code=404, detail="Device not found")
    return device

@router.get("/sensoreading/{device_id}")
async def get_sensor_readings(device_id: str, db: AsyncSession = Depends(get_db)):
    result = await db.execute(select(Device).where(Device.id == device_id))
    device = result.scalar_one_or_none()
    if not device:
        raise HTTPException(status_code=404, detail="Device not found")
    sensor_data = await getSensorData(device)
    return sensor_data


@router.get("/device/{device_id}/version", summary="Get device version")
async def get_device_version(device_id: str, db: AsyncSession = Depends(get_db)):
    try:
        # Fetch the device from the database
        result = await db.execute(select(Device).where(Device.id == device_id))
        device = result.scalar_one_or_none()
        
        if not device:
            raise HTTPException(status_code=404, detail="Device not found")
        
        controller = DeviceController(device_ip=device.http_endpoint)
        device_version = await controller.get_version()
        
        if not device_version:
            raise HTTPException(status_code=500, detail="Failed to retrieve device version")
        
        return {"device_id": device_id, "version": device_version}

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error fetching device version: {e}")
    
@router.post("/valve", response_model=DeviceResponse, summary="Register a new valve controller")
async def create_valve_device(
    device: ValveDeviceCreate,
    session: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_user),
):
    """
    Create/register a new 4â€‘valve controller.
    """
    # ensure http endpoint discovery
    endpoint = device.http_endpoint
    if not endpoint.startswith("http"):
        endpoint = f"http://{endpoint}"
    controller = DeviceController(device_ip=endpoint)
    discovered = await controller.discover()
    if not discovered:
        raise HTTPException(status_code=500, detail="Valve controller discovery failed")

    # enforce uniqueness
    existing = await session.execute(select(Device).where(Device.mac_id == device.mac_id))
    if existing.scalar_one_or_none():
        raise HTTPException(status_code=400, detail="Device already registered")

    new_device = Device(
        name=discovered.get("name", device.name),
        user_id=current_user.id,
        mac_id=device.mac_id,
        type=DeviceType.VALVE_CONTROLLER,
        http_endpoint=endpoint,
        location_description=device.location_description or "",
        valve_configurations=[v.model_dump() for v in device.valve_configurations],
        is_active=True,
        farm_id=device.farm_id,
    )
    session.add(new_device)
    await session.commit()
    await session.refresh(new_device)
    return new_device

@router.get(
    "/my",
    response_model=List[DeviceResponse],
    summary="List my active devices (with valid subscription)"
)
async def list_my_devices(
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_user),
):
    now = datetime.now(timezone.utc)
    # only devices I own *and* that have an active subscription right now
    q = (
        select(Device)
        .join(Subscription, Subscription.device_id == Device.id)
        .where(
            Device.user_id == current_user.id,
            Device.is_active == True,
            Subscription.active == True,
            Subscription.start_date <= now,
            Subscription.end_date >= now,
        )
        .distinct()
    )
    result = await db.execute(q)
    return result.scalars().all()

----- app/routers/device_comm.py -----
from fastapi import APIRouter, Body, Depends, HTTPException, Path, Query, Request, Path as PathParam, logger
from fastapi.responses import FileResponse
import httpx
from requests import request
import semver
from sqlalchemy import func, select
from sqlalchemy.ext.asyncio import AsyncSession
from pydantic import BaseModel

import os

from app.core.config import API_V1_STR
from app.core.database import get_db
from app.dependencies import get_current_device
from app.models import Device, Task
from app.schemas import DeviceType, SimpleDosingCommand
from pathlib import Path as FilePath 
CAM_FW = FilePath("firmware/camera/firmware.bin")
router = APIRouter(prefix="/api/v1/device_comm", tags=["device_comm"])


@router.get("/update", summary="Check for firmware update")
async def check_for_update(
    request: Request,
    device_id: str = Query(..., description="MAC ID of this device"),
    db: AsyncSession = Depends(get_db),
):
    # 1) Look up the device by its MAC ID
    result = await db.execute(select(Device).where(Device.mac_id == device_id))
    device = result.scalar_one_or_none()

    # 2) Decide latest release
    latest_version = "2.2.0"
    current_version = device.firmware_version if device else "0.0.0"
    update_available = semver.compare(latest_version, current_version) > 0

    # 3) Build a pull URL matching this endpoint
    base = str(request.base_url).rstrip("/")
    pull_url = f"{base}{API_V1_STR}/device_comm/update/pull?device_id={device_id}"

    return {
        "version": latest_version,
        "update_available": update_available,
        "download_url": pull_url
    }


@router.get("/update/pull", summary="Download the latest firmware")
async def pull_firmware(
    request: Request,                                           
    device_id: str = Query(..., description="Device or Camera ID")):
    logger.info(
        "Firmware pull â€¢ device_id=%s â€¢ ip=%s",
        device_id,
        request.headers.get("x-forwarded-for", request.client.host),
    )
    if device_id.startswith("CAM_") or device_id.lower().startswith("camera"):
        if not CAM_FW.exists():
            raise HTTPException(404, "Camera firmware not found")
        return FileResponse(CAM_FW, media_type="application/octet-stream",
                            filename="firmware.bin")

class ValveEventPayload(BaseModel):
    device_id: str
    valve_id: int
    state: str  # "on" or "off"


@router.post("/valve_event", summary="Receive a valve toggle event from device")
async def valve_event(
    payload: ValveEventPayload,
    db: AsyncSession = Depends(get_db)
):
    task = Task(
        device_id=payload.device_id,
        type="valve_event",
        parameters={"valve_id": payload.valve_id, "state": payload.state},
        status="received"
    )
    db.add(task)
    await db.commit()
    return {"message": "Valve event recorded"}


@router.get("/valve/{device_id}/state", summary="Fetch current valve states")
async def get_valve_state(
    device_id: str = PathParam(..., description="MAC ID of the valve controller"),
    db: AsyncSession = Depends(get_db),
):
    device = await db.get(Device, device_id)
    if not device or device.type != DeviceType.VALVE_CONTROLLER:
        raise HTTPException(status_code=404, detail="Valve controller not found")

    async with httpx.AsyncClient() as client:
        resp = await client.get(f"{device.http_endpoint.rstrip('/')}/state", timeout=5)
        resp.raise_for_status()
        return resp.json()


@router.post("/valve/{device_id}/toggle", summary="Toggle a single valve")
async def toggle_valve(
    device_id: str = PathParam(..., description="MAC ID of the valve controller"),
    body: dict = Body(..., media_type="application/json"),
    db: AsyncSession = Depends(get_db),
):
    valve_id = body.get("valve_id")
    if not isinstance(valve_id, int) or not (1 <= valve_id <= 4):
        raise HTTPException(status_code=400, detail="Invalid valve_id (must be 1â€“4)")

    device = await db.get(Device, device_id)
    if not device or device.type != DeviceType.VALVE_CONTROLLER:
        raise HTTPException(status_code=404, detail="Valve controller not found")

    async with httpx.AsyncClient() as client:
        resp = await client.post(
            f"{device.http_endpoint.rstrip('/')}/toggle",
            json={"valve_id": valve_id},
            timeout=5
        )
        resp.raise_for_status()
        data = resp.json()

    task = Task(
        device_id=device_id,
        type="valve",
        parameters={"valve_id": valve_id, "new_state": data.get("new_state")}
    )
    db.add(task)
    await db.commit()

    return data


def find_latest_firmware(device_type: str) -> tuple[str, str]:
    base = os.path.join("firmware", device_type)
    if not os.path.isdir(base):
        raise FileNotFoundError(f"No firmware folder for device type '{device_type}'")
    versions = [
        d for d in os.listdir(base)
        if os.path.isdir(os.path.join(base, d)) and semver.VersionInfo.isvalid(d)
    ]
    if not versions:
        raise FileNotFoundError(f"No versioned firmware found under {base}")
    latest = str(max(versions, key=semver.VersionInfo.parse))
    binpath = os.path.join(base, latest, "firmware.bin")
    if not os.path.isfile(binpath):
        raise FileNotFoundError(f"Missing firmware.bin in {base}/{latest}")
    return latest, binpath


@router.get("/pending_tasks", summary="Get pending pump tasks")
async def get_pending_tasks(
    device_id: str = Query(..., description="MAC ID of this device"),
    db: AsyncSession = Depends(get_db)
):
    result = await db.execute(
        select(Task).where(Task.device_id == device_id, Task.status == "pending")
    )
    return [t.to_dict() for t in result.scalars().all()]


@router.post(
    "/heartbeat",
    dependencies=[Depends(get_current_device)],
    summary="Device heartbeat (returns tasks & OTA info)"
)
async def heartbeat(request: Request, db: AsyncSession = Depends(get_db)):
    payload = await request.json()
    mac = payload.get("device_id")
    dtype = payload.get("type")
    ver = payload.get("version")
    logger.info("Heartbeat from %s  â€¢  IP=%s", mac, request.headers.get("xâ€‘forwardedâ€‘for", request.client.host))

    # Update last_seen & firmware_version
    device = await db.scalar(select(Device).where(Device.mac_id == mac))
    device.last_seen = func.now()
    device.firmware_version = ver
    await db.commit()

    # Collect pending pump tasks
    q = await db.execute(
        select(Task).where(
            Task.device_id == mac, Task.status == "pending", Task.type == "pump"
        )
    )
    tasks = [t.parameters for t in q.scalars().all()]

    # OTA check
    try:
        latest_ver, _ = find_latest_firmware(dtype)
        update_available = semver.compare(latest_ver, ver) > 0
    except Exception:
        latest_ver, update_available = ver, False

    return {
        "status": "ok",
        "status_message": "All systems nominal",
        "tasks": tasks,
        "update": {
            "current": ver,
            "latest": latest_ver,
            "available": update_available,
        },
    }


@router.post("/tasks", summary="Enqueue a dosing task")
async def enqueue_pump(
    body: SimpleDosingCommand,
    device_id: str = Query(..., description="MAC ID of this device"),
    db: AsyncSession = Depends(get_db),
):
    task = Task(
        device_id=device_id,
        type="pump",
        parameters={"pump": body.pump, "amount": body.amount},
        status="pending"
    )
    db.add(task)
    await db.commit()
    return {"message": "Pump task enqueued", "task": task.to_dict()}


----- app/core/config.py -----
"""
Centralised runtime configuration.

â€¢ Reads a single `.env` file at project root (already loaded by dotenv).
â€¢ Fails fast if a mandatory variable is missing (e.g. DATABASE_URL).
â€¢ Casts booleans & integers safely.
â€¢ Exposes helpers for feature flags.
"""
from __future__ import annotations

import os
from pathlib import Path
from dotenv import load_dotenv

# --------------------------------------------------------------------------- #
# 1.  Load .env early â€“ variables already in the environment win               #
# --------------------------------------------------------------------------- #
ENV_FILE = Path(__file__).resolve().parent.parent.parent / ".env"
load_dotenv(dotenv_path=ENV_FILE, override=False)

# --------------------------------------------------------------------------- #
# 2.  Core settings                                                            #
# --------------------------------------------------------------------------- #
def _get_bool(name: str, default: bool = False) -> bool:
    return os.getenv(name, str(default)).strip().lower() in {"1", "true", "yes", "on"}

def _get_int(name: str, default: int) -> int:
    try:
        return int(os.getenv(name, default))
    except ValueError:      # pragma: no cover â€“ bad env var
        return default

ENVIRONMENT      = os.getenv("ENVIRONMENT", "production").lower()
DEBUG            = _get_bool("DEBUG", ENVIRONMENT != "production")
TESTING          = _get_bool("TESTING")
DEPLOYMENT_MODE  = os.getenv("DEPLOYMENT_MODE", "LAN").upper()            # LAN / CLOUD
ALLOWED_ORIGINS  = [o.strip() for o in os.getenv("ALLOWED_ORIGINS", "*").split(",")]

# --------------------------------------------------------------------------- #
# 3.  Database                                                                 #
# --------------------------------------------------------------------------- #
if TESTING:
    DATABASE_URL = os.getenv("TEST_DATABASE_URL")
    if not DATABASE_URL:   # in CI you *must* supply a test DB
        raise RuntimeError("TEST_DATABASE_URL must be set when TESTING=1")
else:
    DATABASE_URL = os.getenv("DATABASE_URL")
    if not DATABASE_URL:
        raise RuntimeError(
            "DATABASE_URL is not configured. "
            "Example: postgresql+asyncpg://user:pass@host:5432/dbname"
        )

# optional pool tuning
DB_POOL_SIZE      = _get_int("DB_POOL_SIZE", 20)
DB_MAX_OVERFLOW   = _get_int("DB_MAX_OVERFLOW", 20)

# --------------------------------------------------------------------------- #
# 4.  Misc feature flags / paths                                              #
# --------------------------------------------------------------------------- #
DATA_ROOT                 = os.getenv("CAM_DATA_ROOT", "./data")
RAW_DIR                   = os.getenv("CAM_RAW_DIR", "raw")
CLIPS_DIR                 = os.getenv("CAM_CLIPS_DIR", "clips")
PROCESSED_DIR             = os.getenv("CAM_PROCESSED_DIR", "processed")
RETENTION_DAYS            = _get_int("CAM_RETENTION_DAYS", 2)
OFFLINE_TIMEOUT           = _get_int("CAM_OFFLINE_TIMEOUT", 45)
BOUNDARY                  = os.getenv("CAM_BOUNDARY", "frame")
YOLO_MODEL_PATH           = os.getenv("YOLO_MODEL_PATH", "yolov5s.pt")
CAM_DETECTION_WORKERS     = _get_int("CAM_DETECTION_WORKERS", 4)
CAM_EVENT_GAP_SECONDS     = _get_int("CAM_EVENT_GAP_SECONDS", 2)

API_V1_STR   = os.getenv("API_V1_STR", "/api/v1")
PROJECT_NAME = os.getenv("PROJECT_NAME", "Hydroleaf")
SESSION_KEY  = os.getenv("SESSION_KEY", "Hydroleaf_session")

# Ollama / LLM
USE_OLLAMA   = _get_bool("USE_OLLAMA", True)
OLLAMA_HOST  = os.getenv("OLLAMA_HOST", "http://localhost:11434")
MODEL_NAME_1_5B = os.getenv("MODEL_NAME_1_5B", "deepseek-r1:1.5b")
MODEL_NAME_7B   = os.getenv("MODEL_NAME_7B", "gemma")

# third-party keys
SERPER_API_KEY = os.getenv("SERPER_API_KEY", "")

# secrets
SECRET_KEY = os.getenv("SECRET_KEY")
if not SECRET_KEY:
    raise RuntimeError("SECRET_KEY is required for JWT / session signing")
RESET_DB = _get_bool("RESET_DB", False)



----- app/core/database.py -----
# app/core/database.py
"""PostgreSQLâ€‘only async DB layer with *safe multiâ€‘worker bootstrap*.

Key points
----------
* Refuses to start if `DATABASE_URL` is **not** `postgresql+asyncpg://â€¦`.
* Uses a **PostgreSQL advisory lock** so only **one worker** runs
  `metadata.create_all()` â€“ avoids the duplicateâ€‘sequence race you just hit.
* Exposes:  `engine`, `AsyncSessionLocal`, `Base`, `get_db()` dependency,
  `init_db()`, `check_db_connection()`, and `cleanup_db()`.
* In production you should normally run Alembic migrations; the bootstrap
  helper is for local dev / CI or the very first deploy.
"""
from __future__ import annotations

import logging
from datetime import datetime
from typing import AsyncGenerator, Dict

from sqlalchemy import text
from sqlalchemy.engine.url import make_url
from sqlalchemy.ext.asyncio import (
    AsyncSession,
    async_sessionmaker,
    create_async_engine,
)
from sqlalchemy.orm import declarative_base

from app.core.config import DATABASE_URL, DB_POOL_SIZE, DB_MAX_OVERFLOW

logger = logging.getLogger(__name__)

# --------------------------------------------------------------------------- #
# 1.  Validate DATABASE_URL â€“ we only support Postgres via asyncpg             #
# --------------------------------------------------------------------------- #
url = make_url(DATABASE_URL)
if not url.drivername.startswith("postgresql+asyncpg"):
    raise RuntimeError(
        "Hydroleaf is configured for PostgreSQL only.  "
        f"Invalid driver in DATABASE_URL: {url.drivername}"
    )

# --------------------------------------------------------------------------- #
# 2.  Engine & session factory                                                #
# --------------------------------------------------------------------------- #
engine = create_async_engine(
    DATABASE_URL,
    pool_size=DB_POOL_SIZE,
    max_overflow=DB_MAX_OVERFLOW,
    future=True,
    pool_pre_ping=True,
)

AsyncSessionLocal: async_sessionmaker[AsyncSession] = async_sessionmaker(
    bind=engine,
    autoflush=False,
    autocommit=False,
    expire_on_commit=False,
)

# Base that every model shares
Base = declarative_base()

# --------------------------------------------------------------------------- #
# 3.  FastAPI session dependency                                              #
# --------------------------------------------------------------------------- #
async def get_db() -> AsyncGenerator[AsyncSession, None]:
    """Yield a transactional session and guarantee proper cleanup."""
    async with AsyncSessionLocal() as session:
        try:
            yield session
            await session.commit()
        except Exception:  # pragma: no cover
            await session.rollback()
            raise
        finally:
            await session.close()

# --------------------------------------------------------------------------- #
# 4.  Bootâ€‘time schema helper with advisory lock                              #
# --------------------------------------------------------------------------- #
_ADVISORY_KEY = 0x6A7971  # arbitrary constant <= 2^31â€‘1

async def init_db(create: bool = True) -> None:
    """Ensure the schema exists (dev / firstâ€‘run).

    Uses `pg_advisory_lock` so that when several Uvicorn workers start at the
    same time **only one** will run `metadata.create_all()`; the others wait
    for the lock, see that the tables already exist, and move on.
    """
    if not create:
        return  # migrations only, skip autoâ€‘create

    async with engine.begin() as conn:
        # Acquire global lock (blocks until available)
        await conn.execute(text("SELECT pg_advisory_lock(:k)").bindparams(k=_ADVISORY_KEY))
        try:
            await conn.run_sync(Base.metadata.create_all)
            logger.info("DB schema ensured (create_all checkfirst)")
        finally:
            # Always release lock so hotâ€‘reload works in dev
            await conn.execute(text("SELECT pg_advisory_unlock(:k)").bindparams(k=_ADVISORY_KEY))

# --------------------------------------------------------------------------- #
# 5.  Health helpers                                                          #
# --------------------------------------------------------------------------- #
async def check_db_connection() -> Dict[str, str]:
    try:
        async with AsyncSessionLocal() as session:
            await session.execute(text("SELECT 1"))
        return {"status": "connected", "timestamp": datetime.utcnow().isoformat()}
    except Exception as exc:  # pragma: no cover
        logger.error("DB healthâ€‘check failed", exc_info=True)
        return {"status": "error", "error": str(exc)}

async def cleanup_db() -> None:
    await engine.dispose()


----- app/core/__init__.py -----


----- app/utils/image_utils.py -----
# app/utils/image_utils.py
import cv2
import numpy as np

def is_day(frame: np.ndarray, thresh: float = 50.0) -> bool:
    """
    Convert to grayscale and use mean intensity to decide day vs night.
    """
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    return float(gray.mean()) >= thresh

def clean_frame(frame: np.ndarray, day: bool) -> np.ndarray:
    """
    Apply a simple cleanup depending on day/night:
      - day: histogramâ€equalize the V channel (improve contrast)
      - night: denoise with fastNlMeans
    """
    if day:
        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
        hsv[:, :, 2] = cv2.equalizeHist(hsv[:, :, 2])
        return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
    else:
        # parameters (10,10,7,21) tuned for mild denoising
        return cv2.fastNlMeansDenoisingColored(frame, None, 10, 10, 7, 21)


----- app/utils/camera_tasks.py -----

# app/utils/camera_tasks.py
import asyncio
import logging
from datetime import datetime, timedelta, timezone
from pathlib import Path
import cv2
from sqlalchemy.future import select
from app.models import Camera
from app.core.config import DATA_ROOT, RAW_DIR, CLIPS_DIR, RETENTION_DAYS, OFFLINE_TIMEOUT
from app.core.database import AsyncSessionLocal

logger = logging.getLogger(__name__)
encode_locks: dict[str, asyncio.Lock] = {}

def _encode_and_cleanup_sync(cam_id: str):
    cam_dir = Path(DATA_ROOT) / cam_id
    raw_dir = cam_dir / RAW_DIR
    clips_dir = cam_dir / CLIPS_DIR
    clips_dir.mkdir(parents=True, exist_ok=True)
    CLIP_MS = 15 * 60 * 1000
    files = sorted(raw_dir.glob("*.jpg"), key=lambda f: int(f.stem))
    buckets: dict[int, list[Path]] = {}
    for f in files:
        period = int(f.stem) // CLIP_MS
        buckets.setdefault(period, []).append(f)
    for period, group in buckets.items():
        timestamps = sorted(int(f.stem) for f in group)
        if timestamps[-1] - timestamps[0] < CLIP_MS:
            continue
        clip_start = period * CLIP_MS
        clip_path = clips_dir / f"{clip_start}.mp4"
        if clip_path.exists():
            continue
        first = cv2.imread(str(group[0]))
        h, w = first.shape[:2]
        vw = cv2.VideoWriter(
            str(clip_path), cv2.VideoWriter_fourcc(*"mp4v"), 10, (w, h)
        )
        for imgf in group:
            im = cv2.imread(str(imgf))
            if im is not None:
                vw.write(im)
            imgf.unlink(missing_ok=True)
        vw.release()
    # prune old clips
    cutoff = datetime.now(timezone.utc) - timedelta(days=RETENTION_DAYS)
    # raw frames
    for frame_file in raw_dir.glob("*.jpg"):
        if datetime.fromtimestamp(frame_file.stat().st_mtime, timezone.utc) < cutoff:
            frame_file.unlink(missing_ok=True)
    # clip files
    for clip in clips_dir.glob("*.mp4"):
        if datetime.fromtimestamp(clip.stat().st_mtime, timezone.utc) < cutoff:
            clip.unlink(missing_ok=True)

async def encode_and_cleanup(cam_id: str):
    lock = encode_locks.setdefault(cam_id, asyncio.Lock())
    if lock.locked():
        return
    async with lock:
        await asyncio.to_thread(_encode_and_cleanup_sync, cam_id)

async def offline_watcher(db_factory, interval_seconds: float = 5.0):
    logger.info(f"Starting offline watcher, interval={interval_seconds}s")
    while True:
        await asyncio.sleep(interval_seconds)
        now = datetime.now(timezone.utc)
        async with db_factory() as session:
            result = await session.execute(select(Camera))
            cams = result.scalars().all()
            for cam in cams:
                last_seen = cam.last_seen or datetime.fromtimestamp(0, timezone.utc)
                is_online = (now - last_seen).total_seconds() <= OFFLINE_TIMEOUT
                if cam.is_online != is_online:
                    cam.is_online = is_online
                    logger.info(f"Camera {cam.id} online status changed: {is_online}")
            await session.commit()


----- app/utils/json_utils.py -----
from datetime import datetime
import json

class CustomJSONEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, datetime):
            return obj.isoformat()
        return super().default(obj)

def format_json_response(data):
    return json.dumps(data, cls=CustomJSONEncoder, indent=2)

----- app/utils/camera_queue.py -----
import asyncio
from pathlib import Path
from datetime import datetime, timezone
import cv2
from sqlalchemy.ext.asyncio import AsyncSession
from ultralytics import YOLO

from app.core.config    import DATA_ROOT, RAW_DIR, PROCESSED_DIR, YOLO_MODEL_PATH, CAM_DETECTION_WORKERS
from app.core.database  import AsyncSessionLocal
from app.models         import DetectionRecord

class CameraQueue:
    def __init__(self):
        self.queue    = asyncio.Queue()
        self.model    = YOLO(YOLO_MODEL_PATH)
        self.workers  = CAM_DETECTION_WORKERS

    async def enqueue(self, camera_id: str, frame_path: Path):
        """Push a newly saved raw frame into the detection queue."""
        await self.queue.put((camera_id, frame_path))

    async def _worker(self):
        while True:
            camera_id, frame_path = await self.queue.get()
            try:
                frame = cv2.imread(str(frame_path))
                if frame is None:
                    continue

                # Run YOLO inference
                results = self.model(frame)[0]
                boxes   = results.boxes
                if boxes and len(boxes) > 0:
                    # Annotate & save to processed dir
                    proc_dir = Path(DATA_ROOT)/camera_id/PROCESSED_DIR
                    proc_dir.mkdir(parents=True, exist_ok=True)
                    annotated = results.plot()  # returns an np.ndarray
                    out_path  = proc_dir/frame_path.name
                    cv2.imwrite(str(out_path), annotated)

                    # Record each detection
                    async with AsyncSessionLocal() as session:
                        for box in boxes:
                            cls       = int(box.cls.cpu().numpy())
                            name      = self.model.names[cls]
                            record    = DetectionRecord(
                                camera_id=camera_id,
                                object_name=name,
                                timestamp=datetime.now(timezone.utc)
                            )
                            session.add(record)
                        await session.commit()

            except Exception as e:
                # youâ€™d normally use proper logging
                print(f"[camera_queue] error: {e}")
            finally:
                self.queue.task_done()

    def start_workers(self):
        """Spawn N background tasks on the running loop."""
        loop = asyncio.get_event_loop()
        for _ in range(self.workers):
            loop.create_task(self._worker())

# Singleton queue
camera_queue = CameraQueue()


----- app/services/dose_manager.py -----
# dose_manager.py
import logging
from datetime import datetime
from app.models import Device
from fastapi import HTTPException
from app.services.device_controller import DeviceController
from sqlalchemy.ext.asyncio import AsyncSession

logger = logging.getLogger(__name__)

class DoseManager:
    def __init__(self):
        pass

    async def execute_dosing(self, device_id: str, http_endpoint: str, dosing_actions: list, combined: bool = False) -> dict:
        """
        Execute a dosing command using the unified device controller.
        If combined=True, the controller will use the /dose_monitor endpoint.
        """
        if not dosing_actions:
            raise ValueError("No dosing action provided")
        controller = DeviceController(device_ip=http_endpoint)
        responses = []
        for action in dosing_actions:
            pump = action.get("pump_number") or action.get("pump")
            amount = action.get("dose_ml") or action.get("amount")
            if pump is None or amount is None:
                raise ValueError("Dosing action must include pump number and dose amount")
            try:
                resp = await controller.execute_dosing(pump, amount, combined=combined)
                responses.append(resp)
            except Exception as e:
                raise HTTPException(status_code=500, detail=str(e))
        
        logger.info(f"Sent dosing commands to device {device_id}: {responses}")
        return {
            "status": "command_sent",
            "device_id": device_id,
            "actions": dosing_actions,
            "responses": responses
        }

    async def cancel_dosing(self, device_id: str, http_endpoint: str) -> dict:
    # Create a controller instance for the device.
        controller = DeviceController(device_ip=http_endpoint)
        response = await controller.cancel_dosing()
        logger.info(f"Cancellation response for device {device_id}: {response}")
        return {"status": "dosing_cancelled", "device_id": device_id, "response": response}
    async def get_device(self, device_id: str, db: AsyncSession):
        device = await db.get(Device, device_id)
        if not device:
            raise HTTPException(status_code=404, detail="Device not found")
        return device


# Create singleton instance
dose_manager = DoseManager()

async def execute_dosing_operation(device_id: str, http_endpoint: str, dosing_actions: list, combined: bool = False) -> dict:
    return await dose_manager.execute_dosing(device_id, http_endpoint, dosing_actions, combined)

async def cancel_dosing_operation(device_id: str, http_endpoint: str) -> dict:
    return await dose_manager.cancel_dosing(device_id, http_endpoint)


----- app/services/supply_chain_service.py -----
import os
import asyncio
import json
import logging
import re
from datetime import datetime
from fastapi import HTTPException
from typing import Dict, Any, Tuple, Union, List
import httpx
from sqlalchemy.ext.asyncio import AsyncSession

from app.models import SupplyChainAnalysis, ConversationLog
from app.services.serper import fetch_search_results

logger = logging.getLogger(__name__)

# Production-level configuration via environment variables
OLLAMA_URL = os.getenv("OLLAMA_URL", "http://localhost:11434/api/generate")
MODEL_1_5B = os.getenv("MODEL_1_5B", "deepseek-r1:1.5b")
MODEL_7B = os.getenv("MODEL_7B", "gemma3")
LLM_REQUEST_TIMEOUT = int(os.getenv("LLM_REQUEST_TIMEOUT", "300"))

def extract_json_from_response(response_text: str) -> Dict:
    """
    Extract and parse JSON from an LLM response while handling errors gracefully.
    """
    try:
        response_text = response_text.replace("'", '"').strip()
        json_match = re.search(r"(\{.*\})", response_text, flags=re.DOTALL)
        if json_match:
            cleaned_json = json_match.group(1)
            return json.loads(cleaned_json)
        else:
            logger.error("No valid JSON block found in LLM response.")
            raise HTTPException(status_code=500, detail="Invalid JSON from LLM")
    except json.JSONDecodeError as e:
        logger.error(f"JSON Parsing Error: {e}. Response: {response_text}")
        raise HTTPException(status_code=500, detail="Malformed JSON format from LLM")

async def call_llm(prompt: str, model_name: str = MODEL_1_5B) -> Dict:
    """
    Calls the LLM API and extracts JSON data from the response.
    """
    logger.info(f"Calling LLM with model {model_name}, prompt:\n{prompt}")
    request_body = {"model": model_name, "prompt": prompt, "stream": False}
    
    try:
        async with httpx.AsyncClient(timeout=LLM_REQUEST_TIMEOUT) as client:
            response = await client.post(OLLAMA_URL, json=request_body)
            response.raise_for_status()
            data = response.json()
            raw_completion = data.get("response", "").strip()
            logger.info(f"Ollama raw response: {raw_completion}")
            return extract_json_from_response(raw_completion)
    
    except httpx.HTTPStatusError as http_err:
        logger.error(f"Ollama HTTP error: {http_err}")
        raise HTTPException(status_code=500, detail="LLM API HTTP error") from http_err
    except Exception as e:
        logger.error(f"Ollama call failed: {e}")
        raise HTTPException(status_code=500, detail="Error processing LLM response") from e

async def analyze_transport_optimization(transport_request: Dict[str, Any]) -> Tuple[Dict, Dict]:
    """
    Fetches optimized transport analysis for agricultural products.
    """
    origin = transport_request.get("origin", "Unknown")
    destination = transport_request.get("destination", "Unknown")
    produce_type = transport_request.get("produce_type", "Unknown Product")
    weight_kg = transport_request.get("weight_kg", 0)
    transport_mode = transport_request.get("transport_mode", "railway")

    distance_query = f"average distance in km from {origin} to {destination} by {transport_mode}"
    cost_query = f"average cost per kg to transport {produce_type} from {origin} to {destination} by {transport_mode}"
    time_query = f"average travel time in hours from {origin} to {destination} by {transport_mode}"
    perish_query = f"average time in hours before {produce_type} perishes during transport"
    market_price_query = f"average market price per kg for {produce_type} in {destination}"

    distance_km = await fetch_and_average_value(distance_query)
    cost_per_kg = await fetch_and_average_value(cost_query)
    estimated_time_hours = await fetch_and_average_value(time_query)
    perish_time_hours = await fetch_and_average_value(perish_query)
    market_price_per_kg = await fetch_and_average_value(market_price_query)

    total_cost = cost_per_kg * weight_kg
    net_profit_per_kg = market_price_per_kg - cost_per_kg

    prompt = f"""
You are a supply chain optimization expert. Evaluate the following transport parameters for {produce_type}:
- Origin: {origin}
- Destination: {destination}
- Transport Mode: {transport_mode}
- Distance: {distance_km:.2f} km
- Cost per kg: {cost_per_kg:.2f} USD
- Total Weight: {weight_kg} kg
- Estimated Travel Time: {estimated_time_hours:.2f} hours
- Time before perish: {perish_time_hours:.2f} hours
- Market Price per kg: {market_price_per_kg:.2f} USD

Considering possible delays and perishability constraints, provide a final recommendation to optimize transportation.
Output in JSON format:
{{
  "final_recommendation": "<optimized transport plan>",
  "reasoning": "<detailed explanation>"
}}
""".strip()

    optimization_result = await call_llm(prompt, model_name=MODEL_7B)

    analysis_record = {
        "origin": origin,
        "destination": destination,
        "produce_type": produce_type,
        "weight_kg": weight_kg,
        "transport_mode": transport_mode,
        "distance_km": distance_km,
        "cost_per_kg": cost_per_kg,
        "total_cost": total_cost,
        "estimated_time_hours": estimated_time_hours,
        "market_price_per_kg": market_price_per_kg,
        "net_profit_per_kg": net_profit_per_kg,
        "final_recommendation": json.dumps(optimization_result.get("final_recommendation", "No recommendation provided"))
    }
    return analysis_record, optimization_result

async def store_supply_chain_analysis(db_session: AsyncSession, analysis_record: Dict[str, Any]):
    """
    Stores transport analysis results into the database.
    """
    record = SupplyChainAnalysis(**analysis_record)
    db_session.add(record)
    try:
        await db_session.commit()
        await db_session.refresh(record)
        logger.info(f"Supply chain analysis record stored with ID: {record.id}")
    except Exception as exc:
        await db_session.rollback()
        logger.error(f"Error storing supply chain analysis record: {exc}")
        raise HTTPException(status_code=500, detail="Failed to store supply chain analysis record") from exc

async def store_conversation(db_session: AsyncSession, user_request: Dict[str, Any],
                             prompt: str, llm_response: Dict[str, Any]):
    """
    Logs LLM conversations into the database.
    """
    log = ConversationLog(conversation={
        "user_request": user_request,
        "llm_prompt": prompt,
        "llm_response": llm_response
    })
    db_session.add(log)
    try:
        await db_session.commit()
        await db_session.refresh(log)
        logger.info(f"Conversation log stored with ID: {log.id}")
    except Exception as exc:
        await db_session.rollback()
        logger.error(f"Error storing conversation log: {exc}")
        raise HTTPException(status_code=500, detail="Failed to store conversation log") from exc

async def trigger_transport_analysis(transport_request: Dict[str, Any], db_session: AsyncSession) -> Dict[str, Any]:
    """
    Runs the transport optimization analysis and stores the results.
    """
    analysis_record, optimization_result = await analyze_transport_optimization(transport_request)
    prompt_for_log = f"Analysis parameters: {json.dumps(analysis_record, indent=2)}"
    await store_supply_chain_analysis(db_session, analysis_record)
    await store_conversation(db_session, transport_request, prompt_for_log, optimization_result)
    return {"analysis": analysis_record, "optimization": optimization_result}

async def fetch_and_average_value(query: str) -> float:
    """
    Dummy implementation to support testing.
    Returns a numeric value based on keywords found in the query.
    """
    q = query.lower()
    if "distance" in q:
        return 350.0
    elif "cost" in q:
        return 1.0
    elif "travel" in q:
        return 6.0
    elif "perish" in q:
        return 24.0
    elif "market price" in q:
        return 2.5
    return 0.0



----- app/services/device_discovery.py -----
import time

# Inâ€‘memory registry: key=device_id, value=dict(ip=<ip>, last_seen=<timestamp>)
_connected_devices = {}

def update_device(device_id: str, ip: str) -> None:
    _connected_devices[device_id] = {"ip": ip, "last_seen": time.time()}

def get_connected_devices() -> dict:
    now = time.time()
    # Only return devices seen in the last 60 seconds (adjust as needed)
    return {device_id: info for device_id, info in _connected_devices.items() if now - info["last_seen"] < 60}


----- app/services/serper.py -----
import os
import asyncio
import httpx
from bs4 import BeautifulSoup
from typing import Any, Dict, List, Optional
import logging

logger = logging.getLogger(__name__)

# Configuration
SERPER_API_KEY: str = os.getenv("SERPER_API_KEY") or ""
if not SERPER_API_KEY:
    raise RuntimeError("Environment variable SERPER_API_KEY is not set.")

BASE_URL = "https://google.serper.dev/search"
HEADERS = {"User-Agent": "Hydroleaf/1.0 (+https://yourdomain.com)"}
MAX_SCRAPE_WORKERS: int = int(os.getenv("SERPER_MAX_WORKERS", "5"))
RETRY_ATTEMPTS: int = int(os.getenv("SERPER_RETRIES", "3"))
RETRY_BACKOFF_BASE: float = float(os.getenv("SERPER_BACKOFF", "1.0"))


def _sync_scrape_text(url: str) -> str:
    """
    Blocking function to fetch and parse page text.
    """
    if not url:
        return ""
    try:
        with httpx.Client(headers=HEADERS, timeout=5.0) as client:
            resp = client.get(url)
            resp.raise_for_status()
            soup = BeautifulSoup(resp.text, "html.parser")
            for tag in soup(["script", "style", "noscript"]):
                tag.decompose()
            return soup.get_text(separator=" ", strip=True)
    except Exception as exc:
        logger.warning(f"Scraping failed for {url}: {exc}")
        return ""


async def _scrape_page_text(url: str) -> str:
    """
    Async wrapper around the blocking scraper using a thread.
    """
    return await asyncio.to_thread(_sync_scrape_text, url)


async def _get_json_with_retry(
    client: httpx.AsyncClient, url: str, params: Dict[str, Any]
) -> Dict[str, Any]:
    """
    Perform a GET request with retry and exponential backoff.
    """
    for attempt in range(1, RETRY_ATTEMPTS + 1):
        try:
            response = await client.get(url, params=params, headers=HEADERS, timeout=10.0)
            response.raise_for_status()
            return response.json()
        except httpx.HTTPStatusError as http_err:
            logger.error(f"Serper API HTTP error ({http_err.response.status_code}): {http_err.response.text}")
            raise
        except Exception as exc:
            if attempt == RETRY_ATTEMPTS:
                logger.error(f"Serper request failed after {attempt} attempts: {exc}")
                raise
            backoff = RETRY_BACKOFF_BASE * (2 ** (attempt - 1))
            logger.info(f"Retrying Serper API in {backoff:.1f}s (attempt {attempt}/{RETRY_ATTEMPTS})")
            await asyncio.sleep(backoff)
    # Should never reach here
    raise RuntimeError("Exceeded retry attempts for Serper API")


async def fetch_search_results(
    query: str,
    num_results: int = 5,
    gl: str = "in",
    hl: str = "en"
) -> Dict[str, Any]:
    """
    Fetch search results from Google Serper API and enrich organic results with page content.

    :param query: Search query string.
    :param num_results: Number of organic results to return.
    :param gl: Geolocation parameter (e.g., 'in').
    :param hl: Language parameter (e.g., 'en').
    :return: Raw API response including 'organic' entries with added 'page_content'.
    """
    params = {
        "q": query,
        "gl": gl,
        "hl": hl,
        "apiKey": SERPER_API_KEY,
        "num": num_results,
        "full": "true",
        "output": "detailed"
    }

    async with httpx.AsyncClient() as client:
        data = await _get_json_with_retry(client, BASE_URL, params)

    organic: Optional[List[Dict[str, Any]]] = data.get("organic")
    if not organic:
        logger.debug("No organic results found in Serper response.")
        return data

    # Limit to desired number of entries
    results_list = organic[:num_results]

    # Concurrently scrape each page's text with bounded concurrency
    semaphore = asyncio.Semaphore(MAX_SCRAPE_WORKERS)

    async def sem_scrape(entry: Dict[str, Any]) -> None:
        link = entry.get("link")
        if not link:
            entry["page_content"] = ""
            return
        async with semaphore:
            entry["page_content"] = await _scrape_page_text(link)

    # Kick off all scraping tasks
    await asyncio.gather(*(sem_scrape(entry) for entry in results_list))

    # Overwrite the organic list with enriched entries
    data["organic"] = results_list
    return data


----- app/services/__init__.py -----


----- app/services/llm.py -----
import os
import asyncio
import openai
import json
import logging
import re
from datetime import datetime
from fastapi import HTTPException
from typing import Dict, List, Union, Tuple
import httpx
from bs4 import BeautifulSoup
from sqlalchemy.ext.asyncio import AsyncSession

from app.models import Device
from app.services.dose_manager import DoseManager
from app.services.serper import fetch_search_results


logger = logging.getLogger(__name__)

# Production-level configuration via environment variables
OLLAMA_URL = os.getenv("OLLAMA_URL", "http://localhost:11434/api/generate")
MODEL_1_5B = os.getenv("MODEL_1_5B", "deepseek-r1:1.5b")
GPT_MODEL = os.getenv("GPT_MODEL")
MODEL_7B = os.getenv("MODEL_7B", "deepseek-r1:7b")
LLM_REQUEST_TIMEOUT = int(os.getenv("LLM_REQUEST_TIMEOUT", "300"))
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
USE_OLLAMA = os.getenv("USE_OLLAMA", "false").lower() == "true"


dosing_manager = DoseManager()

def enhance_query(user_query: str, plant_profile: dict) -> str:
    location = str(plant_profile.get("location", "Unknown"))
    plant_name = plant_profile.get("plant_name", "Unknown Plant")
    plant_type = plant_profile.get("plant_type", "Unknown Type")
    growth_stage = plant_profile.get("growth_stage", "Unknown Stage")
    seeding_date = plant_profile.get("seeding_date", "Unknown Date")
    additional_context = (
        f"Please consider that the plant '{plant_name}' of type '{plant_type}' is in the '{growth_stage}' stage, "
        f"seeded on {seeding_date}, and located in {location}. Provide precise nutrient dosing recommendations based on current sensor data."
    )
    if location.lower() not in user_query.lower():
        return f"{user_query}. {additional_context}"
    return user_query

def parse_json_response(json_str: str) -> Union[List[str], dict]:
    try:
        data = json.loads(json_str)
    except json.JSONDecodeError:
        # Split into lines if JSON parsing fails
        paragraphs = json_str.split("\n")
        result = [para.strip() for para in paragraphs if para.strip()]
        return result
    return data

def parse_ollama_response(raw_response: str) -> str:
    # Remove any <think> block and extra whitespace
    cleaned = re.sub(r"<think>.*?</think>", "", raw_response, flags=re.DOTALL).strip()
    return cleaned

def parse_openai_response(raw_response: str) -> str:
    """Extracts and cleans OpenAI's response to match Ollama's JSON format."""
    
    # Remove any <think> blocks (if present)
    cleaned = re.sub(r"<think>.*?</think>", "", raw_response, flags=re.DOTALL).strip()
    start = cleaned.find('{')
    end = cleaned.rfind('}')

    if start == -1 or end == -1 or end <= start:
        logger.error(f"No valid JSON block found in OpenAI response: {cleaned}")
        raise ValueError("Invalid JSON response from OpenAI")

    cleaned_json = cleaned[start:end+1]

    # Attempt to parse and reformat to ensure valid JSON
    try:
        parsed_response = json.loads(cleaned_json)
        return json.dumps(parsed_response)  # Ensure JSON consistency
    except json.JSONDecodeError as e:
        logger.error(f"Malformed JSON from OpenAI: {cleaned_json}")
        raise ValueError("Malformed JSON from OpenAI") from e


async def build_dosing_prompt(device: Device, sensor_data: dict, plant_profile: dict) -> str:
    """
    Creates a text prompt that asks the LLM for a JSON-based dosing plan.
    """
    if not device.pump_configurations:
        raise ValueError(f"Device {device.id} has no pump configurations available")
    
    pump_info = "\n".join([
        f"Pump {pump['pump_number']}: {pump['chemical_name']} - {pump.get('chemical_description', 'No description')}"
        for pump in device.pump_configurations
    ])
    plant_info = (
        f"Plant: {plant_profile.get('plant_name', 'Unknown')}\n"
        f"Type: {plant_profile.get('plant_type', 'Unknown')}\n"
        f"Growth Stage: {plant_profile.get('growth_stage', 'N/A')} days\n"
        f"Seeding Date: {plant_profile.get('seeding_date', 'N/A')}\n"
        f"Region: {plant_profile.get('region', 'Bangalore')}\n"
        f"Location: {plant_profile.get('location', 'Bangalore')}\n"
        f"Target pH Range: {plant_profile.get('target_ph_min', '3')} - {plant_profile.get('target_ph_max', '4')}\n"
        f"Target TDS Range: {plant_profile.get('target_tds_min', '150')} - {plant_profile.get('target_tds_max', '1000')}\n"
    )
    prompt = (
        "You are an expert hydroponic system manager. Based on the following information, determine optimal nutrient dosing amounts.\n\n"
        "Current Sensor Readings:\n"
        f"- pH: {sensor_data.get('ph', 'Unknown')}\n"
        f"- TDS (PPM): {sensor_data.get('tds', 'Unknown')}\n\n"
        "Plant Information:\n"
        f"{plant_info}\n\n"
        "Available Dosing Pumps:\n"
        f"{pump_info}\n\n"
        "Provide dosing recommendations in the following JSON format:\n"
        '{\n'
        '  "actions": [\n'
        '    {\n'
        '      "pump_number": 1,\n'
        '      "chemical_name": "Nutrient A",\n'
        '      "dose_ml": 50,\n'
        '      "reasoning": "Brief explanation"\n'
        '    }\n'
        '  ],\n'
        '  "next_check_hours": 24\n'
        '}\n\n'
        "Consider:\n"
        "1. Current pH and TDS levels\n"
        "2. Plant growth stage\n"
        "3. Chemical interactions\n"
        "4. Maximum safe dosing limits\n\n"
        "5. You **must NOT** create additional pumps beyond those listed above.\n"
        "Please provide a JSON response with exactly two keys: 'actions' (a list) and 'next_check_hours' (a number). "
        "Do not include any additional text or formatting. Limit your answer to 300 tokens."
    )
    return prompt

async def build_plan_prompt(sensor_data: dict, plant_profile: dict, query: str) -> str:
    """
    Creates a detailed text prompt for a growing plan.
    Optionally uses a Serper-based web search to gather additional detailed context.
    """
    plant_info = (
        f"Plant: {plant_profile['plant_name']}\n"
        f"Plant Type: {plant_profile['plant_type']}\n"
        f"Growth Stage: {plant_profile['growth_stage']} days from seeding (seeded at {plant_profile['seeding_date']})\n"
        f"Region: {plant_profile.get('region', 'Unknown')}\n"
        f"Location: {plant_profile.get('location', 'Unknown')}"
    )
    promptPlan = f"""
You are an expert hydroponic system manager. Based on the following information, determine optimal nutrient dosing amounts.

Plant Information:
{plant_info}

Current Sensor Readings:
- pH: {sensor_data.get('P','Unknown')}
- TDS (PPM): {sensor_data.get('TDS','Unknown')}

Provide an efficient and optimized solution according to the plant's location, local weather conditions, and soil conditions.

Consider:
1. Place of planting
2. Plant growth stage
3. Chemical interactions
4. Maximum safe dosing limits

Provide a detailed growing plan for {plant_profile['plant_name']} based on the {plant_profile['location']}. Include the best months for planting and the total growing duration. Specify pH and TDS requirements based on the local soil and water conditions. If the query mentions 'seeding' or 'growing,' tailor the plan accordingly. Break down the process into clear steps, covering:

1. Ideal Planting Time
2. Growth Duration
3. Soil and Water Conditions
4. Seeding Stage
5. Growing Stage
6. Harvesting Time
7. Additional Tips
""".strip()

    # Enhance the query with additional location context.
    enhanced_query = f"{query}. Focus on best practices in {plant_profile.get('region', 'Unknown')} for {plant_profile.get('plant_type', 'Unknown')} cultivation."

    # Gather additional data from a web search using Serper.
    search_results = await fetch_search_results(enhanced_query)
    organic_results = search_results.get("organic", [])
    if organic_results:
        # Process the top 5 results for a richer context.
        raw_info_list = []
        for entry in organic_results[:5]:
            title = entry.get("title", "No Title")
            snippet = entry.get("snippet", "No snippet available.")
            link = entry.get("link", None)
            info_str = f"â€¢ Title: {title}\n  Snippet: {snippet}"
            if link:
                info_str += f"\n  Link: {link}"
            raw_info_list.append(info_str)
        raw_info = "\n\n".join(raw_info_list)
    else:
        raw_info = "No additional information available."

    # Append a header to the additional information.
    final_prompt = f"{promptPlan}\n\nDetailed Search Insights:\n{raw_info}"
    return final_prompt.strip()


async def direct_ollama_call(prompt: str, model_name: str) -> str:
    """
    Calls the local Ollama API to run the prompt on the specified model.
    Returns the raw completion for further processing.
    """
    logger.info(f"Making direct Ollama call to model {model_name} with prompt:\n{prompt}")
    try:
        request_body = {
            "model": model_name,
            "prompt": prompt,
            "stream": False
        }
        async with httpx.AsyncClient(timeout=LLM_REQUEST_TIMEOUT) as client:
            response = await client.post(OLLAMA_URL, json=request_body)
            response.raise_for_status()
            data = response.json()
            raw_completion = data.get("response", "").strip()
            logger.info(f"Ollama raw completion: {raw_completion}")
            if not raw_completion:
                logger.error("No response received from Ollama.")
                raise HTTPException(status_code=500, detail="Empty response from LLM service")
            return raw_completion
    except Exception as e:
        logger.error(f"Ollama call failed: {e}")
        raise HTTPException(status_code=500, detail="Error calling LLM service") from e


async def direct_openai_text_call(prompt: str, model_name: str) -> str:
    client = openai.AsyncOpenAI(api_key=OPENAI_API_KEY)
    response = await client.chat.completions.create(
        model=model_name,
        messages=[{"role": "user", "content": prompt}],
        max_tokens=800,
        temperature=0.5
    )
    return response.choices[0].message.content.strip()


async def direct_openai_call(prompt: str, model_name: str) -> str:
    """
    Calls OpenAI's API to generate a response and formats it like Ollama's.
    """
    if not OPENAI_API_KEY:
        raise ValueError("OpenAI API Key is missing. Set it as an environment variable.")

    logger.info(f"Making OpenAI call to model {model_name} with prompt:\n{prompt}")

    try:
        client = openai.AsyncOpenAI(api_key=OPENAI_API_KEY)
        response = await client.chat.completions.create(
            model=model_name,
            messages=[{"role": "user", "content": prompt}],
            max_tokens=600
        )
        logger.info(f"OpenAI response: {response}")
        
        raw_completion = response.choices[0].message.content.strip()
        cleaned_response = parse_openai_response(raw_completion)
        
        logger.info(f"OpenAI cleaned response: {cleaned_response}")
        return cleaned_response
    except Exception as e:
        logger.error(f"OpenAI call failed: {e}")
        raise HTTPException(status_code=500, detail="Error calling OpenAI LLM") from e
    
def validate_llm_response(response: Dict) -> None:
    """
    Validates that the parsed JSON response has a top-level 'actions' list with the required keys.
    """
    if not isinstance(response, dict):
        raise ValueError("Response must be a dictionary")
    if "actions" not in response:
        raise ValueError("Response must contain 'actions' key")
    if not isinstance(response["actions"], list):
        raise ValueError("'actions' must be a list")
    for action in response["actions"]:
        required_keys = {"pump_number", "chemical_name", "dose_ml", "reasoning"}
        if not all(key in action for key in required_keys):
            raise ValueError(f"Action missing required keys: {required_keys}")
        if not isinstance(action["dose_ml"], (int, float)) or action["dose_ml"] < 0:
            raise ValueError("dose_ml must be a positive number")

async def call_llm_async(prompt: str, model_name: str = MODEL_1_5B) -> Tuple[Dict, str]:
    """
    Calls either Ollama or OpenAI and ensures the response format is consistent.
    Returns:
      - The parsed JSON response.
      - The full raw completion for UI display.
    """
    logger.info(f"Sending prompt to LLM:\n{prompt}")

    if USE_OLLAMA:
        raw_completion = await direct_ollama_call(prompt, model_name)
        cleaned = parse_ollama_response(raw_completion).replace("'", '"').strip()
        start = cleaned.find('{')
        end = cleaned.rfind('}')
        if start == -1 or end == -1 or end <= start:
          logger.error("No valid JSON block found in cleaned response.")
          raise HTTPException(status_code=500, detail="Invalid JSON from LLM")
        cleaned_json = cleaned[start:end+1]   
    else:
        raw_completion = await direct_openai_call(prompt, GPT_MODEL)  
        cleaned_json = parse_openai_response(raw_completion)  

    logger.info(f"Raw response from LLM:\n{raw_completion}")

    # Validate JSON structure
    try:
        parsed_response = json.loads(cleaned_json)
    except json.JSONDecodeError as e:
        logger.error(f"Invalid JSON from LLM after extraction: {cleaned_json}")
        raise HTTPException(status_code=500, detail="Invalid JSON from LLM") from e
    return parsed_response, raw_completion

async def call_llm_plan(prompt: str, model_name: str = MODEL_1_5B) -> str:
    """
    Calls the local Ollama API for a freeform plan.
    Returns the raw text (which may include a <think> block) for display.
    """
    logger.info(f"Sending plan prompt to LLM:\n{prompt}")
    if USE_OLLAMA:
       raw_completion = await direct_ollama_call(prompt, model_name)
    else:
       logger.info(f" plan raw text: {GPT_MODEL}")
       raw_completion = await direct_openai_text_call(prompt, GPT_MODEL)   
    logger.info(f"Ollama plan raw text: {raw_completion}")
    return raw_completion

async def execute_dosing_plan(device: Device, dosing_plan: Dict) -> Dict:
    """
    Executes the dosing plan by calling the deviceâ€™s /pump endpoint for each dosing action.
    """
    if not device.http_endpoint:
        raise ValueError(f"Device {device.id} has no HTTP endpoint configured")
    message = {
        "timestamp": datetime.utcnow().isoformat(),
        "device_id": device.id,
        "actions": dosing_plan.get("actions", []),
        "next_check_hours": dosing_plan.get("next_check_hours", 24)
    }
    
    logger.info(f"Dosing plan for device {device.id}: {message}")
    async with httpx.AsyncClient() as client:
        for action in dosing_plan.get("actions", []):
            pump_number = action.get("pump_number")
            dose_ml = action.get("dose_ml")
            endpoint = device.http_endpoint if device.http_endpoint.startswith("http") else f"http://{device.http_endpoint}"
            try:
                logger.info(f"Pump activation started")
                response = await client.post(
                    f"{endpoint}/pump",
                    json={"pump": pump_number, "amount": int(dose_ml)},
                    timeout=10
                )
                response_data = response.json()
                success_message = response_data.get("message") or response_data.get("msg")
                if response.status_code == 200 and success_message == "Pump started":
                    logger.info(f"Pump {pump_number} activated successfully: {response_data}")
                else:
                      logger.error(f"Failed to activate pump {pump_number}: {response_data}")

            except httpx.RequestError as e:
                logger.error(f"HTTP request to pump {pump_number} failed: {e}")
                raise HTTPException(status_code=500, detail=f"Pump {pump_number} activation failed") from e
    return message

async def getSensorData(device: Device) -> dict:
    """
    Retrieves sensor data from the deviceâ€™s /monitor endpoint.
    """
    if not device.http_endpoint:
        raise ValueError(f"Device {device.id} has no HTTP endpoint configured")
    logger.info(f"Fetching sensor data for device {device.id}")
    endpoint = device.http_endpoint if device.http_endpoint.startswith("http") else f"http://{device.http_endpoint}"
    async with httpx.AsyncClient() as client:
        try:
            response = await client.get(f"{endpoint}/monitor", timeout=10)
            response.raise_for_status()
            data = response.json()
            logger.info(f"Sensor data for device {device.id}: {data}")
            return data
        except Exception as e:
            logger.error(f"Error fetching sensor data: {e}")
            raise HTTPException(status_code=500, detail="Failed to fetch sensor data") from e

async def process_dosing_request(
    device_id: str,
    sensor_data: dict,
    plant_profile: dict,
    db: AsyncSession
) -> Tuple[Dict, str]:
    """
    Triggered by the dosing endpoint; builds a prompt, calls the LLM,
    parses the JSON dosing plan, and executes it.
    Returns the execution result and the raw LLM response.
    """
    try:
        device = await dosing_manager.get_device(device_id, db)
        if not device.pump_configurations:
            raise ValueError(f"Device {device.id} has no pump configurations available")
        if not device.http_endpoint:
            raise ValueError(f"Device {device.id} has no HTTP endpoint configured")
        prompt = await build_dosing_prompt(device, sensor_data, plant_profile)
        dosing_plan, ai_response = await call_llm_async(prompt=prompt, model_name=MODEL_1_5B)
        result = await execute_dosing_plan(device, dosing_plan)
        return result, ai_response
    except ValueError as ve:
        logger.error(f"ValueError in dosing request: {ve}")
        raise HTTPException(status_code=400, detail=str(ve))
    except json.JSONDecodeError as je:
        logger.error(f"JSON Parsing Error: {je}")
        raise HTTPException(status_code=500, detail="Invalid JSON format from LLM")
    except Exception as e:
        logger.exception(f"Unexpected error: {e}")
        raise HTTPException(status_code=500, detail="An unexpected error occurred") from e

async def process_sensor_plan(
    device_id: str,
    sensor_data: dict,
    plant_profile: dict,
    query: str,
    db: AsyncSession
):
    """
    Triggered by the plan endpoint; builds a prompt, calls the LLM,
    and returns a structured growing plan.
    """
    try:
        device = await dosing_manager.get_device(device_id, db)
        if not device.http_endpoint:
            raise ValueError(f"Device {device.id} has no HTTP endpoint configured")
        prompt = await build_plan_prompt(sensor_data, plant_profile, query)
        sensor_plan_raw = await call_llm_plan(prompt, MODEL_1_5B)
        beautify_response = parse_json_response(sensor_plan_raw)
        if isinstance(beautify_response, list):
            beautify_response = {"plan": "\n".join(beautify_response)}
        return beautify_response
    except ValueError as ve:
        logger.error(f"ValueError in sensor plan request: {ve}")
        raise HTTPException(status_code=400, detail=str(ve))
    except json.JSONDecodeError as je:
        logger.error(f"JSON Parsing Error: {je}")
        raise HTTPException(status_code=500, detail="Invalid format from LLM")
    except Exception as e:
        logger.exception(f"Unexpected error in sensor plan: {e}")
        raise HTTPException(status_code=500, detail="An unexpected error occurred") from e

async def call_llm(prompt: str, model_name: str) -> Dict:
    """
    Utility function that calls the LLM and returns the parsed JSON response.
    """
    logger.info(f"Calling LLM with model {model_name}, prompt:\n{prompt}")
    if USE_OLLAMA:
       raw_completion = await direct_ollama_call(prompt, model_name)
       cleaned = parse_ollama_response(raw_completion).replace("'", '"').strip()
    else:
       raw_completion = await direct_openai_call(prompt, GPT_MODEL)  
       cleaned =  parse_openai_response(raw_completion).replace("'", '"').strip()  
    try:
        parsed_response = json.loads(cleaned)
    except json.JSONDecodeError:
        logger.error(f"Invalid JSON from LLM: {raw_completion}")
        raise HTTPException(status_code=500, detail="Invalid JSON from LLM")
    return parsed_response

async def analyze_transport_options(origin: str, destination: str, weight_kg: float) -> Dict:
    prompt = f"""
    You are a logistics expert. Analyze the best railway and trucking options for transporting goods.
    - Origin: {origin}
    - Destination: {destination}
    - Weight: {weight_kg} kg

    Provide a JSON output with estimated cost, time, and best transport mode.
    """
    return await call_llm(prompt, MODEL_1_5B)

async def analyze_market_price(produce_type: str) -> Dict:
    prompt = f"""
    You are a market analyst. Provide the latest price per kg of {produce_type} in major cities.
    - Provide an approximate or typical value if uncertain.
    - Output must be valid JSON.
    """
    return await call_llm(prompt, MODEL_1_5B)

async def generate_final_decision(transport_analysis: Dict, market_price: Dict) -> Dict:
    prompt = f"""
    You are an AI supply chain consultant. Based on the transport analysis and market price insights, 
    determine if this transportation plan is profitable.

    Transport Analysis:
    {json.dumps(transport_analysis, indent=2)}

    Market Price Data:
    {json.dumps(market_price, indent=2)}

    Provide a JSON output with the final decision and reasoning.
    """
    return await call_llm(prompt, MODEL_7B) 


----- app/services/device_controller.py -----
# device_controller.py
import logging
import asyncio
from datetime import datetime
from typing import Dict, Optional
import httpx
from fastapi import HTTPException
import re
logger = logging.getLogger(__name__)
from app.schemas import DeviceType

class DeviceController:
    """
    Unified controller for the dosing and monitoring device.
    Provides methods for:
      - Discovering the device via its /discovery endpoint.
      - Executing dosing commands via /pump or the combined /dose_monitor endpoint.
      - Fetching sensor readings via the /monitor endpoint.
    """
    def __init__(self, device_ip: str, request_timeout: float = 10.0):
        self.device_ip = device_ip
        self.request_timeout = request_timeout

    async def discover(self) -> Optional[Dict]:
        """
        Try /discovery first; if that fails, assume it's a valve controller and call /state.
        """
        async with httpx.AsyncClient(timeout=self.request_timeout) as client:
            # 1) Try standard discovery
            try:
                url = await self._build_url("discovery")
                res = await client.get(url)
                if res.status_code == 200:
                    data = res.json()
                    data["ip"] = self.device_ip
                    return data
            except Exception:
                logger.debug(f"/discovery failed for {self.device_ip}, trying /state")

            # 2) Fallback to valve controller /state
            try:
                url = await self._build_url("state")
                res = await client.get(url)
                res.raise_for_status()
                state = res.json()
                # expect { device_id, valves: [ {id, state}, â€¦ ] }
                return {
                    "device_id": state.get("device_id"),
                    "type": DeviceType.VALVE_CONTROLLER.value,
                    "valves": state.get("valves", []),
                    "ip": self.device_ip
                }
            except Exception as e:
                logger.debug(f"/state discovery failed for {self.device_ip}: {e}")

        return None

    async def get_version(self) -> str:
        """
        Try /version first, fallback to /discovery.
        """
        async with httpx.AsyncClient(timeout=self.request_timeout) as client:
            url = await self._build_url("version")
            try:
                res = await client.get(url)
                if res.status_code == 200:
                    data = res.json()
                    # assume { version: "x.y.z" }
                    return data.get("version")
            except Exception:
                pass
            # fallback
            disc = await self.discover()
            return disc.get("version") if disc else None

    async def get_sensor_readings(self) -> Dict:
        """
        Retrieve averaged sensor readings from the device via the /monitor endpoint.
        (The device now returns averaged pH and TDS values.)
        """
        url = f"http://{self.device_ip}/monitor"
        try:
            async with httpx.AsyncClient(timeout=self.request_timeout) as client:
                response = await client.get(url)
                if response.status_code == 200:
                    data = response.json()
                    logger.info(f"Sensor readings from {self.device_ip}: {data}")
                    return data
                else:
                    raise HTTPException(status_code=response.status_code, detail=f"Sensor reading failed: {response.text}")
        except Exception as e:
            logger.error(f"Error fetching sensor readings: {e}")
            raise HTTPException(status_code=500, detail=str(e))
    async def cancel_dosing(self) -> Dict:
        """
        Cancel dosing by sending a stop command to the device.
        Uses the /pump_calibration endpoint with {"command": "stop"}.
        """
        url = f"http://{self.device_ip}/pump_calibration"
        payload = {"command": "stop"}
        try:
            async with httpx.AsyncClient(timeout=self.request_timeout) as client:
                response = await client.post(url, json=payload)
                if response.status_code == 200:
                    logger.info(f"Cancellation command sent to {url}: {payload}")
                    return response.json()
                else:
                    raise HTTPException(status_code=response.status_code, detail=f"Cancellation failed: {response.text}")
        except Exception as e:
            logger.error(f"Error sending cancellation command: {e}")
            raise HTTPException(status_code=500, detail=str(e))
    
    async def _build_url(self, path: str) -> str:
        base = self.device_ip
        if not base.startswith(("http://","https://")):
            base = f"http://{base}"
        return f"{base.rstrip('/')}/{path.lstrip('/')}"
    
    async def execute_dosing(self, pump: int, amount: int, combined: bool = False) -> Dict:
        endpoint = "dose_monitor" if combined else "pump"
        url = await self._build_url(endpoint)
        payload = {"pump": pump, "amount": amount, "timestamp": datetime.utcnow().isoformat()}
        async with httpx.AsyncClient(timeout=self.request_timeout) as client:
            resp = await client.post(url, json=payload)
            resp.raise_for_status()
            return resp.json()
    async def get_state(self) -> Dict:
        """
        Fetch the current valves state from /state.
        """
        url = await self._build_url("state")
        async with httpx.AsyncClient(timeout=self.request_timeout) as client:
            res = await client.get(url)
            res.raise_for_status()
            return res.json()

    async def toggle_valve(self, valve_id: int) -> Dict:
        """
        Toggle a single valve via /toggle.
        """
        url = await self._build_url("toggle")
        payload = {"valve_id": valve_id}
        async with httpx.AsyncClient(timeout=self.request_timeout) as client:
            res = await client.post(url, json=payload)
            res.raise_for_status()
            return res.json()

----- app/services/ph_tds.py -----
import logging
from typing import Dict
from fastapi import HTTPException
import httpx

logger = logging.getLogger(__name__)

async def get_ph_tds_readings(device_ip: str) -> Dict[str, float]:
    """
    Fetch pH and TDS readings from the device's /monitor endpoint directly,
    without using DeviceController.
    """
    url = f"{device_ip}/monitor"
    
    try:
        async with httpx.AsyncClient(timeout=10.0) as client:
            response = await client.get(url)
            response.raise_for_status()
            data = response.json()
            logger.info(f"[{device_ip}] Raw /monitor response: {data}")

            if "pH" in data and "TDS" in data:
                return {
                    "ph": float(data["pH"]),
                    "tds": float(data["TDS"])
                }
            else:
                raise HTTPException(status_code=500, detail=f"Invalid /monitor response: {data}")

    except Exception as e:
        logger.error(f"Failed to fetch pH/TDS from {device_ip}: {e}")
        raise HTTPException(status_code=500, detail=f"Error fetching from /monitor: {e}")


----- app/services/dosing_profile_service.py -----
# dosing_profile_service.py
import json
import logging
from datetime import datetime
from typing import Dict
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.future import select
from fastapi import HTTPException
from app.models import Device, DosingProfile
from app.services.device_controller import DeviceController
from app.services.ph_tds import get_ph_tds_readings  # Ensure this returns averaged values
from app.services.llm import call_llm_async, build_dosing_prompt

logger = logging.getLogger(__name__)


async def set_dosing_profile_service(profile_data: dict, db: AsyncSession) -> dict:
    """
    Set the dosing profile for a unified dosing/monitoring device.
    This function uses the unified device for both sensor reading and dosing.
    """
    device_id = profile_data.get("device_id")
    if not device_id:
        raise HTTPException(status_code=400, detail="Device ID is required in profile data")
    
    # Retrieve the unified device from the database.
    result = await db.execute(select(Device).where(Device.id == device_id))
    dosing_device = result.scalars().first()
    
    if not dosing_device:
        # If the device is not found, attempt discovery via the unified controller.
        device_ip = profile_data.get("device_ip")
        if not device_ip:
            raise HTTPException(status_code=404, detail="Unified device not found and device_ip not provided")
        controller = DeviceController(device_ip=device_ip)
        discovered_device = await controller.discover()
        if discovered_device:
            new_device = Device(
                name=discovered_device.get("name", "Discovered Unified Device"),
                type="dosing_unit",  # Using the same type for unified devices
                http_endpoint=discovered_device.get("http_endpoint"),
                location_description=discovered_device.get("location_description", ""),
                pump_configurations=[],  # Can be updated later if needed
                is_active=True
            )
            db.add(new_device)
            try:
                await db.commit()
                await db.refresh(new_device)
                dosing_device = new_device
            except Exception as exc:
                await db.rollback()
                raise HTTPException(status_code=500, detail=f"Error adding discovered device: {exc}") from exc
        else:
            raise HTTPException(status_code=404, detail="Unified dosing device not found and could not be discovered")
    
    # For the unified device, use its HTTP endpoint to get sensor readings.
    sensor_ip = dosing_device.http_endpoint
    logger.info(f"Fetching pH/TDS readings from device at {sensor_ip}")
    try:
        readings = await get_ph_tds_readings(sensor_ip)
    except Exception as exc:
        raise HTTPException(
            status_code=500,
            detail=f"Error fetching PH/TDS readings: {exc}"
        ) from exc

    ph = readings.get("ph")
    tds = readings.get("tds")

    # Build a comprehensive dosing prompt using the unified device details.
    # (Now using the unified device instance, averaged sensor values, and profile_data.)
    prompt = await build_dosing_prompt(dosing_device, {"ph": ph, "tds": tds}, profile_data)
    try:
        llm_response, raw_llm = await call_llm_async(prompt)
        logger.info(f"LLM response: {llm_response}")
        if isinstance(llm_response, str):
            result_json = json.loads(llm_response)
        elif isinstance(llm_response, list):
            result_json = {"actions": llm_response}
        elif isinstance(llm_response, dict):
            result_json = llm_response
        else:
            raise ValueError("Unexpected response format from LLM.")
        
        recommended_dose = result_json.get("actions", [])
    except Exception as exc:
        raise HTTPException(
            status_code=500,
            detail=f"Error calling LLM: {exc}"
        ) from exc

    # Create a new dosing profile using the unified device.
    new_profile = DosingProfile(
        device_id=dosing_device.id,
        plant_name=profile_data.get("plant_name"),
        plant_type=profile_data.get("plant_type"),
        growth_stage=profile_data.get("growth_stage"),
        seeding_date=profile_data.get("seeding_date"),
        target_ph_min=profile_data.get("target_ph_min"),
        target_ph_max=profile_data.get("target_ph_max"),
        target_tds_min=profile_data.get("target_tds_min"),
        target_tds_max=profile_data.get("target_tds_max"),
        dosing_schedule=profile_data.get("dosing_schedule")
    )
    db.add(new_profile)
    try:
        await db.commit()
        await db.refresh(new_profile)
    except Exception as exc:
        await db.rollback()
        raise HTTPException(
            status_code=500,
            detail=f"Error saving dosing profile: {exc}"
        ) from exc

    return {"recommended_dose": recommended_dose, "profile": new_profile}


----- app/services/plant_service.py -----
import logging
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.future import select
from fastapi import HTTPException
from app.models import Plant
logger = logging.getLogger(__name__)

async def get_all_plants(db: AsyncSession):
    """Retrieve all plants from the database."""
    try:
        logger.info("Fetching plants from database...")

        # Fetch plants
        result = await db.execute(select(Plant))
        plants = result.scalars().all()

        if not plants:
            logger.info("No plants found, returning an empty list.")
            return []

        logger.info(f"Fetched {len(plants)} plants from the database")
        return plants

    except Exception as e:
        logger.error(f"Database query failed: {str(e)}")
        return []


async def get_plant_by_id(plant_id: int, db: AsyncSession):
    """Retrieve a specific plant by ID."""
    plant = await db.get(Plant, plant_id)
    if not plant:
        raise HTTPException(status_code=404, detail="Plant not found")
    return plant

async def create_plant(plant_data, db: AsyncSession):
    """Create a new plant."""
    new_plant = Plant(**plant_data.model_dump())
    db.add(new_plant)
    await db.commit()
    await db.refresh(new_plant)
    return new_plant

async def delete_plant(plant_id: int, db: AsyncSession):
    """Delete a plant by ID."""
    plant = await db.get(Plant, plant_id)
    if not plant:
        raise HTTPException(status_code=404, detail="Plant not found")
    await db.delete(plant)
    await db.commit()
    return {"message": "Plant deleted successfully"}


----- app/services/ping.py -----
import asyncio
from asyncio.subprocess import PIPE

async def ping_host(ip: str, timeout: float = 1.0) -> bool:
    # Using Linux-style ping: '-c 1' for one packet, '-W' for timeout in seconds
    proc = await asyncio.create_subprocess_exec(
        "ping", "-c", "1", "-W", str(int(timeout)),
        ip,
        stdout=PIPE, stderr=PIPE
    )
    try:
        await asyncio.wait_for(proc.communicate(), timeout=timeout + 1)
    except asyncio.TimeoutError:
        proc.kill()
        return False
    return proc.returncode == 0


======= Directory: device code =======

----- device code/CCTV/code.ino -----
/*****************************************************************************************
 *  HYDROLEAF SMARTâ€‘CAM  â€“  Production Firmware  v3.2  (03â€‘Mayâ€‘2025)
 *  Target  : ESP32â€‘CAM (AIâ€‘Thinker) â€“ 4â€¯MB flash, PSRAM enabled
 *  Author  : ChatGPTÂ (o3)
 *
 *  CHANGELOG
 *  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 *  â€¢ Fixed compileâ€‘error (StringSumHelper â†’ const char*) on all HTTPClient::begin().
 *  â€¢ Filled in every previously â€œomittedâ€ helper so the sketch is 100â€¯% complete.
 *  â€¢ Minor tidyâ€‘ups (const correctness, tighter scopes, explicit casts).
 *
 *  Backend contract (matches FastAPI):
 *    â€¢ Auth  :  POST  /api/v1/cloud/authenticate
 *    â€¢ Upload:  POST  /upload/<cam_id>/{day,night}
 *    â€¢ OTA    :  GET   /api/v1/device_comm/update?device_id=<cam_id>
 *****************************************************************************************/

#pragma GCC optimize("Os")
#include <ArduinoJson.h>
#include <WiFi.h>
#include <WebServer.h>
#include <DNSServer.h>
#include <Preferences.h>
#include <esp_camera.h>
#include <Update.h>
#include <HTTPClient.h>
#include <time.h>

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€ GPIO map (AIâ€‘Thinker) â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
#define PWDN_GPIO_NUM 32
#define RESET_GPIO_NUM -1
#define XCLK_GPIO_NUM 0
#define SIOD_GPIO_NUM 26
#define SIOC_GPIO_NUM 27
#define Y9_GPIO_NUM 35
#define Y8_GPIO_NUM 34
#define Y7_GPIO_NUM 39
#define Y6_GPIO_NUM 36
#define Y5_GPIO_NUM 21
#define Y4_GPIO_NUM 19
#define Y3_GPIO_NUM 18
#define Y2_GPIO_NUM 5
#define VSYNC_GPIO_NUM 25
#define HREF_GPIO_NUM 23
#define PCLK_GPIO_NUM 22
#define LED_STATUS 33
#define BTN_CONFIG 4
#define PIN_LDR 14
#define PIN_IRLED 12

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€ Cloud endâ€‘points (portÂ 80 via proxy) â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
static const char* BACKEND_HOST = "cloud.hydroleaf.in";
static const char* AUTH_PATH = "/api/v1/cloud/authenticate";
static const char* UPLOAD_PRFX = "/upload/";  // +<cam_id>/{day,night}
static const char* UPDATE_CHECK_PRFX = "/api/v1/device_comm/update?device_id=";

/* unique per board â€“ keep safe */
static const char* CLOUD_KEY = "371688b7edd0dbf049c5344ead7f4c6a";

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€ timings â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
#define WIFI_RETRY_MS (30UL * 1000UL)
#define FRAME_IVL_MS 1000UL
#define UPDATE_IVL_MS (6UL * 60UL * 60UL * 1000UL)

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€ globals â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
Preferences prefs;
WebServer http(80);
DNSServer dns;
sensor_t* cam = nullptr;
bool camReady = false;
bool nightMode = false;

String ssid, pass, apPass, camId, jwt;
bool activated = false;

static unsigned long lastWifiTry = 0;
static unsigned long lastFrameTx = 0;
static unsigned long lastUpdateChk = 0;

/* â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 1.  Tiny RAM logger â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• */
#define LOG_BUF_SZ 2048
static char logBuf[LOG_BUF_SZ];
static size_t logHead = 0;
void logLine(const char* msg) {
  const size_t n = strlen(msg);
  if (n + 2 > LOG_BUF_SZ) return;
  if (n + logHead + 2 >= LOG_BUF_SZ) logHead = 0;  // wrap
  memcpy(logBuf + logHead, msg, n);
  logBuf[logHead + n] = '\n';
  logBuf[logHead + n + 1] = 0;
  logHead += n + 1;
  Serial.println(msg);
}

/* â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 2.  helpers / fwd decls â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• */
void generateCameraId();
bool wifiConnect(uint8_t retryMax = 5);
bool cloudAuthenticate();
void initCamera();
void applyDayParams();
bool sendFrame();
void updateLDR();
void handleButton();
void portalStart();
void setupRoutes();
void checkCloudOta();

/* â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 3.  NVS helpers â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• */
inline void putStr(const char* k, const String& v) {
  prefs.begin("cam_cfg", false);
  prefs.putString(k, v);
  prefs.end();
}
inline void putBool(const char* k, bool v) {
  prefs.begin("cam_cfg", false);
  prefs.putBool(k, v);
  prefs.end();
}

/* â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 4.  LED heartbeat â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• */
inline void beatLED() {
  static uint32_t t = 0;
  if (millis() - t < 3000) return;
  t = millis();
  digitalWrite(LED_STATUS, HIGH);
  delay(20);
  digitalWrite(LED_STATUS, LOW);
}

/* â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 5.  HTML helpers â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• */
String header(const char* title) {
  String h = String(F(/* â†â€‘â€‘ convert the very first F() to String */
                      "<!doctype html><html><head><meta charset=utf-8>"
                      "<meta name=viewport content='width=device-width,initial-scale=1'><title>"));
  h += title;
  h += F(
    "</title><style>body{font-family:system-ui;background:#fafafa;margin:0;padding:18px}"
    "h1{font-size:20px}pre{background:#222;color:#0f0;padding:12px;overflow:auto}"
    "a,button{display:block;width:100%;padding:10px;margin:8px 0;border:0;background:#007bff;color:#fff;"
    "font-size:16px;text-align:center;text-decoration:none;border-radius:4px}</style></head><body>");
  return h;
}

/* â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 6.  Web pages â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• */
void pageMenu() {
  const String ipSta = WiFi.isConnected() ? WiFi.localIP().toString() : "â€”";
  String page = header("Smartâ€‘Cam Menu");

  page += String(F("<h1>Hydroleaf Smartâ€‘Cam</h1>"
                   "<p><b>ID:</b> "))
          + camId + F("<br><b>STAÂ IP:</b> ") + ipSta + F("<br><b>APÂ IP:</b> 192.168.0.1<br><b>CloudÂ Key:</b> ") + CLOUD_KEY + F("</p>"
                                                                                                                                "<a href='/wifi'>Configureâ€¯Wiâ€‘Fi</a>"
                                                                                                                                "<a href='/logs'>Viewâ€¯Logs</a>"
                                                                                                                                "</body></html>");

  http.send(200, "text/html", page);
}


void pageLogs() {
  String page = header("Logs");
  page += "<pre>";
  /* print from logHead..end then 0..logHead */
  page += String(logBuf + logHead);
  page += String(logBuf);
  page += "</pre><a href='/'>Back</a></body></html>";
  http.send(200, "text/html", page);
}

/* â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 7.  Pushâ€‘OTA handler â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• */
void pushUpload() {
  HTTPUpload& up = http.upload();
  if (up.status == UPLOAD_FILE_START) {
    if (!http.hasHeader("X-OTA-KEY") || http.header("X-OTA-KEY") != CLOUD_KEY) {
      http.send(403, "text/plain", "Forbidden");
      return;
    }
    logLine("[OTA] pushâ€‘start");
    Update.begin(UPDATE_SIZE_UNKNOWN);
  } else if (up.status == UPLOAD_FILE_WRITE) {
    if (Update.write(up.buf, up.currentSize) != up.currentSize)
      Update.printError(Serial);
  } else if (up.status == UPLOAD_FILE_END) {
    const bool ok = Update.end(true);
    logLine(ok ? "[OTA] pushâ€‘done" : "[OTA] pushâ€‘FAIL");
    http.send(ok ? 200 : 500, "text/plain",
              ok ? "OK â€“ rebooting" : "FAIL");
    delay(400);
    ESP.restart();
  }
}

/* â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 8.  Routes & captive portal â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• */
void setupRoutes() {
  http.on("/", HTTP_GET, pageMenu);
  http.on("/logs", HTTP_GET, pageLogs);
  http.on(
    "/manual_update", HTTP_POST,
    []() {}, pushUpload);

  /* add /wifi etc. here if you have those pages */
  http.begin();
}

void portalStart() {
  WiFi.mode(WIFI_AP_STA);
  IPAddress ip(192, 168, 0, 1);
  WiFi.softAPConfig(ip, ip, IPAddress(255, 255, 255, 0));
  WiFi.softAP(camId.c_str(), apPass.c_str());
  dns.start(53, "*", ip);
  setupRoutes();
  logLine("[AP] captive portal ready");
}

/* â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 9.  Camera â”€ init & helpers â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• */
void applyDayParams() {
  if (!cam) return;
  prefs.begin("cam_cfg", true);
  cam->set_brightness(cam, prefs.getInt("bright", 1));
  cam->set_contrast(cam, prefs.getInt("contr", 1));
  cam->set_saturation(cam, prefs.getInt("sat", 1));
  cam->set_denoise(cam, prefs.getInt("dn", 5));
  prefs.end();
}

void initCamera() {
  camera_config_t cfg{};
  cfg.ledc_channel = LEDC_CHANNEL_0;
  cfg.ledc_timer = LEDC_TIMER_0;
  cfg.pin_d0 = Y2_GPIO_NUM;
  cfg.pin_d1 = Y3_GPIO_NUM;
  cfg.pin_d2 = Y4_GPIO_NUM;
  cfg.pin_d3 = Y5_GPIO_NUM;
  cfg.pin_d4 = Y6_GPIO_NUM;
  cfg.pin_d5 = Y7_GPIO_NUM;
  cfg.pin_d6 = Y8_GPIO_NUM;
  cfg.pin_d7 = Y9_GPIO_NUM;
  cfg.pin_xclk = XCLK_GPIO_NUM;
  cfg.pin_pclk = PCLK_GPIO_NUM;
  cfg.pin_vsync = VSYNC_GPIO_NUM;
  cfg.pin_href = HREF_GPIO_NUM;
  cfg.pin_sscb_sda = SIOD_GPIO_NUM;
  cfg.pin_sscb_scl = SIOC_GPIO_NUM;
  cfg.pin_pwdn = PWDN_GPIO_NUM;
  cfg.pin_reset = RESET_GPIO_NUM;
  cfg.xclk_freq_hz = 20'000'000;
  cfg.pixel_format = PIXFORMAT_JPEG;

  if (psramFound()) {
    cfg.frame_size = FRAMESIZE_HD;
    cfg.fb_count = 2;
    cfg.jpeg_quality = 12;
  } else {
    cfg.frame_size = FRAMESIZE_SVGA;
    cfg.fb_count = 1;
    cfg.jpeg_quality = 15;
  }

  if (esp_camera_init(&cfg) != ESP_OK) {
    logLine("[CAM] init failed");
    delay(500);
    ESP.restart();
  }
  cam = esp_camera_sensor_get();
  cam->set_hmirror(cam, 1);
  cam->set_vflip(cam, 0);
  applyDayParams();
  camReady = true;
  logLine("[CAM] ready");
}

/* â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 10.  Wiâ€‘Fi / Auth â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• */
bool wifiConnect(uint8_t retryMax) {
  WiFi.mode(WIFI_STA);
  for (uint8_t attempt = 0; attempt < retryMax; ++attempt) {
    logLine("[NET] connectingâ€¦");
    WiFi.begin(ssid.c_str(), pass.c_str());
    for (uint8_t i = 0; i < 50; ++i) {  // 10â€¯s
      if (WiFi.status() == WL_CONNECTED) {
        logLine(("[NET] IP " + WiFi.localIP().toString()).c_str());
        return true;
      }
      delay(200);
    }
    WiFi.disconnect(true);
    delay(200);
  }
  return false;
}

void generateCameraId() {
  prefs.begin("cam_cfg", false);
  camId = prefs.getString("camId", "");
  prefs.end();
  if (camId.length()) return;

  configTime(0, 0, "pool.ntp.org", "time.google.com");
  struct tm tm {};
  char buf[32] = "CAM";
  if (getLocalTime(&tm, 4000))
    strftime(buf, sizeof(buf), "CAM_%Y%m%d_%H%M%S", &tm);
  camId = String(buf) + "_" + String((uint32_t)esp_random(), HEX);
  putStr("camId", camId);
}

bool cloudAuthenticate() {
  HTTPClient cli;
  String url = String("http://") + BACKEND_HOST + AUTH_PATH;
  cli.begin(url.c_str());
  cli.addHeader("Content-Type", "application/json");
  String body = "{\"device_id\":\"" + camId + "\",\"cloud_key\":\"" + CLOUD_KEY + "\"}";
  const int code = cli.POST(body);
  String resp = cli.getString();
  cli.end();
  if (code != 200) {
    logLine("[AUTH] fail");
    return false;
  }

  DynamicJsonDocument doc(256);
  if (deserializeJson(doc, resp) != DeserializationError::Ok || !doc["token"].is<String>())
    return false;

  jwt = doc["token"].as<String>();
  putStr("token", jwt);
  activated = true;
  putBool("activated", true);
  logLine("[AUTH] success");
  return true;
}

/* â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 11.  Frame upload â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• */
bool sendFrame() {
  if (!camReady) return false;
  camera_fb_t* fb = esp_camera_fb_get();
  if (!fb) return false;

  String url = String("http://") + BACKEND_HOST + UPLOAD_PRFX + camId + (nightMode ? "/night" : "/day");

  HTTPClient cli;
  cli.begin(url.c_str());
  cli.addHeader("Content-Type", "image/jpeg");
  if (jwt.length()) cli.addHeader("Authorization", "Bearer " + jwt);

  const int code = cli.POST(fb->buf, fb->len);
  cli.end();
  esp_camera_fb_return(fb);

  if (code == 401) {  // token expired
    jwt = "";
    putStr("token", "");
    activated = false;
    putBool("activated", false);
  }
  return (code >= 200 && code < 300);
}

/* â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 12.  LDR day/night â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• */
uint8_t ldrRing[5] = { 1, 1, 1, 1, 1 };
uint8_t ldrIdx = 0;

void updateLDR() {
  ldrRing[ldrIdx++] = digitalRead(PIN_LDR);
  if (ldrIdx >= 5) ldrIdx = 0;

  uint8_t dark = 0;
  for (uint8_t v : ldrRing)
    if (v == LOW) ++dark;

  if (dark >= 4 && !nightMode) {  // switch to night
    nightMode = true;
    digitalWrite(PIN_IRLED, HIGH);
    cam->set_whitebal(cam, 0);
    cam->set_awb_gain(cam, 0);
    cam->set_brightness(cam, 2);
    cam->set_contrast(cam, 2);
    cam->set_saturation(cam, -1);
    cam->set_denoise(cam, 7);
  } else if (dark <= 1 && nightMode) {  // back to day
    nightMode = false;
    digitalWrite(PIN_IRLED, LOW);
    applyDayParams();
    cam->set_whitebal(cam, 1);
    cam->set_awb_gain(cam, 1);
  }
}

/* â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 13.  Button (shortâ€‘press = portal, 3â€¯s = factory) â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• */
void handleButton() {
  static unsigned long down = 0;
  const bool pressed = (digitalRead(BTN_CONFIG) == LOW);

  if (pressed && !down) down = millis();
  if (!pressed && down) {
    const unsigned long held = millis() - down;
    down = 0;
    if (held >= 3000) {  // factory reset
      prefs.begin("cam_cfg", false);
      prefs.clear();
      prefs.end();
      logLine("[BTN] factory reset");
      delay(500);
      ESP.restart();
    } else if (held >= 100) {  // open portal
      portalStart();
    }
  }
}

/* â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 14.  OTA pull (check JSON, then download) â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• */
void checkCloudOta() {
  if (!WiFi.isConnected() || !activated) return;

  HTTPClient cli;
  String checkUrl = String("http://") + BACKEND_HOST + UPDATE_CHECK_PRFX + camId;
  cli.begin(checkUrl.c_str());
  int code = cli.GET();
  if (code != 200) {
    logLine("[OTA] check failed");
    cli.end();
    return;
  }

  DynamicJsonDocument doc(256);
  if (deserializeJson(doc, cli.getString()) != DeserializationError::Ok) {
    logLine("[OTA] bad JSON");
    cli.end();
    return;
  }
  cli.end();

  if (!doc["update_available"]) {
    logLine("[OTA] upâ€‘toâ€‘date");
    return;
  }

  const String binUrl = doc["download_url"].as<String>();
  logLine(("[OTA] downloading " + binUrl).c_str());

  cli.begin(binUrl.c_str());
  code = cli.GET();
  if (code != 200) {
    logLine("[OTA] pull 404/noâ€‘bin");
    cli.end();
    return;
  }

  const int len = cli.getSize();
  WiFiClient* s = cli.getStreamPtr();
  if (!Update.begin(len == 0 ? UPDATE_SIZE_UNKNOWN : len)) {
    Update.printError(Serial);
    cli.end();
    return;
  }

  uint8_t buf[256];
  size_t written = 0;
  while (cli.connected() && (written < len || len == 0)) {
    const size_t avail = s->available();
    if (avail) {
      const size_t rd = s->readBytes(buf, (avail > sizeof(buf) ? sizeof(buf) : avail));
      Update.write(buf, rd);
      written += rd;
    }
    delay(1);
  }
  const bool ok = Update.end() && Update.isFinished();
  logLine(ok ? "[OTA] SUCCESS â†’ reboot" : "[OTA] FAIL");
  cli.end();
  if (ok) {
    delay(400);
    ESP.restart();
  }
}

/* â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 15.  setup() â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• */
void setup() {
  Serial.begin(115200);
  pinMode(LED_STATUS, OUTPUT);
  digitalWrite(LED_STATUS, LOW);
  pinMode(BTN_CONFIG, INPUT_PULLUP);
  pinMode(PIN_LDR, INPUT_PULLUP);
  pinMode(PIN_IRLED, OUTPUT);
  digitalWrite(PIN_IRLED, LOW);

  /* load prefs */
  prefs.begin("cam_cfg", false);
  ssid = prefs.getString("ssid", "");
  pass = prefs.getString("pass", "");
  apPass = prefs.getString("apPass", "configme");
  jwt = prefs.getString("token", "");
  activated = prefs.getBool("activated", false);
  prefs.end();

  generateCameraId();

  if (ssid.length() && wifiConnect()) {
    if (!activated) activated = cloudAuthenticate();
    if (activated && !camReady) initCamera();
    if (activated) {
      checkCloudOta();
      lastUpdateChk = millis();
    }
  }
  portalStart();
}

/* â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 16.  loop() â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• */
void loop() {
  handleButton();
  updateLDR();
  beatLED();

  if (WiFi.status() != WL_CONNECTED && millis() - lastWifiTry > WIFI_RETRY_MS) {
    lastWifiTry = millis();
    logLine("[NET] Wiâ€‘Fi retry");
    if (wifiConnect() && activated && !camReady) initCamera();
  }

  if (activated && WiFi.status() == WL_CONNECTED && camReady && millis() - lastFrameTx > FRAME_IVL_MS) {
    sendFrame() ? logLine("[TX] frame OK") : logLine("[TX] frame FAIL");
    lastFrameTx = millis();
  }

  if (activated && WiFi.status() == WL_CONNECTED && millis() - lastUpdateChk > UPDATE_IVL_MS) {
    lastUpdateChk = millis();
    checkCloudOta();
  }

  dns.processNextRequest();
  http.handleClient();
}

----- device code/Smart Dosing Unit/code.ino -----
/**
 * Hydroleaf Smart Dosing Controller â€“ HTTPâ€‘only build (v3.1.1)
 * ------------------------------------------------------------
 *  âœ¦  Nonâ€‘blocking pumps   âœ¦  Wiâ€‘Fi watchdog                 *
 *  âœ¦  Cloud API heartbeat  âœ¦  HTTP OTA (no TLS certificate)  *
 */

#pragma GCC optimize("Os")

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. INCLUDES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
#include <WiFi.h>
#include <WebServer.h>
#include <DNSServer.h>
#include <Preferences.h>
#include <TFT_eSPI.h>
#include <HTTPClient.h>
#include <HTTPUpdate.h>  //  â† fixes ESPhttpUpdate error
#include <Update.h>
#include <ArduinoJson.h>
#include <esp_adc_cal.h>

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. HARDWARE MAP â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
#define RELAY_PUMP_1 26
#define RELAY_PUMP_2 27
#define RELAY_PUMP_3 14
#define RELAY_PUMP_4 12
#define PH_SENSOR_PIN 34
#define TDS_SENSOR_PIN 35
#define LED_STATUS 2

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. CONSTANTS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
static const uint8_t DNS_PORT = 53;
static const char* DEFAULT_AP_PASS = "hydroleaf";
static const char* CLOUD_HOST = "http://cloud.hydroleaf.in";  // HTTP!
static const char* OTA_PATH = "/api/v1/device_comm/update/pull?device_id=";
static const char* UPDATE_CHECK_PATH = "/api/v1/device_comm/update?device_id=";
static const char* HEARTBEAT_PATH = "/api/v1/device_comm/heartbeat";
static const char* FW_VERSION = "3.1.1";
static const char* DEVICE_TYPE = "dosing_unit";

/*  Timing  */
static const uint32_t HB_INTERVAL = 60UL * 1000;             // 1â€¯min
static const uint32_t UPDATE_INTERVAL = 60UL * 60UL * 1000;  // 1â€¯hr
static const uint32_t WIFI_WATCHDOG_MS = 120UL * 1000;       // 2â€¯min

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4. GLOBALS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
Preferences prefs;
WebServer http(80);
DNSServer dns;
TFT_eSPI tft;
esp_adc_cal_characteristics_t* adc_chars = nullptr;

String g_ssid, g_pass, g_apPass, g_deviceId;
bool g_wifiConnected = false;
uint32_t wifiLostSince = 0;

/*  Sensor cache  */
float pHValue = -1.0f;
float tdsValue = -1.0f;

/*  Nonâ€‘blocking pump state  */
struct PumpState {
  bool active = false;
  uint32_t startMs = 0, durMs = 0;
} pumps[4];

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5. UTILITIES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
void showStatus(const String& msg) {
  tft.fillScreen(TFT_BLACK);
  tft.setCursor(10, 100);
  tft.setTextColor(TFT_WHITE, TFT_BLACK);
  tft.setTextSize(2);
  tft.println(msg);
}
void setRelay(int idx, bool on) {
  digitalWrite(RELAY_PUMP_1 + idx - 1, on ? LOW : HIGH);
}
void savePref(const char* key, const String& v) {
  prefs.begin("doser_cfg", false);
  prefs.putString(key, v);
  prefs.end();
}

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€ 6. PUMP CONTROL â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
void schedulePump(int pump, uint32_t ms) {
  if (pump < 1 || pump > 4 || ms == 0) return;
  pumps[pump - 1] = { true, millis(), ms };
  setRelay(pump, true);
  showStatus("Pump#" + String(pump) + " ON");
}
void updatePumps() {
  uint32_t now = millis();
  for (int i = 0; i < 4; ++i)
    if (pumps[i].active && now - pumps[i].startMs >= pumps[i].durMs) {
      setRelay(i + 1, false);
      pumps[i].active = false;
      showStatus("Pump#" + String(i + 1) + " OFF");
    }
}

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€ 7. SENSOR READ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
void readSensors() {
  static uint32_t last = 0;
  if (millis() - last < 1000) return;
  last = millis();
  uint32_t sum = 0;
  for (int i = 0; i < 30; ++i) sum += analogRead(PH_SENSOR_PIN);
  float v = esp_adc_cal_raw_to_voltage(sum / 30, adc_chars) / 1000.0f;
  pHValue = constrain(7.0f + ((2.5f - v) / 0.18f), 0.0f, 14.0f);
  sum = 0;
  for (int i = 0; i < 30; ++i) sum += analogRead(TDS_SENSOR_PIN);
  float v2 = esp_adc_cal_raw_to_voltage(sum / 30, adc_chars) / 1000.0f;
  float cv = max(0.0f, v2 * (100.0f / 110.0f) - 0.12f);
  tdsValue = constrain(133.42f * pow(cv, 3) - 255.86f * pow(cv, 2) + 857.39f * cv, 0.0f, 2500.0f);
}

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€ 8. CLOUD I/O (HTTP) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
bool cloudGET(const String& url, String& payload) {
  HTTPClient cli;
  if (!cli.begin(url)) return false;
  int code = cli.GET();
  if (code == HTTP_CODE_OK) payload = cli.getString();
  cli.end();
  return code == HTTP_CODE_OK;
}
bool cloudPOST(const String& url, const String& body, String& resp) {
  HTTPClient cli;
  if (!cli.begin(url)) return false;
  cli.addHeader("Content-Type", "application/json");
  int code = cli.POST(body);
  if (code == HTTP_CODE_OK) resp = cli.getString();
  cli.end();
  return code == HTTP_CODE_OK;
}

/* OTA (HTTP) */
void checkForUpdate() {
  if (!g_wifiConnected) return;
  String body;
  if (!cloudGET(String(CLOUD_HOST) + UPDATE_CHECK_PATH + g_deviceId, body)) return;
  if (body.indexOf("\"update_available\":true") < 0) return;

  showStatus("OTA updatingâ€¦");
  WiFiClient client;
  httpUpdate.setLedPin(LED_STATUS, LOW);  // Blink LED while flashing
  httpUpdate.rebootOnUpdate(true);
  httpUpdate.update(client, String(CLOUD_HOST) + OTA_PATH + g_deviceId);
}

/* Heartbeat */
void sendHeartbeat() {
  if (!g_wifiConnected) return;
  StaticJsonDocument<256> d;
  d["device_id"] = g_deviceId;
  d["type"] = DEVICE_TYPE;
  d["version"] = FW_VERSION;
  String out;
  serializeJson(d, out);
  String resp;
  if (!cloudPOST(String(CLOUD_HOST) + HEARTBEAT_PATH, out, resp)) return;

  StaticJsonDocument<512> r;
  if (deserializeJson(r, resp) != DeserializationError::Ok) return;
  for (JsonObject t : r["tasks"].as<JsonArray>()) schedulePump(t["pump"] | 0, t["amount"] | 0);
}

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€ 9. WEB ROUTES (unchangedÂ +Â API) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
String htmlHeader(const String& title) {
  return "<!doctype html><html><head><meta charset='utf-8' "
         "name='viewport' content='width=device-width,initial-scale=1'><title>"
         + title + "</title><style>body{font-family:Arial;margin:0;padding:20px;}h2{margin-top:0;}"
                   "input,button{width:100%;padding:10px;margin:8px 0;font-size:16px;}"
                   "button{background:#007bff;border:none;color:#fff;}button:hover{background:#0069d9}"
                   "a{display:block;margin:8px 0;color:#007bff;}</style></head><body>";
}

void sendJSON(int code, const JsonDocument& doc) {
  String o;
  serializeJson(doc, o);
  http.send(code, "application/json", o);
}

void handleDiscovery() {
  StaticJsonDocument<160> d;
  d["device_id"] = g_deviceId;
  d["name"] = "Hydroleaf Smart Doser";
  d["type"] = DEVICE_TYPE;
  d["version"] = FW_VERSION;
  d["status"] = g_wifiConnected ? "online" : "offline";
  d["ip"] = WiFi.localIP().toString();
  sendJSON(200, d);
}
void handleVersion() {
  StaticJsonDocument<32> d;
  d["version"] = FW_VERSION;
  sendJSON(200, d);
}

void handlePumpPOST() {
  if (!http.hasArg("plain")) {
    http.send(400, "text/plain", "Missing JSON");
    return;
  }
  StaticJsonDocument<128> j;
  if (deserializeJson(j, http.arg("plain"))) {
    http.send(400, "Bad JSON");
    return;
  }
  int pump = j["pump"] | 0, amt = j["amount"] | 0;
  schedulePump(pump, amt);
  j["timestamp"] = millis();
  sendJSON(200, j);
}
void handleDoseMonitor() {
  if (!http.hasArg("plain")) {
    http.send(400, "Missing");
    return;
  }
  StaticJsonDocument<128> j;
  if (deserializeJson(j, http.arg("plain"))) {
    http.send(400, "Bad");
    return;
  }
  int pump = j["pump"] | 0, amt = j["amount"] | 0;
  schedulePump(pump, amt);
  StaticJsonDocument<160> r;
  r["message"] = "Started";
  r["pump"] = pump;
  r["dose_ms"] = amt;
  r["ph"] = pHValue;
  r["tds"] = tdsValue;
  r["timestamp"] = millis();
  sendJSON(200, r);
}
void handlePumpCal() {
  if (!http.hasArg("plain")) {
    http.send(400, "Missing");
    return;
  }
  StaticJsonDocument<64> j;
  if (deserializeJson(j, http.arg("plain"))) {
    http.send(400, "Bad");
    return;
  }
  String cmd = j["command"] | "";
  if (cmd == "start") {
    for (int p = 1; p <= 4; ++p) schedulePump(p, 50000);
    http.send(200, "application/json", "{\"message\":\"calibration started\"}");
  } else if (cmd == "stop") {
    for (int i = 0; i < 4; ++i) {
      pumps[i].active = false;
      setRelay(i + 1, false);
    }
    http.send(200, "application/json", "{\"message\":\"calibration stopped\"}");
  } else http.send(400, "text/plain", "Invalid command");
}
void handleMonitor() {
  StaticJsonDocument<128> d;
  d["ph"] = pHValue;
  d["tds"] = tdsValue;
  sendJSON(200, d);
}

/* Register routes (+Â keep existing portal pages if any) */
void setupRoutes() {
  http.on("/discovery", HTTP_GET, handleDiscovery);
  http.on("/version", HTTP_GET, handleVersion);
  http.on("/pump", HTTP_POST, handlePumpPOST);
  http.on("/dose_monitor", HTTP_POST, handleDoseMonitor);
  http.on("/pump_calibration", HTTP_POST, handlePumpCal);
  http.on("/monitor", HTTP_GET, handleMonitor);

  http.onNotFound([]() {
    http.sendHeader("Location", "/", true);
    http.send(302);
  });
  http.begin();
}

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€ 10. CAPTIVE PORTAL â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
void portalStart() {
  WiFi.mode(WIFI_AP_STA);
  IPAddress apIP(192, 168, 0, 1);
  WiFi.softAPConfig(apIP, apIP, IPAddress(255, 255, 255, 0));
  WiFi.softAP(g_deviceId.c_str(), g_apPass.c_str());
  dns.start(DNS_PORT, "*", apIP);
  setupRoutes();
}

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€ 11. SETUP â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
void setup() {
  Serial.begin(115200);
  tft.init();
  tft.setRotation(1);
  pinMode(LED_STATUS, OUTPUT);
  digitalWrite(LED_STATUS, LOW);
  for (int p : { RELAY_PUMP_1, RELAY_PUMP_2, RELAY_PUMP_3, RELAY_PUMP_4 }) {
    pinMode(p, OUTPUT);
    digitalWrite(p, HIGH);
  }

  prefs.begin("doser_cfg", false);
  g_ssid = prefs.getString("ssid", "");
  g_pass = prefs.getString("pass", "");
  g_apPass = prefs.getString("apPass", DEFAULT_AP_PASS);
  g_deviceId = prefs.getString("id", "");
  if (!g_deviceId.length()) {
    g_deviceId = "DOSER_" + String((uint32_t)esp_random(), HEX);
    prefs.putString("id", g_deviceId);
  }
  prefs.end();

  adc_chars = (esp_adc_cal_characteristics_t*)calloc(1, sizeof(*adc_chars));
  esp_adc_cal_characterize(ADC_UNIT_1, ADC_ATTEN_DB_11, ADC_WIDTH_BIT_12, 1100, adc_chars);
  analogSetPinAttenuation(PH_SENSOR_PIN, ADC_11db);
  analogSetPinAttenuation(TDS_SENSOR_PIN, ADC_11db);

  showStatus("Connecting Wiâ€‘Fiâ€¦");
  WiFi.mode(WIFI_STA);
  WiFi.begin(g_ssid.c_str(), g_pass.c_str());
  uint32_t st = millis();
  while (WiFi.status() != WL_CONNECTED && millis() - st < 10000) delay(200);
  g_wifiConnected = (WiFi.status() == WL_CONNECTED);
  showStatus(g_wifiConnected ? "Wiâ€‘Fi OK" : "AP mode");

  portalStart();
}

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€ 12. LOOP â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
void loop() {
  dns.processNextRequest();
  http.handleClient();
  updatePumps();
  readSensors();

  static uint32_t tHB = 0, tUpd = 0;
  uint32_t now = millis();
  if (now - tHB >= HB_INTERVAL) {
    tHB = now;
    sendHeartbeat();
  }
  if (now - tUpd >= UPDATE_INTERVAL) {
    tUpd = now;
    checkForUpdate();
  }

  if (WiFi.status() == WL_CONNECTED) wifiLostSince = 0;
  else {
    if (!wifiLostSince) wifiLostSince = now;
    if (now - wifiLostSince > WIFI_WATCHDOG_MS) {
      for (int i = 0; i < 4; ++i) {
        pumps[i].active = false;
        setRelay(i + 1, false);
      }
      ESP.restart();
    }
  }
}


----- device code/Valve controller/code.ino -----
/*****************************************************************************************
 *  HYDROLEAF VALVE-CTL  â€“  Production Firmware  v1.0  (28-Apr-2025)
 *  Target  : ESP8266 (4 MB flash)
 *  Author  : ChatGPT (OpenAI o4-mini)
 *
 *  â€¢ Device-ID auto-generated once (chip ID).
 *  â€¢ SSID/Pass/Host/Port persisted in EEPROM.
 *  â€¢ AP SSID = Device-ID, never user-configurable.
 *  â€¢ AP password persisted and resettable via captive portal.
 *  â€¢ Always-on captive portal (AP+STA) at 192.168.4.1 for Wi-Fi/Host/Port & AP-password reset.
 *  â€¢ Full production-grade: 4 valves, cloud heartbeat, chunked OTA (local & cloud).
 *****************************************************************************************/

#include <ESP8266WiFi.h>
#include <ESP8266WebServer.h>
#include <DNSServer.h>
#include <EEPROM.h>
#include <ArduinoJson.h>
#include <ESP8266HTTPClient.h>
#include <ESP8266httpUpdate.h>
#include <Ticker.h>

#pragma GCC optimize("Os")

// â”€â”€â”€â”€â”€â”€â”€â”€â”€ Configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
static const uint8_t  VALVE_COUNT     = 4;
static const uint8_t  valvePins[VALVE_COUNT] = { D1, D2, D5, D6 };
static const char*    DEFAULT_AP_PWD  = "configme";
static const byte     DNS_PORT        = 53;
static const unsigned long UPDATE_INTERVAL = 60*60UL;  // hourly cloud-check

#define EEPROM_SIZE       512
#define ADDR_SSID         0
#define ADDR_PASS         64
#define ADDR_HOST         128
#define ADDR_PORT         192
#define ADDR_AP_PWD       194
#define ADDR_DEVICE_ID    256
#define ADDR_TOKEN        288
#define ADDR_VALVE_STATE  336

// â”€â”€â”€â”€â”€â”€â”€â”€â”€ Libraries & Globals â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ESP8266WebServer http(80);
DNSServer           dns;
Ticker              heartbeatTicker;

String  g_ssid, g_pass;
String  g_host; 
uint16_t g_port;
String  g_apPass;
String  g_deviceId, g_token;
bool    g_valveState[VALVE_COUNT];

WiFiClient wifiClient;
bool        otaSuccess = false;
unsigned long lastCloudCheck = 0;

// â”€â”€â”€â”€â”€â”€â”€â”€â”€ Helpers: EEPROM â†” String â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
void saveString(int addr, const String &s, int maxLen){
  for(int i=0;i<maxLen;i++){
    char c = i < s.length() ? s[i] : '\0';
    EEPROM.write(addr + i, c);
  }
}

String loadString(int addr, int maxLen){
  String s;
  for(int i=0;i<maxLen;i++){
    char c = EEPROM.read(addr + i);
    if(!c) break;
    s += c;
  }
  return s;
}

void commitConfig(){
  EEPROM.commit();
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€ Heartbeat LED (reuse D0) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const uint32_t BLINK_MS=3000;
uint32_t lastBlink=0;
void beatLED(){
  uint32_t now=millis();
  if(now-lastBlink<BLINK_MS) return;
  lastBlink=now;
  digitalWrite(LED_BUILTIN,LOW);
  delay(20);
  digitalWrite(LED_BUILTIN,HIGH);
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€ HTML + CSS header â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
String htmlHeader(const char* title){
  String h="<!doctype html><html><head><meta charset='utf-8'>";
  h+="<meta name='viewport' content='width=device-width,initial-scale=1'>";
  h+="<title>";h+=title;h+="</title><style>"
     "body{font-family:Arial;background:#f7f7f7;margin:0;padding:20px}h2{margin-top:0}"
     "input,button{width:100%;padding:10px;margin:8px 0;box-sizing:border-box;font-size:16px}"
     "button{background:#007bff;border:none;color:#fff;cursor:pointer}"
     "button:hover{background:#0069d9}"
     "a{display:block;margin:8px 0;color:#007bff;text-decoration:none}"
     "a:hover{text-decoration:underline}"
     "</style></head><body>";
  return h;
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€ Captive-Portal Handlers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

// Main menu
void handleMenu(){
  String p=htmlHeader("Config Menu");
  p+="<h2>Settings</h2><ul>"
     "<li><a href='/network'>Wi-Fi / Host & Port</a></li>"
     "<li><a href='/ap_password'>Reset AP Password</a></li>"
     "</ul></body></html>";
  http.send(200,"text/html",p);
}

// Wi-Fi + Backend form
void handleNetworkPage(){
  String p=htmlHeader("Network Setup");
  p+="<h2>Wi-Fi & Backend</h2><form action='/save_network'>"
     "Wi-Fi SSID:<input name='ssid' value='"+g_ssid+"'>"
     "Wi-Fi Pass:<input type='password' name='pass' value='"+g_pass+"'>"
     "Host:<input name='host' value='"+g_host+"'>"
     "Port:<input name='port' value='"+String(g_port)+"'>"
     "<button type='submit'>Save &amp; Restart</button></form>"
     "<a href='/'>â† Back</a></body></html>";
  http.send(200,"text/html",p);
}

void handleSaveNetwork(){
  if(!http.hasArg("ssid")||!http.hasArg("pass")
  || !http.hasArg("host")||!http.hasArg("port")){
    http.send(400,"text/plain","Missing fields");return;
  }
  g_ssid = http.arg("ssid");
  g_pass = http.arg("pass");
  g_host = http.arg("host");
  g_port = http.arg("port").toInt();
  saveString(ADDR_SSID, g_ssid,   64);
  saveString(ADDR_PASS, g_pass,   64);
  saveString(ADDR_HOST, g_host,   64);
  EEPROM.write(ADDR_PORT, (g_port>>8)&0xFF);
  EEPROM.write(ADDR_PORT+1, g_port&0xFF);
  commitConfig();
  http.send(200,"text/html","<h1>Saved! Restartingâ€¦</h1>");
  delay(1000); ESP.restart();
}

// AP-Password form
void handleAPPage(){
  String p=htmlHeader("AP Password");
  p+="<h2>Reset AP Password</h2><form action='/reset_ap'>"
     "Password:<input type='password' name='apwd' value='"+g_apPass+"'>"
     "<button type='submit'>Update</button></form>"
     "<a href='/'>â† Back</a></body></html>";
  http.send(200,"text/html",p);
}

void handleResetAP(){
  if(!http.hasArg("apwd")){
    http.send(400,"text/plain","Missing");return;
  }
  g_apPass = http.arg("apwd");
  saveString(ADDR_AP_PWD, g_apPass, 32);
  commitConfig();
  dns.stop(); http.stop();
  // restart captive-portal
  WiFi.softAP(g_deviceId.c_str(),g_apPass.c_str());
  dns.start(DNS_PORT,"*",WiFi.softAPIP());
  setupRoutes();
  http.send(200,"text/html","<h1>AP Password Updated!</h1><a href='/'>Back</a>");
}

// Trap everything else
void handleNotFound(){
  http.sendHeader("Location","http://192.168.4.1",true);
  http.send(302);
}

// Build all routes
void setupRoutes(){
  http.on("/",            HTTP_GET,  handleMenu);
  http.on("/network",     HTTP_GET,  handleNetworkPage);
  http.on("/save_network",HTTP_GET,  handleSaveNetwork);
  http.on("/ap_password", HTTP_GET,  handleAPPage);
  http.on("/reset_ap",    HTTP_GET,  handleResetAP);

  // Get current valve states
  http.on("/state", HTTP_GET, [](){
    DynamicJsonDocument doc(256);
    doc["device_id"]=g_deviceId;
    auto arr=doc.createNestedArray("valves");
    for(uint8_t i=0;i<VALVE_COUNT;i++){
      JsonObject v=arr.createNestedObject();
      v["id"]=i+1; v["state"]=g_valveState[i];
    }
    String s; serializeJson(doc,s);
    http.send(200,"application/json",s);
  });

  // Toggle a valve
  http.on("/toggle", HTTP_POST, [](){
    DynamicJsonDocument in(128), out(128);
    if(deserializeJson(in,http.arg("plain"))||!in.containsKey("valve_id")){
      http.send(400,"application/json","{\"error\":\"invalid payload\"}"); return;
    }
    int vid=in["valve_id"];
    if(vid<1||vid>VALVE_COUNT){
      http.send(400,"application/json","{\"error\":\"valve_id out of range\"}"); return;
    }
    // flip
    uint8_t idx=vid-1;
    g_valveState[idx]=!g_valveState[idx];
    digitalWrite(valvePins[idx], g_valveState[idx]?HIGH:LOW);
    EEPROM.write(ADDR_VALVE_STATE+idx, g_valveState[idx]?1:0);
    commitConfig();
    // report upstream
    if(WiFi.status()==WL_CONNECTED && g_token.length()){
      HTTPClient  hc;
      String url=String("http://")+g_host+":"+g_port+"/valve_event";
      if(hc.begin(wifiClient,url)){
        hc.addHeader("Content-Type","application/json");
        hc.addHeader("Authorization","Bearer "+g_token);
        StaticJsonDocument<128> ev;
        ev["device_id"]=g_deviceId;
        ev["valve_id"]=vid;
        ev["state"]=g_valveState[idx];
        String body; serializeJson(ev,body);
        hc.POST(body);
        hc.end();
      }
    }
    out["device_id"]=g_deviceId;
    out["valve_id"]=vid;
    out["new_state"]=g_valveState[idx];
    String s; serializeJson(out,s);
    http.send(200,"application/json",s);
  });

  // Local OTA via multipart POST
  http.on("/update_firmware", HTTP_POST,
    [](){ // response after upload
      if(otaSuccess)   http.send(200,"text/plain","DONE");
      else             http.send(500,"text/plain","FAIL");
      otaSuccess=false;
      delay(100);
      ESP.restart();
    },
    [](){ // upload handler
      HTTPUpload &up = http.upload();
      if(up.status==UPLOAD_FILE_START){
        Serial.println("[OTA] Begin");
        WiFiClient::stopAll();
        uint32_t maxSz = (ESP.getFreeSketchSpace() - 0x1000) & 0xFFFFF000;
        if(!Update.begin(maxSz)) Update.printError(Serial);
      } else if(up.status==UPLOAD_FILE_WRITE){
        if(Update.write(up.buf, up.currentSize)!=up.currentSize)
          Update.printError(Serial);
      } else if(up.status==UPLOAD_FILE_END){
        otaSuccess = Update.end(true);
        Serial.println(otaSuccess? "[OTA] Success":"[OTA] Fail");
      } else if(up.status==UPLOAD_FILE_ABORTED){
        otaSuccess = false;
      }
    }
  );

  http.onNotFound(handleNotFound);
  http.begin();
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€ Networking & Capsule â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
bool wifiConnect(uint8_t tries=5){
  WiFi.mode(WIFI_STA);
  while(tries--){
    WiFi.begin(g_ssid.c_str(),g_pass.c_str());
    for(int i=0;i<50;i++){
      if(WiFi.status()==WL_CONNECTED) return true;
      delay(200);
    }
    WiFi.disconnect(true);
    delay(200);
  }
  return false;
}

void portalStart(){
  WiFi.mode(WIFI_AP_STA);
  WiFi.softAP(g_deviceId.c_str(), g_apPass.c_str());
  dns.start(DNS_PORT,"*",WiFi.softAPIP());
  setupRoutes();
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€ Device-ID & Config init â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
void generateDeviceId(){
  g_deviceId = loadString(ADDR_DEVICE_ID,32);
  if(!g_deviceId.length()){
    uint32_t chip=ESP.getChipId();
    g_deviceId = "valve-"+String(chip,HEX);
    saveString(ADDR_DEVICE_ID,g_deviceId,32);
    commitConfig();
  }
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€ Cloud Registration & OTA â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
void cloudRegister(){
  if(g_token.length()) return;
  HTTPClient hc;
  String url = String("http://")+g_host+":"+g_port+"/register";
  if(hc.begin(wifiClient,url)){
    hc.addHeader("Content-Type","application/json");
    StaticJsonDocument<128> j; j["device_id"]=g_deviceId;
    String b; serializeJson(j,b);
    if(hc.POST(b)==200){
      StaticJsonDocument<128> resp;
      deserializeJson(resp,hc.getString());
      if(resp.containsKey("token")){
        g_token = resp["token"].as<String>();
        saveString(ADDR_TOKEN,g_token,48);
        commitConfig();
      }
    }
    hc.end();
  }
}

void checkCloudUpdate(){
  if(WiFi.status()!=WL_CONNECTED||!g_token.length()) return;
  if(millis()<lastCloudCheck+UPDATE_INTERVAL) return;
  lastCloudCheck=millis();
  HTTPClient hc;
  String url=String("http://")+g_host+":"+g_port+"/update?device_id="+g_deviceId;
  if(hc.begin(wifiClient,url)){
    hc.addHeader("Authorization","Bearer "+g_token);
    if(hc.GET()==200){
      StaticJsonDocument<256> doc;
      deserializeJson(doc,hc.getString());
      if(doc["update_available"]){
        String uri = "/update/pull?device_id="+g_deviceId;
        ESPhttpUpdate.setAuthorization("Bearer "+g_token);
        ESPhttpUpdate.rebootOnUpdate(true);
        t_httpUpdate_return r = ESPhttpUpdate.update(wifiClient,g_host,cfg_port,uri);
        Serial.printf("[OTA] cloud pull: %d\n",r);
      }
    }
    hc.end();
  }
}

// Heartbeat
void sendHeartbeat(){
  if(WiFi.status()!=WL_CONNECTED||!g_token.length())return;
  HTTPClient hc;
  String url=String("http://")+g_host+":"+g_port+"/heartbeat";
  if(hc.begin(wifiClient,url)){
    hc.addHeader("Content-Type","application/json");
    hc.addHeader("Authorization","Bearer "+g_token);
    StaticJsonDocument<128> h;
    h["device_id"]=g_deviceId;
    h["status"]="ok";
    h["ts"]=millis();
    String b; serializeJson(h,b);
    hc.POST(b);
    hc.end();
  }
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€ Setup & Loop â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
void setup(){
  Serial.begin(115200);
  pinMode(LED_BUILTIN,OUTPUT); digitalWrite(LED_BUILTIN,HIGH);

  EEPROM.begin(EEPROM_SIZE);
  // load config
  g_ssid   = loadString(ADDR_SSID,64);
  g_pass   = loadString(ADDR_PASS,64);
  g_host   = loadString(ADDR_HOST,64);
  g_port   = (EEPROM.read(ADDR_PORT)<<8)|EEPROM.read(ADDR_PORT+1);
  g_apPass = loadString(ADDR_AP_PWD,32);
  if(!g_apPass.length()) g_apPass=DEFAULT_AP_PWD;

  // restore valves
  for(uint8_t i=0;i<VALVE_COUNT;i++){
    pinMode(valvePins[i],OUTPUT);
    bool st = EEPROM.read(ADDR_VALVE_STATE+i)==1;
    g_valveState[i]=st;
    digitalWrite(valvePins[i], st?HIGH:LOW);
  }

  // device ID & network
  generateDeviceId();
  if(g_ssid.length() && wifiConnect()){
    cloudRegister();
  }

  // start portal + server
  portalStart();

  // schedule heartbeat
  heartbeatTicker.attach(30, sendHeartbeat);
}

void loop(){
  dns.processNextRequest();
  http.handleClient();
  beatLED();
  if(WiFi.status()==WL_CONNECTED){
    checkCloudUpdate();
  }
}


